{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# T1 SEMANTIC SEGMENTATION\n",
    "\n",
    "Import and prepare point clouds for semantic segmentation and do the inference.\n",
    "To run these scripts, create a python 3.10 environment & install geomapi (numpy, opend3d, ifcopenshell, trimesh, ...), pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "#IMPORT PACKAGES\n",
    "from pathlib import Path\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import laspy\n",
    "from geomapi.utils import geometryutils as gmu\n",
    "import torch\n",
    "import os\n",
    "from collections import OrderedDict\n",
    "import time\n",
    "import torch.nn.functional as F\n",
    "\n",
    "#CONTEXT\n",
    "import context \n",
    "\n",
    "#UTILS\n",
    "from utils.t1_utils import *\n",
    "\n",
    "#POINTCEPT\n",
    "from pointcept.engines.defaults import (\n",
    "    default_argument_parser,\n",
    "    default_config_parser,\n",
    "    default_setup,\n",
    ")\n",
    "from pointcept.engines.test import TESTERS\n",
    "from pointcept.engines.launch import launch\n",
    "from pointcept.datasets import build_dataset, collate_fn\n",
    "import pointcept.utils.comm as comm\n",
    "\n",
    "from pointcept.engines.defaults import create_ddp_model\n",
    "\n",
    "from pointcept.utils.misc import make_dirs\n",
    "from pointcept.models import build_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## INPUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path= Path(os.getcwd()).parents[0]/'data'\n",
    "\n",
    "point_cloud_path =path/'t1_data'/'input'/'Eva.las'\n",
    "output_folder =  path/'t1_data'/'input'\n",
    "\n",
    "config_path = path/'t1_data'/'config.py' #Path(os.getcwd())/'data'/'t1_data'/'config.py'\n",
    "save_path = path/'t1_data' #Path(os.getcwd())/'data'/'t1_data'\n",
    "weights = path/'t1_data'/'model'/'model_best.pth' #Path(os.getcwd())/'data'/'t1_data'/'model'/'model_best.pth'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## INPUT DATA CONVERSION\n",
    "\n",
    "Preprocessing of input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['X', 'Y', 'Z', 'intensity', 'return_number', 'number_of_returns', 'scan_direction_flag', 'edge_of_flight_line', 'classification', 'synthetic', 'key_point', 'withheld', 'scan_angle_rank', 'user_data', 'point_source_id', 'red', 'green', 'blue']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "scene_id = os.path.basename(point_cloud_path)\n",
    "\n",
    "name, ext = os.path.splitext(scene_id)\n",
    "\n",
    "if ext not in  [\".las\", \".laz\"]:\n",
    "    exit()\n",
    "\n",
    "# Read LAS/LAZ\n",
    "# populate dict\n",
    "las = laspy.read(point_cloud_path)\n",
    "print(list(las.point_format.dimension_names))\n",
    "\n",
    "pcd = gmu.las_to_pcd(las)\n",
    "pcd.estimate_normals()\n",
    "pcd.orient_normals_to_align_with_direction()\n",
    "\n",
    "coords = np.stack([las.x, las.y, las.z], axis=1)\n",
    "# colors = np.stack([las.red, las.green, las.blue], axis=1) # betons\n",
    "colors = np.zeros((len(las.points), 3)).astype(np.uint8) + 255\n",
    "normals = np.asarray(pcd.normals)    \n",
    "\n",
    "save_dict = dict(coord=coords, color=colors, normal=normals, scene_id=scene_id) #, semantic_gt=las.labels.astype(int))\n",
    "\n",
    "torch.save(save_dict, os.path.join(output_folder, f\"{name}.pth\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## INFERENCE\n",
    "\n",
    "Inference using Point Transformer V3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'ThreeDomDataset is not in the datasets registry'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 102\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDONE.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    100\u001b[0m cfg \u001b[38;5;241m=\u001b[39m default_config_parser(\u001b[38;5;28mstr\u001b[39m(config_path), {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msave_path\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mstr\u001b[39m(save_path), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweight\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mstr\u001b[39m(weights)})\n\u001b[0;32m--> 102\u001b[0m \u001b[43mlaunch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    103\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmain_worker\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    104\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_gpus_per_machine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    105\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_machines\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    106\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmachine_rank\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    107\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdist_url\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mauto\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    109\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/code/Scan-to-BIM-CVPR-2024/scripts/../thirdparty/pointcept/pointcept/engines/launch.py:89\u001b[0m, in \u001b[0;36mlaunch\u001b[0;34m(main_func, num_gpus_per_machine, num_machines, machine_rank, dist_url, cfg, timeout)\u001b[0m\n\u001b[1;32m     74\u001b[0m     mp\u001b[38;5;241m.\u001b[39mspawn(\n\u001b[1;32m     75\u001b[0m         _distributed_worker,\n\u001b[1;32m     76\u001b[0m         nprocs\u001b[38;5;241m=\u001b[39mnum_gpus_per_machine,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     86\u001b[0m         daemon\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     87\u001b[0m     )\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 89\u001b[0m     \u001b[43mmain_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[4], line 46\u001b[0m, in \u001b[0;36mmain_worker\u001b[0;34m(cfg)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmain_worker\u001b[39m(cfg):    \n\u001b[1;32m     45\u001b[0m     cfg \u001b[38;5;241m=\u001b[39m default_setup(cfg)\n\u001b[0;32m---> 46\u001b[0m     test_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mbuild_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m comm\u001b[38;5;241m.\u001b[39mget_world_size() \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m     49\u001b[0m         test_sampler \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mdistributed\u001b[38;5;241m.\u001b[39mDistributedSampler(test_dataset)\n",
      "File \u001b[0;32m~/code/Scan-to-BIM-CVPR-2024/scripts/../thirdparty/pointcept/pointcept/datasets/builder.py:15\u001b[0m, in \u001b[0;36mbuild_dataset\u001b[0;34m(cfg)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbuild_dataset\u001b[39m(cfg):\n\u001b[1;32m     14\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Build datasets.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDATASETS\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/code/Scan-to-BIM-CVPR-2024/scripts/../thirdparty/pointcept/pointcept/utils/registry.py:214\u001b[0m, in \u001b[0;36mRegistry.build\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbuild\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 214\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mregistry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/code/Scan-to-BIM-CVPR-2024/scripts/../thirdparty/pointcept/pointcept/utils/registry.py:47\u001b[0m, in \u001b[0;36mbuild_from_cfg\u001b[0;34m(cfg, registry, default_args)\u001b[0m\n\u001b[1;32m     45\u001b[0m     obj_cls \u001b[38;5;241m=\u001b[39m registry\u001b[38;5;241m.\u001b[39mget(obj_type)\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m obj_cls \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 47\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mobj_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not in the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mregistry\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m registry\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39misclass(obj_type):\n\u001b[1;32m     49\u001b[0m     obj_cls \u001b[38;5;241m=\u001b[39m obj_type\n",
      "\u001b[0;31mKeyError\u001b[0m: 'ThreeDomDataset is not in the datasets registry'"
     ]
    }
   ],
   "source": [
    "\n",
    "def collate_fn(batch):\n",
    "    return batch\n",
    "\n",
    "def build_inference_model(cfg):\n",
    "    model = build_model(cfg.model)\n",
    "    n_parameters = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    model = create_ddp_model(\n",
    "        model.cuda(),\n",
    "        broadcast_buffers=False,\n",
    "        find_unused_parameters=cfg.find_unused_parameters,\n",
    "    )\n",
    "    if os.path.isfile(cfg.weight):\n",
    "        checkpoint = torch.load(cfg.weight)\n",
    "        weight = OrderedDict()\n",
    "        for key, value in checkpoint[\"state_dict\"].items():\n",
    "            if key.startswith(\"module.\"):\n",
    "                if comm.get_world_size() == 1:\n",
    "                    key = key[7:]  # module.xxx.xxx -> xxx.xxx\n",
    "            else:\n",
    "                if comm.get_world_size() > 1:\n",
    "                    key = \"module.\" + key  # xxx.xxx -> module.xxx.xxx\n",
    "            weight[key] = value\n",
    "        model.load_state_dict(weight, strict=True)\n",
    "\n",
    "    else:\n",
    "        raise RuntimeError(\"=> No checkpoint found at '{}'\".format(cfg.weight))\n",
    "    return model\n",
    "\n",
    "def main_worker(cfg):    \n",
    "    cfg = default_setup(cfg)\n",
    "    test_dataset = build_dataset(cfg.data.test)\n",
    "\n",
    "    if comm.get_world_size() > 1:\n",
    "        test_sampler = torch.utils.data.distributed.DistributedSampler(test_dataset)\n",
    "    else:\n",
    "        test_sampler = None\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=cfg.batch_size_test_per_gpu,\n",
    "        shuffle=False,\n",
    "        num_workers=cfg.batch_size_test_per_gpu,\n",
    "        pin_memory=True,\n",
    "        sampler=test_sampler,\n",
    "        collate_fn=collate_fn,\n",
    "    )\n",
    "    \n",
    "    model = build_inference_model(cfg)\n",
    "    model.eval()\n",
    "\n",
    "    save_path = os.path.join(cfg.save_path, \"result\")\n",
    "    make_dirs(save_path)\n",
    "    \n",
    "    for idx, data_dict in enumerate(test_loader):\n",
    "        data_dict = data_dict[0]  # current assume batch size is 1\n",
    "        fragment_list = data_dict.pop(\"fragment_list\")\n",
    "        segment = data_dict.pop(\"segment\")\n",
    "        data_name = data_dict.pop(\"name\")\n",
    "        pred_save_path = os.path.join(save_path, \"{}_pred.npy\".format(data_name))\n",
    "\n",
    "        pred = torch.zeros((segment.size, cfg.data.num_classes)).cuda()\n",
    "        for i in range(len(fragment_list)):\n",
    "            fragment_batch_size = 1\n",
    "            s_i, e_i = i * fragment_batch_size, min(\n",
    "                (i + 1) * fragment_batch_size, len(fragment_list)\n",
    "            )\n",
    "            input_dict = collate_fn(fragment_list[s_i:e_i])[0]\n",
    "            for key in input_dict.keys():\n",
    "                if isinstance(input_dict[key], torch.Tensor):\n",
    "                    input_dict[key] = input_dict[key].cuda(non_blocking=True)\n",
    "            idx_part = input_dict[\"index\"]            \n",
    "            with torch.no_grad():\n",
    "                pred_part = model(input_dict)[\"seg_logits\"]  # (n, k)\n",
    "                pred_part = F.softmax(pred_part, -1)\n",
    "                if cfg.empty_cache:\n",
    "                    torch.cuda.empty_cache()\n",
    "                bs = 0                \n",
    "                for be in input_dict[\"offset\"]:\n",
    "                    pred[idx_part[bs:be], :] += pred_part[bs:be]\n",
    "                    bs = be        \n",
    "        pred = pred.max(1)[1].data.cpu().numpy()\n",
    "        np.save(pred_save_path, pred)\n",
    "\n",
    "    print(\"DONE.\")\n",
    "\n",
    "cfg = default_config_parser(str(config_path), {'save_path': str(save_path), 'weight': str(weights)})\n",
    "\n",
    "launch(\n",
    "    main_worker,\n",
    "    num_gpus_per_machine=1,\n",
    "    num_machines=1,\n",
    "    machine_rank=0,\n",
    "    dist_url='auto',\n",
    "    cfg=(cfg,),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RESULTS\n",
    "\n",
    "Convert inference result back to .las"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "point_cloud_path = Path(os.getcwd())/'data'/'t1_data'/'input'/'Eva.las'\n",
    "labels_path = Path(os.getcwd())/'data'/'t1_data'/'result'/'Eva_pred.npy'\n",
    "output_folder =  Path(os.getcwd())/'data'/'t1_data'/'result'\n",
    "\n",
    "las = laspy.read(point_cloud_path)\n",
    "\n",
    "las.add_extra_dim(laspy.ExtraBytesParams(\n",
    "    name=\"labels\",\n",
    "    type=np.int32\n",
    "))\n",
    "\n",
    "labels = np.load(labels_path)\n",
    "\n",
    "las[\"labels\"] = labels\n",
    "\n",
    "las.write(os.path.join(output_folder, \"Eva_pred.las\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pointcept",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "metadata": {
   "interpreter": {
    "hash": "335c87f273ac958436761b9f67f775e8d80f72098ef3f48ec79b69099f6adb85"
   }
  },
  "orig_nbformat": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
