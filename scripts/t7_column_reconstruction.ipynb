{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "T7. COLUMNS RECONSTRUCTION\n",
    "\n",
    "    T7.1 RECTANGULAR COLUMNS \n",
    "\n",
    "In this script, we reconstruct columns from the instance segmentation and reference heights.\n",
    "We need:\n",
    " - T0 for classes and objects\n",
    " - T1: objest and objects_ids\n",
    " - T5: reference levels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORT PACKAGES\n",
    "from rdflib import Graph, URIRef\n",
    "import os.path\n",
    "import importlib\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import xml.etree.ElementTree as ET\n",
    "import open3d as o3d\n",
    "import uuid    \n",
    "import pye57 \n",
    "import ifcopenshell\n",
    "import ifcopenshell.geom as geom\n",
    "import ifcopenshell.util\n",
    "from ifcopenshell.util.selector import Selector\n",
    "import multiprocessing\n",
    "import random as rd\n",
    "import pandas as pd\n",
    "# from tabulate import tabulate\n",
    "import cv2\n",
    "import laspy\n",
    "import json\n",
    "from scipy.spatial.transform import Rotation   \n",
    "import copy\n",
    "import geomapi\n",
    "from geomapi.nodes import *\n",
    "import geomapi.utils as ut\n",
    "from geomapi.utils import geometryutils as gmu\n",
    "import geomapi.tools as tl\n",
    "\n",
    "# #import utils\n",
    "# from context import utils\n",
    "# import utils as utl\n",
    "# import utils.t1_utils as t1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "INPUTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name='steel_labels'\n",
    "\n",
    "path=Path(os.getcwd()).parents[2]/'data'\n",
    "pcd_input_path=os.path.join(path,f'{name}.las')\n",
    "class_file=path/'_classes.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OUTPUTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name=name.split('_')[0]\n",
    "json_output_path=os.path.join(path,f'{name}_columns.json') \n",
    "geometry_output_path= os.path.join(path,f'{name}_columns.obj') # these are the bounding surfaces of the reference levels (optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMPORT CLASSES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the JSON file\n",
    "with open(class_file, 'r') as file:\n",
    "    json_data = json.load(file)\n",
    "\n",
    "# Create a dictionary\n",
    "class_dict = {\n",
    "    'classes': json_data['classes'],\n",
    "    'default': json_data['default'],\n",
    "    'type': json_data['type'],\n",
    "    'format': json_data['format'],\n",
    "    'created_with': json_data['created_with']\n",
    "}\n",
    "print(class_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "THRESHOLDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_level=0.5\n",
    "t_distance=0.5\n",
    "t_thickness=0.15\n",
    "t_orthogonal=0.5\n",
    "t_topo_floors_ceilings=False\n",
    "t_intersection=0.5\n",
    "# t_topology=5\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NODES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pcd_input_path)\n",
    "\n",
    "laz=laspy.read(pcd_input_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "laz=laspy.read(pcd_input_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcdNodes=[]\n",
    "\n",
    "#split pcd per object\n",
    "for i in np.unique(laz['classes']):\n",
    "    idx=np.where(laz['classes']==i)\n",
    "    points=laz.xyz[idx]\n",
    "    # colors=np.array([laz.red[idx],laz.green[idx],laz.blue[idx]])\n",
    "    object_labels=laz['objects'][idx]\n",
    "\n",
    "    class_obj=next((class_obj for class_obj in json_data['classes'] if float(class_obj['id']) ==i), json_data['classes'][0])\n",
    "    class_name=class_obj['name']\n",
    "\n",
    "    # pcd.colors=o3d.utility.Vector3dVector(colors)\n",
    "    for j in np.unique(object_labels):\n",
    "        \n",
    "        new_points=points[np.where(object_labels==j)]\n",
    "        if new_points.shape[0]>100:\n",
    "            pcd=o3d.geometry.PointCloud()\n",
    "            pcd.points=o3d.utility.Vector3dVector(new_points)\n",
    "\n",
    "            pcdNodes.append(PointCloudNode(resource=pcd,\n",
    "                                        class_id=i,\n",
    "                                        object_id=j,\n",
    "                                        color=ut.random_color(),\n",
    "                                            name=class_name+f'_{j}'))\n",
    "\n",
    "print(f'{len(pcdNodes)} pcdNodes created!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GRAPH_IMPORT GRAPH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphPath = str(path / f'{name}Graph.ttl')\n",
    "graph = Graph().parse(graphPath, format=\"turtle\")\n",
    "\n",
    "print(graph)\n",
    "\n",
    "graph=Graph().parse(graphPath)\n",
    "print(graph)\n",
    "nodes=tl.graph_to_nodes(graph)\n",
    "print(nodes)\n",
    "columnNodes=[n for n in nodes if 'Columns' in n.subject and type(n)==PointCloudNode]\n",
    "wallNodes=[n for n in nodes if 'Walls' in n.subject and type(n)==PointCloudNode]\n",
    "ceilingsNodes=[n for n in nodes if 'Ceilings' in n.subject and type(n)==PointCloudNode]\n",
    "floorsNodes=[n for n in nodes if 'Floors' in n.subject and type(n)==PointCloudNode]\n",
    "print(f'{len(columnNodes)} columnNodes detected!')\n",
    "print(f'{len(wallNodes)} wallNodes detected!')\n",
    "print(f'{len(ceilingsNodes)} ceilingsNodes detected!')\n",
    "print(f'{len(floorsNodes)} floorsNodes detected!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMPORT PCD- MATCHING GRAPH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in columnNodes:\n",
    "    idx=np.where((laz['classes']==n.class_id) & (laz['objects']==n.object_id))\n",
    "    pcd=o3d.geometry.PointCloud()\n",
    "    pcd.points=o3d.utility.Vector3dVector(laz.xyz[idx])\n",
    "    n.resource=pcd\n",
    "    n.get_oriented_bounding_box()\n",
    "    n.orientedBoundingBox.color=[1,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_pcd=gmu.join_geometries([n.resource.paint_uniform_color(ut.literal_to_array(n.color)) for n in wallNodes if n.resource is not None])\n",
    "# o3d.visualization.draw_geometries([joined_pcd])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMPORT LEVELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "levelNodes=[n for n in nodes if 'level' in n.subject]\n",
    "referenceNodes=[]\n",
    "for l in levelNodes:\n",
    "    new_graph=ut.get_subject_graph(graph,levelNodes[0].subject)\n",
    "    n=SessionNode(graph=new_graph)\n",
    "    n.get_oriented_bounding_box()\n",
    "    n.resource=o3d.geometry.TriangleMesh.create_from_oriented_bounding_box(n.orientedBoundingBox)\n",
    "    referenceNodes.append(n) \n",
    "levelNodes=referenceNodes\n",
    "print(f'{len(levelNodes)} levelNodes detected!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CEILINGS AND FLOORS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in ceilingsNodes+floorsNodes: # this is quite slow because you iterate through 2 scalar fields every time\n",
    "    idx=np.where((laz['classes']==n.class_id) & (laz['objects']==n.object_id))\n",
    "    pcd=o3d.geometry.PointCloud()\n",
    "    pcd.points=o3d.utility.Vector3dVector(laz.xyz[idx])\n",
    "    n.resource=pcd\n",
    "    n.get_oriented_bounding_box()\n",
    "    n.orientedBoundingBox.color=[1,1,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PROCESSING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "READ POINTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A_BASE CONSTRAINT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in columnNodes:\n",
    "    #compute minheight of the resource at 0.1% of the height \n",
    "    z_values = np.sort(np.asarray(n.resource.points)[:,2])\n",
    "    minheight = np.percentile(z_values, 0.1)\n",
    "\n",
    "    #compute base constraint. select the intersecting level that is closest to the bottom of the wall. Else, just take first levelNode.\n",
    "    nearby_ref_levels= tl.select_nodes_with_intersecting_bounding_box(n,levelNodes)\n",
    "    n.base_constraint= next((n for n in nearby_ref_levels if np.absolute(n.height-minheight)<t_level),levelNodes[0])  if nearby_ref_levels else levelNodes[0] \n",
    "    \n",
    "    #compute base offset\n",
    "    n.base_offset=minheight-n.base_constraint.height\n",
    "    print(f'name: {n.name}, base_constraint: {n.base_constraint.name}, base_offset: {n.base_offset}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "B_TOP CONSTRAINT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points = np.sort(np.asarray(n.resource.points)[:,0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in columnNodes:\n",
    "    #compute maxheight of the resource at 0.1% of the height (absolute minimum might be wrong)\n",
    "    z_values = np.sort(np.asarray(n.resource.points)[:,2])\n",
    "    minheight = np.percentile(z_values, 0.1)\n",
    "    maxheight = np.percentile(z_values, 99.9)\n",
    "\n",
    "    #compute base constraint. select the intersecting level that is closest to the top of the wall. Else, just take last levelNode.\n",
    "    nearby_ref_levels= tl.select_nodes_with_intersecting_bounding_box(n,levelNodes)\n",
    "    n.top_constraint= next((n for n in nearby_ref_levels if np.absolute(n.height-maxheight)<t_level),levelNodes[-1]) if nearby_ref_levels else levelNodes[-1] #this is a link!\n",
    "    \n",
    "    #compute base offset\n",
    "    n.top_offset=maxheight-n.top_constraint.height\n",
    "\n",
    "    #compute wall height\n",
    "    n.height=maxheight-minheight\n",
    "    print(f'name: {n.name}, top_constraint: {n.top_constraint.name}, top_offset: {n.top_offset}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_pcd=gmu.join_geometries([n.resource.paint_uniform_color(ut.literal_to_array(n.color)) for n in columnNodes if n.resource is not None])\n",
    "for n in columnNodes:\n",
    "    n.orientedBoundingBox.color=[1,0,0]\n",
    "o3d.visualization.draw_geometries([joined_pcd]+[n.orientedBoundingBox for n in columnNodes])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COLUMN ORIENTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in columnNodes:    \n",
    "    # Main plane\n",
    "    n.plane_model, inliers = n.resource.segment_plane(distance_threshold=0.01,\n",
    "                                            ransac_n=3,\n",
    "                                            num_iterations=1000)\n",
    "    \n",
    "    # Center at correct heigth   \n",
    "    n.faceCenter=n.resource.select_by_index(inliers).get_center()  \n",
    "    n.faceCenter[2]=n.base_constraint.height + n.base_offset\n",
    "\n",
    "    #compute the normal of the plane in 2D (z=0)\n",
    "    n.normal=n.plane_model[:3]\n",
    "    n.normal[2]=0\n",
    "    n.normal/=np.linalg.norm(n.normal)\n",
    "\n",
    "    #compute the sign.\n",
    "    #if n.orientedBoundingBox width is > than 0.1, the sign is  given by the dotproduct of the normal of the face with the vector between the center of the face and the center of the oriented bounding box\n",
    "    boxCenter=n.orientedBoundingBox.get_center()\n",
    "    boxCenter[2]=n.base_constraint.height + n.base_offset\n",
    "    n.sign=np.sign(np.dot(n.normal,n.faceCenter-boxCenter))\n",
    "\n",
    "    #if n.orientedBoundingBox width < t_thickness, take a look at the ceiling and floor nodes to see on which side they are, and use them to spawn the wall away from these nodes\n",
    "    if n.orientedBoundingBox.extent[2]<=t_thickness:   \n",
    "        #combine list\n",
    "        combined_list = ceilingsNodes + floorsNodes\n",
    "        #create reference pcd from these resources\n",
    "        referencePcd,identityArray=gmu.create_identity_point_cloud([n.resource for n in combined_list if n.resource is not None])\n",
    "        #find nearest point near the top and the bottom \n",
    "        topPoint=copy.deepcopy(boxCenter)\n",
    "        topPoint[2]=n.base_constraint.height + n.base_offset+n.height\n",
    "        bottomPoint=boxCenter\n",
    "        idx,distances=gmu.compute_nearest_neighbors(np.asarray([topPoint,bottomPoint]),np.asarray(referencePcd.points)) \n",
    "        points=np.asarray(referencePcd.points)[idx[:,0]]\n",
    "        #compute orthogonal distance to the plane and select node with lowest distance\n",
    "        idx=idx[np.argmin(np.absolute(np.einsum('i,ji->j',n.normal,points-boxCenter))) ][0]\n",
    "        index=identityArray[idx]\n",
    "        referenceNode=combined_list[index]\n",
    "        point=np.asarray(referencePcd.points)[idx]\n",
    "        point[2]=n.base_constraint.height + n.base_offset\n",
    "        n.sign=np.sign(np.dot(n.normal,point-boxCenter))\n",
    "    \n",
    "    #flip the normal if it points inwards\n",
    "    n.normal*=-1 if n.sign==-1 else 1\n",
    "\n",
    "    print(f'name: {n.name}, plane: {n.plane_model}, inliers: {len(inliers)}/{len(np.asarray(n.resource.points))}')\n",
    "          \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMPUTE COLUMN THICKNESS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in columnNodes:\n",
    "    #compute the normals of the wall\n",
    "    pcd_tree = o3d.geometry.KDTreeFlann(n.resource)\n",
    "    n.resource.estimate_normals() if not n.resource.has_normals() else None\n",
    "\n",
    "    #for every 10th point in P, that has the same normal as the dominant plane, select nearest points in P that meet a distance threshold    \n",
    "    points=np.asarray(n.resource.points)[::100]\n",
    "    normals=np.asarray(n.resource.normals)[::100]\n",
    "    idx=np.where(np.absolute(np.einsum('i,ji->j',n.normal,normals))>0.9)\n",
    "    points=points[idx]\n",
    "    normals=normals[idx]\n",
    "    distances=[]\n",
    "\n",
    "    for p,q in zip(points,normals):\n",
    "        #compute distances\n",
    "        [k, idx, _] = pcd_tree.search_radius_vector_3d(p, t_distance)        \n",
    "        #retain only the distances for which the normal is within 0.7 radians of the normal of the point\n",
    "        kNormals=np.asarray(n.resource.normals)[idx]\n",
    "        indices=np.asarray(idx)[np.where(np.absolute(np.einsum('i,ji->j',q,kNormals))>0.9)]\n",
    "        #compute the dotproduct between the point and the normals of the points in the radius\n",
    "        vectors=p-np.asarray(n.resource.select_by_index(indices).points)\n",
    "        #keep the max distance (orthogonal distance between the planes)\n",
    "        distances.append(np.absolute(np.einsum('i,ji->j', q, vectors)).max())\n",
    "\n",
    "    #take the distance at the 99% percentile\n",
    "    distance = np.percentile(np.sort(np.array(distances)), 90) \n",
    "    n.columnThickness=distance if distance > t_thickness else t_thickness\n",
    "\n",
    "    print(f'name: {n.name}, BB_extent: {n.orientedBoundingBox.extent}, columnThickness: {n.columnThickness}')\n",
    "\n",
    "\n",
    "    ## ADD columnWidth: {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o3d.visualization.draw_geometries([n.resource for n in columnNodes if n.columnThickness <=t_thickness]+\n",
    "                                  [n.orientedBoundingBox for n in columnNodes])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMPUTE COLUMN AXIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in columnNodes:     \n",
    "    \n",
    "    #offset the center of the plane with half the column thickness in the direction of the normal of the plane  \n",
    "    columnCenter=n.faceCenter-n.normal*n.columnThickness/2 \n",
    "\n",
    "    columnCenter[2]=n.base_constraint.height + n.base_offset\n",
    "\n",
    "    #project axis aligned bounding points on the plane\n",
    "    box=n.resource.get_axis_aligned_bounding_box()    \n",
    "    points=np.asarray(box.get_box_points())\n",
    "    points[:,2]=n.base_constraint.height + n.base_offset\n",
    "\n",
    "    #translate the points to the plane\n",
    "    vectors=points-columnCenter\n",
    "    translation=np.einsum('ij,j->i',vectors,n.normal)\n",
    "    points=points - translation[:, np.newaxis] * n.normal\n",
    "\n",
    "    # Calculate the pairwise distances between all boundary points\n",
    "    distances = np.linalg.norm(points[:, np.newaxis] - points, axis=2)\n",
    "\n",
    "    # Get the indices of the two points with the maximum distance\n",
    "    max_indices = np.unravel_index(np.argmax(distances), distances.shape)\n",
    "\n",
    "    # Retain only the two points with the maximum distance\n",
    "    n.boundaryPoints = points[max_indices,:]\n",
    "\n",
    "    #create the axis\n",
    "    n.axis=o3d.geometry.LineSet(points=o3d.utility.Vector3dVector(n.boundaryPoints),lines=o3d.utility.Vector2iVector([[0,1]])).paint_uniform_color([0,0,1])\n",
    "    n.startPoint=n.boundaryPoints[0]\n",
    "    n.endPoint=n.boundaryPoints[1]\n",
    "    # Calculate the length\n",
    "    n.columnWidth = np.linalg.norm(n.boundaryPoints[0] - n.boundaryPoints[1])\n",
    "\n",
    "    print(f'name: {n.name}, ColumnWidth: {n.columnWidth}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o3d.visualization.draw_geometries([joined_pcd]+\n",
    "                                  [n.orientedBoundingBox for n in columnNodes]+\n",
    "                                  [n.axis for n in columnNodes]+\n",
    "                                  [o3d.geometry.PointCloud(o3d.utility.Vector3dVector(n.boundaryPoints)) for n in columnNodes])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMPUTE COLUMN GEOMETRY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in columnNodes:\n",
    "    pointList=[]\n",
    "    points=np.asarray(n.axis.points)\n",
    "    # pointList.extend(points+n.sign*n.normal*n.wallThickness/2)\n",
    "    pointList.extend(points+n.normal*n.columnThickness/2)\n",
    "\n",
    "    # pointList.extend(points-n.sign*n.normal*n.wallThickness/2)\n",
    "    pointList.extend(points-n.normal*n.columnThickness/2)\n",
    "\n",
    "    pointList.extend(np.array(pointList)+np.array([0,0,n.height]))\n",
    "    pcd=o3d.geometry.PointCloud(points=o3d.utility.Vector3dVector(pointList))\n",
    "\n",
    "    box=pcd.get_oriented_bounding_box()\n",
    "    n.column=o3d.geometry.TriangleMesh.create_from_oriented_bounding_box(box)\n",
    "    n.column.paint_uniform_color(ut.literal_to_array(n.color))\n",
    "    n.columnBox=o3d.geometry.LineSet.create_from_oriented_bounding_box(box)\n",
    "    n.columnBox.paint_uniform_color([0,0,1])\n",
    "\n",
    "    print(f'name: {n.name}, Column: {n.column}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o3d.visualization.draw_geometries([joined_pcd]+\n",
    "                                  [n.columnBox for n in columnNodes]+\n",
    "                                  [n.axis for n in columnNodes]+\n",
    "                                  [o3d.geometry.PointCloud(o3d.utility.Vector3dVector(n.boundaryPoints)) for n in columnNodes])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute Wall topology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intersect_line_2d(p0, p1, q0, q1,strict=True):\n",
    "    \"\"\"\n",
    "    Compute the intersection between two lines in 3D.\n",
    "    Each line is defined by a pair of points.\n",
    "    \n",
    "    Parameters:\n",
    "    - p0, p1: points (arrays) defining the first line.\n",
    "    - q0, q1: points (arrays) defining the second line.\n",
    "    - strict: if True, the intersection point must lie within the line segments.\n",
    "    \n",
    "    Returns:\n",
    "    - The intersection point as a numpy array if it exists, otherwise None.\n",
    "    \"\"\"\n",
    "    # Direction vectors of the lines\n",
    "    dp = p1 - p0\n",
    "    dq = q1 - q0\n",
    "    \n",
    "    # Matrix and vector for the linear system\n",
    "    A = np.vstack((dp, -dq)).T\n",
    "    b = q0 - p0\n",
    "    \n",
    "    # Solve the linear system\n",
    "    try:\n",
    "        t, u = np.linalg.solve(A, b)\n",
    "    except np.linalg.LinAlgError:\n",
    "        # The system is singular: lines are parallel or identical\n",
    "        return None\n",
    "    \n",
    "    # Intersection point\n",
    "    intersection = p0 + t * dp\n",
    "    \n",
    "    if strict:\n",
    "    # Since the system has a solution, check if it lies within the line segments\n",
    "        if np.allclose(intersection, q0 + u * dq):\n",
    "            return intersection\n",
    "        else:\n",
    "            return None\n",
    "    else:\n",
    "        return intersection\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BIM NODES FOR COLUMNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnNodesBIM = []\n",
    "for n in columnNodes:\n",
    "    b = BIMNode(\n",
    "        derivedFrom=n.subject,  # this should be a URI\n",
    "        resource=n.column,\n",
    "        base_constraint=n.base_constraint.subject,\n",
    "        base_constraint_name=n.base_constraint.name,\n",
    "        base_offset=n.base_offset,\n",
    "        top_constraint=n.top_constraint.subject,\n",
    "        top_constraint_name=n.top_constraint.name,\n",
    "        top_offset=n.top_offset,\n",
    "        height=n.height,\n",
    "        columnsThickness=n.columnThickness, \n",
    "        columnsLength=n.columnWidth,  \n",
    "        normal=n.normal,\n",
    "        startpoint=n.boundaryPoints[0],\n",
    "        endpoint=n.boundaryPoints[1],\n",
    "        color=n.color\n",
    "    )\n",
    "    columnNodesBIM.append(b)\n",
    "\n",
    "new_graph = tl.nodes_to_graph(columnNodesBIM, overwrite=True)\n",
    "\n",
    "# Remove all BIM nodes from the original graph\n",
    "for n in columnNodesBIM:\n",
    "    graph.remove((URIRef(n.subject), None, None))\n",
    "\n",
    "# Add new BIM nodes to the graph\n",
    "graph = graph + new_graph\n",
    "\n",
    "# Serialize the graph to a file\n",
    "print(graph.serialize(graphPath, format=\"turtle\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import distance\n",
    "\n",
    "for n in columnNodesBIM:\n",
    "    n.orthogonalStartpoint = n.startpoint + n.normal * n.columnsThickness / 2\n",
    "    n.orthogonalEndpoint = n.endpoint + n.normal * n.columnsThickness / 2\n",
    "\n",
    "for n in columnNodesBIM:\n",
    "    axisPoints = np.array([n.startpoint, n.endpoint])\n",
    "\n",
    "    referencePcd, identityArray = gmu.create_identity_point_cloud([w.resource for w in columnNodesBIM if w != n])\n",
    "    reference_points = np.asarray(referencePcd.points)\n",
    "\n",
    "    idx, distances = gmu.compute_nearest_neighbors(axisPoints, reference_points, n=10)\n",
    "\n",
    "    idx = idx[np.where(distances < t_intersection)]\n",
    "    points = np.asarray(referencePcd.points)[idx]\n",
    "    nearbyColumns = [columnNodesBIM[i] for i in identityArray[idx]]\n",
    "\n",
    "    print(f'found {len(nearbyColumns)} nearby columns for {n.name}')\n",
    "\n",
    "    for w in nearbyColumns:\n",
    "        intersection_point = intersect_line_2d(n.startpoint, n.endpoint, w.startpoint, w.endpoint, strict=False)\n",
    "        if intersection_point is not None:\n",
    "            d = distance.euclidean(intersection_point, n.startpoint)\n",
    "            if d < t_intersection:\n",
    "                print(f'Intersection between {n.name} and {w.name} at {intersection_point}, distance: {d}')\n",
    "\n",
    "    for w in nearbyColumns:\n",
    "        intersection_point = intersect_line_2d(n.orthogonalStartpoint, n.orthogonalEndpoint, w.startpoint, w.endpoint)\n",
    "        if intersection_point is not None:\n",
    "            d = distance.euclidean(intersection_point, n.orthogonalStartpoint)\n",
    "            if d < t_orthogonal:\n",
    "                print(f'Orthogonal intersection between {n.name} and {w.name} at {intersection_point}, distance: {d}')\n",
    "\n",
    "    break  # You may remove this break statement if you want to iterate over all column nodes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EXPORT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMPUTE THE CENTRE OF THE COLUMN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the center of the column for each object\n",
    "for obj in json_data[\"objects\"]:\n",
    "    startpoint = np.array([obj[\"startpoint\"][\"x\"], obj[\"startpoint\"][\"y\"], obj[\"startpoint\"][\"z\"]])\n",
    "    endpoint = np.array([obj[\"endpoint\"][\"x\"], obj[\"endpoint\"][\"y\"], obj[\"endpoint\"][\"z\"]])\n",
    "\n",
    "    # Compute the center as the average of start and end points\n",
    "    center = (startpoint + endpoint) / 2.0\n",
    "\n",
    "    # Update the object with the center coordinates\n",
    "    obj[\"center\"] = {\n",
    "        \"x\": center[0],\n",
    "        \"y\": center[1],\n",
    "        \"z\": center[2]\n",
    "    }\n",
    "\n",
    "print(center)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "json with metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#declare json\n",
    "json_data = {\n",
    "        \"filename\": ut.get_filename(json_output_path),\n",
    "        \"objects\": []\n",
    "    }\n",
    "#fill json\n",
    "for n in columnNodes:\n",
    "    obj = {\n",
    "            \"name\": n.name,\n",
    "            \"base_constraint\":n.base_constraint.name,\n",
    "            \"base_offset\":n.base_offset,\n",
    "            \"top_constraint\":n.top_constraint.name,\n",
    "            \"top_offset\":n.top_offset,\n",
    "            \"height\": n.height,\n",
    "            \"columnThickness\": n.columnThickness,\n",
    "            \"columnWidth\": n.columnWidth,\n",
    "            \"normal\": {\n",
    "                \"x\": n.normal[0],\n",
    "                \"y\": n.normal[1],\n",
    "                \"z\": n.normal[2]\n",
    "            },\n",
    "            \"startpoint\": {\n",
    "                \"x\": n.boundaryPoints[0][0],\n",
    "                \"y\": n.boundaryPoints[0][1],\n",
    "                \"z\": n.boundaryPoints[0][2]\n",
    "            }\n",
    "            ,\n",
    "            \"endpoint\": {\n",
    "                \"x\": n.boundaryPoints[1][0],\n",
    "                \"y\": n.boundaryPoints[1][1],\n",
    "                \"z\": n.boundaryPoints[1][2]\n",
    "            }\n",
    "            }\n",
    "    json_data[\"objects\"].append(obj)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WRITE THE JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write this information to the 3D detection json\n",
    "with open(json_output_path, \"w\") as json_file:\n",
    "    json.dump(json_data, json_file, indent=4)\n",
    "print(\"JSON data written to file:\", json_output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OBJ WITH COLUMNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_obj_with_submeshes(filename, meshes, mesh_names):\n",
    "    \"\"\"\n",
    "    Write multiple Open3D TriangleMesh objects to a single OBJ file with submeshes.\n",
    "\n",
    "    Parameters:\n",
    "    - filename: str, the name of the output OBJ file.\n",
    "    - meshes: list of open3d.geometry.TriangleMesh, the meshes to write.\n",
    "    - mesh_names: list of str, the names of the submeshes.\n",
    "    \"\"\"\n",
    "    if len(meshes) != len(mesh_names):\n",
    "        raise ValueError(\"meshes and mesh_names must have the same length\")\n",
    "\n",
    "    vertex_offset = 1  # OBJ files are 1-indexed\n",
    "    with open(filename, 'w') as file:\n",
    "        for mesh, name in zip(meshes, mesh_names):\n",
    "            file.write(f\"g {name}\\n\")  # Start a new group for the submesh\n",
    "\n",
    "            # Write vertices\n",
    "            for vertex in mesh.vertices:\n",
    "                file.write(f\"v {vertex[0]} {vertex[1]} {vertex[2]}\\n\")\n",
    "\n",
    "            # Write faces, adjusting indices based on the current offset\n",
    "            for triangle in mesh.triangles:\n",
    "                adjusted_triangle = triangle + vertex_offset\n",
    "                file.write(f\"f {adjusted_triangle[0]} {adjusted_triangle[1]} {adjusted_triangle[2]}\\n\")\n",
    "\n",
    "            # Update the vertex offset for the next mesh\n",
    "            vertex_offset += len(mesh.vertices)\n",
    "\n",
    "# Example usage:\n",
    "# Assuming mesh1 and mesh2 are your Open3D TriangleMesh objects\n",
    "mesh1 = o3d.geometry.TriangleMesh.create_sphere(radius=1.0)\n",
    "mesh1.compute_vertex_normals()\n",
    "\n",
    "mesh2 = o3d.geometry.TriangleMesh.create_box(width=1.0, height=1.0, depth=1.0)\n",
    "mesh2.compute_vertex_normals()\n",
    "\n",
    "write_obj_with_submeshes(geometry_output_path, [n.column for n in columnNodes], [n.name for n in columnNodes])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "graph with metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnNodesBIM=[]\n",
    "for n in columnNodes:\n",
    "    b=BIMNode(subject=n.subject+'_BIM',\n",
    "            derivedFrom=n.subject, #this should be a URI\n",
    "            resource=n.column,\n",
    "            base_constraint=n.base_constraint.subject,\n",
    "            base_constraint_name=n.base_constraint.name,\n",
    "            base_offset=n.base_offset,\n",
    "            top_constraint=n.top_constraint.subject,\n",
    "            top_constraint_name=n.top_constraint.name,\n",
    "            top_offset=n.top_offset,\n",
    "            height=n.height,\n",
    "            columnThickness=n.columnThickness,\n",
    "            columnWidth=n.columnWidth,\n",
    "            normal=n.normal,\n",
    "            startpoint=n.boundaryPoints[0],\n",
    "            endpoint=n.boundaryPoints[1],\n",
    "            color=n.color)\n",
    "    columnNodesBIM.append(b)\n",
    "new_graph=tl.nodes_to_graph(columnNodesBIM,overwrite=True)\n",
    "\n",
    "#remove all BIM nodes from original graph\n",
    "for n in columnNodesBIM:\n",
    "    graph.remove((URIRef(n.subject),None,None))\n",
    "graph=graph+new_graph\n",
    "print(graph.serialize(graphPath, format=\"turtle\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.19 64-bit ('pointcept': conda)",
   "name": "python3919jvsc74a57bd0335c87f273ac958436761b9f67f775e8d80f72098ef3f48ec79b69099f6adb85"
  },
  "language_info": {
   "name": "python",
   "version": ""
  },
  "orig_nbformat": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}