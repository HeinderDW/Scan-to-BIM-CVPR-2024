{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# T1 SEMANTIC SEGMENTATION TRAINING\n",
    "\n",
    "Small example on how to train Pointcept for semantic segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORT PACKAGES\n",
    "from pathlib import Path\n",
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, os.path.abspath(os.path.join('.')))\n",
    "sys.path.insert(0, os.path.abspath(os.path.join('scripts')))\n",
    "sys.path.insert(0, os.path.abspath(os.path.join('thirdparty', 'pointcept')))\n",
    "print(sys.path)\n",
    "import numpy as np\n",
    "import laspy\n",
    "from geomapi.utils import geometryutils as gmu\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## INPUT DATA CONVERSION\n",
    "\n",
    "Preprocessing of input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_process(file_name, output_folder):\n",
    "    \n",
    "    coords = []\n",
    "    scene_id = os.path.basename(file_name)\n",
    "\n",
    "    name, ext = os.path.splitext(scene_id)\n",
    "    \n",
    "    if ext not in  [\".las\", \".laz\"]:\n",
    "        return\n",
    "\n",
    "    # Read LAS/LAZ\n",
    "    # populate dict\n",
    "    las = laspy.read(file_name)\n",
    "    print(list(las.point_format.dimension_names))\n",
    "\n",
    "    pcd = gmu.las_to_pcd(las)\n",
    "    pcd.estimate_normals()\n",
    "    pcd.orient_normals_to_align_with_direction()\n",
    "    \n",
    "    coords = np.stack([las.x, las.y, las.z], axis=1)\n",
    "    colors = np.stack([las.red, las.green, las.blue], axis=1).astype(np.uint8)\n",
    "    normals = np.asarray(pcd.normals)\n",
    "    verticality = np.nan_to_num(las.verticality)\n",
    "    max = np.max(verticality)\n",
    "    verticality = verticality / (max / 2.) - 1.\n",
    "    \n",
    "    save_dict = dict(coord=coords, color=colors, normal=normals, verticality=verticality, scene_id=scene_id, semantic_gt=las.labels.astype(int))\n",
    "\n",
    "    torch.save(save_dict, os.path.join(output_folder, f\"{name}.pth\"))\n",
    "\n",
    "\n",
    "training_las_path = Path(os.getcwd())/'data'/'t1_data'/'input'/'train.las'\n",
    "training_output_folder = Path(os.getcwd())/'data'/'t1_data'/'train'\n",
    "\n",
    "validation_las_path = Path(os.getcwd())/'data'/'t1_data'/'input'/'val.las'\n",
    "validation_output_folder = Path(os.getcwd())/'data'/'t1_data'/'val'\n",
    "\n",
    "os.makedirs(training_output_folder, exist_ok=True)\n",
    "os.makedirs(validation_output_folder, exist_ok=True)\n",
    "\n",
    "handle_process(training_las_path, training_output_folder)\n",
    "handle_process(validation_las_path, validation_output_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRAINING\n",
    "\n",
    "Training using Point Transformer V3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pointcept.engines.defaults import (\n",
    "    default_argument_parser,\n",
    "    default_config_parser,\n",
    "    default_setup,\n",
    ")\n",
    "from pointcept.engines.train import TRAINERS\n",
    "from pointcept.engines.launch import launch\n",
    "\n",
    "\n",
    "def main_worker(cfg):\n",
    "    cfg = default_setup(cfg)\n",
    "    trainer = TRAINERS.build(dict(type=cfg.train.type, cfg=cfg))\n",
    "    trainer.train()\n",
    "\n",
    "config_path = Path(os.getcwd())/'data'/'t1_data'/'config.py' #Path(os.getcwd())/'data'/'t1_data'/'config.py'\n",
    "save_path = Path(os.getcwd())/'data'/'t1_data' #Path(os.getcwd())/'data'/'t1_data'\n",
    "weights = Path(os.getcwd())/'data'/'t1_data'/'model'/'model_best.pth' #Path(os.getcwd())/'data'/'t1_data'/'model'/'model_best.pth'\n",
    "\n",
    "cfg = default_config_parser(str(config_path), {'save_path': str(save_path), 'weight': str(weights)})\n",
    "\n",
    "launch(\n",
    "    main_worker,\n",
    "    num_gpus_per_machine=1,\n",
    "    num_machines=1,\n",
    "    machine_rank=0,\n",
    "    dist_url='auto',\n",
    "    cfg=(cfg,),\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.19 64-bit ('pointcept': conda)",
   "name": "python3919jvsc74a57bd0335c87f273ac958436761b9f67f775e8d80f72098ef3f48ec79b69099f6adb85"
  },
  "language_info": {
   "name": "python",
   "version": ""
  },
  "orig_nbformat": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}