{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# T1 SEMANTIC SEGMENTATION TRAINING\n",
    "\n",
    "Small example on how to train Pointcept for semantic segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "root_folder = os.path.abspath('..')\n",
    "data_folder_name = os.path.join(root_folder, 'test_data')\n",
    "\n",
    "print(root_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORT PACKAGES\n",
    "from pathlib import Path\n",
    "import sys\n",
    "sys.path.insert(0, root_folder)\n",
    "sys.path.insert(0, os.path.join(root_folder, \"scripts\"))\n",
    "sys.path.insert(0, os.path.join(root_folder, 'thirdparty', 'pointcept'))\n",
    "print(sys.path)\n",
    "import numpy as np\n",
    "import laspy\n",
    "from geomapi.utils import geometryutils as gmu\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LOAD AND REMAP CLASSES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "classes_file = os.path.join(data_folder_name, '_classes.json')\n",
    "\n",
    "# Read the JSON file\n",
    "with open(classes_file, 'r') as file:\n",
    "    json_data = json.load(file)\n",
    "\n",
    "classes_list = json_data['classes']\n",
    "\n",
    "print(classes_list)\n",
    "\n",
    "remapped_classes_ids = {}\n",
    "\n",
    "for class_entry in classes_list:\n",
    "    remapped_classes_ids[int(class_entry[\"id\"])] = int(class_entry[\"temp_id\"])\n",
    "\n",
    "print(remapped_classes_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## INPUT DATA CONVERSION\n",
    "\n",
    "Preprocessing of input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_process(file_name, output_folder):\n",
    "    \n",
    "    print(file_name)\n",
    "\n",
    "    scene_id = os.path.basename(file_name)\n",
    "\n",
    "    name, ext = os.path.splitext(scene_id)\n",
    "    \n",
    "    if ext not in  [\".las\", \".laz\"]:\n",
    "        return\n",
    "\n",
    "    # Read LAS/LAZ\n",
    "    # populate dict\n",
    "    las = laspy.read(file_name)\n",
    "    print(list(las.point_format.dimension_names))\n",
    "\n",
    "    pcd = gmu.las_to_pcd(las)\n",
    "    pcd.estimate_normals()\n",
    "    pcd.orient_normals_to_align_with_direction()\n",
    "    \n",
    "    coords = np.stack([las.x, las.y, las.z], axis=1)\n",
    "    colors = np.stack([las.red / 256, las.green / 256, las.blue / 256], axis=1).astype(np.uint8)\n",
    "    normals = np.asarray(pcd.normals)\n",
    "    \n",
    "    classes = []\n",
    "\n",
    "    for class_id in las.classes.astype(int):\n",
    "        classes.append(remapped_classes_ids[class_id])\n",
    "\n",
    "    save_dict = dict(coord=coords, color=colors, normal=normals, scene_id=scene_id, semantic_gt=np.array(classes).astype(int))\n",
    "\n",
    "    torch.save(save_dict, os.path.join(output_folder, f\"{name}.pth\"))\n",
    "\n",
    "\n",
    "training_las_folder = os.path.join(data_folder_name, 't1_data', 'input', 'train')\n",
    "training_output_folder = os.path.join(data_folder_name, 't1_data', 'train')\n",
    "\n",
    "validation_las_folder = os.path.join(data_folder_name, 't1_data', 'input', 'val')\n",
    "validation_output_folder = os.path.join(data_folder_name, 't1_data', 'val')\n",
    "\n",
    "os.makedirs(training_output_folder, exist_ok=True)\n",
    "os.makedirs(validation_output_folder, exist_ok=True)\n",
    "\n",
    "for file_name in os.listdir(training_las_folder):\n",
    "    handle_process(os.path.join(training_las_folder, file_name), training_output_folder)\n",
    "\n",
    "for file_name in os.listdir(validation_las_folder):\n",
    "    handle_process(os.path.join(validation_las_folder, file_name), validation_output_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRAINING\n",
    "\n",
    "Training using Point Transformer V3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pointcept.engines.defaults import (\n",
    "    default_argument_parser,\n",
    "    default_config_parser,\n",
    "    default_setup,\n",
    ")\n",
    "from pointcept.engines.train import TRAINERS\n",
    "from pointcept.engines.launch import launch\n",
    "\n",
    "\n",
    "def main_worker(cfg):\n",
    "    cfg = default_setup(cfg)\n",
    "    trainer = TRAINERS.build(dict(type=cfg.train.type, cfg=cfg))\n",
    "    trainer.train()\n",
    "\n",
    "config_path = os.path.join(data_folder_name, 't1_data', 'config.py')\n",
    "save_path = os.path.join(data_folder_name, 't1_data')\n",
    "weights = os.path.join(data_folder_name, 't1_data', 'model', 'model_best.pth')\n",
    "\n",
    "cfg = default_config_parser(str(config_path), {'save_path': str(save_path), 'weight': str(weights)})\n",
    "\n",
    "launch(\n",
    "    main_worker,\n",
    "    num_gpus_per_machine=1,\n",
    "    num_machines=1,\n",
    "    machine_rank=0,\n",
    "    dist_url='auto',\n",
    "    cfg=(cfg,),\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pointcept",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "orig_nbformat": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
