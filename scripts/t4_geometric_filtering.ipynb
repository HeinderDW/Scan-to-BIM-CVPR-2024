{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# T4 Combine Detection Results\n",
    "\n",
    "- import the t1 inferenced point clouds\n",
    "- import the t3 doors \n",
    "- export graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#IMPORT PACKAGES\n",
    "from rdflib import Graph, URIRef\n",
    "import os.path\n",
    "import importlib\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import xml.etree.ElementTree as ET\n",
    "import open3d as o3d\n",
    "import uuid    \n",
    "import pye57 \n",
    "import ifcopenshell\n",
    "import ifcopenshell.geom as geom\n",
    "import ifcopenshell.util\n",
    "from ifcopenshell.util.selector import Selector\n",
    "import multiprocessing\n",
    "import random as rd\n",
    "import pandas as pd\n",
    "# from tabulate import tabulate\n",
    "import cv2\n",
    "import laspy\n",
    "\n",
    "import geomapi\n",
    "from geomapi.nodes import *\n",
    "import geomapi.utils as ut\n",
    "from geomapi.utils import geometryutils as gmu\n",
    "import geomapi.tools as tl\n",
    "import geomapi.tools.progresstools as pt\n",
    "\n",
    "#import utils\n",
    "import context \n",
    "import utils as utl\n",
    "import utils.t1_utils as t1\n",
    "import utils.t2_utils as t2\n",
    "import utils.t4_utils as t4\n",
    "\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## INPUTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\u0094523\\OneDrive - KU Leuven\\2024-05 CVPR scan-to-BIM challenge\n"
     ]
    }
   ],
   "source": [
    "#paths\n",
    "path=Path(os.getcwd()).parents[2]\n",
    "\n",
    "print(path)\n",
    "input_folder=path/'data'/'t2'/'test' \n",
    "class_file=path/'data'/'_classes.json'\n",
    "output_folder=path/'data'/'t4'/ 'test'\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "#parameters\n",
    "resolution=0.05\n",
    "min_cluster_points=1000\n",
    "eps=0.5\n",
    "size=[12,12,100] #size wall boxes\n",
    "threshold_column_height=1.5#m\n",
    "threshold_wall_dim=0.5#m\n",
    "threshold_wall_verticallity=0.2# angle to horizontal\n",
    "threshold_door_dim=1.6#m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'classes': [{'name': 'Unassigned', 'id': 255, 'temp_id': 0, 'color': '#9da2ab'}, {'name': 'floors', 'id': 0, 'temp_id': 1, 'color': '#03c2fc'}, {'name': 'ceilings', 'id': 1, 'temp_id': 2, 'color': '#e81416'}, {'name': 'walls', 'id': 2, 'temp_id': 3, 'color': '#ffa500'}, {'name': 'columns', 'id': 3, 'temp_id': 4, 'color': '#faeb36'}, {'name': 'doors', 'id': 4, 'temp_id': 5, 'color': '#79c314'}, {'name': 'windows', 'id': 5, 'temp_id': 6, 'color': '#4b369d'}], 'default': 255, 'type': 'semantic_segmentation', 'format': 'kitti', 'created_with': {'name': 'Saiga', 'version': '1.0.1'}}\n"
     ]
    }
   ],
   "source": [
    "# Read the JSON file\n",
    "with open(class_file, 'r') as file:\n",
    "    json_data = json.load(file)\n",
    "\n",
    "# Create a dictionary\n",
    "class_dict = {\n",
    "    'classes': json_data['classes'],\n",
    "    'default': json_data['default'],\n",
    "    'type': json_data['type'],\n",
    "    'format': json_data['format'],\n",
    "    'created_with': json_data['created_with']\n",
    "}\n",
    "print(class_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CREATE INITIAL OBJECT PCDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "files=utl.get_list_of_files(input_folder, '.laz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing 08_ShortOffice_01_F1_small_pred...\n",
      "Function fit_planes took 3.1143 seconds to execute.\n",
      "floors : 4 clusters found\n",
      "Function fit_planes took 11.6154 seconds to execute.\n",
      "ceilings : 9 clusters found\n",
      "Function fit_planes took 7.7359 seconds to execute.\n",
      "Function fit_planes took 7.1171 seconds to execute.\n",
      "Function fit_planes took 4.0049 seconds to execute.\n",
      "Function fit_planes took 7.3100 seconds to execute.\n",
      "Function fit_planes took 6.9514 seconds to execute.\n",
      "Function fit_planes took 3.2288 seconds to execute.\n",
      "Function fit_planes took 2.3468 seconds to execute.\n",
      "Function fit_planes took 8.2539 seconds to execute.\n",
      "Function fit_planes took 1.6029 seconds to execute.\n",
      "Function fit_planes took 4.8709 seconds to execute.\n",
      "Function fit_planes took 3.6841 seconds to execute.\n",
      "Function fit_planes took 3.7587 seconds to execute.\n",
      "walls : 257 clusters found\n",
      "columns : 42 clusters found\n",
      "doors : 7 clusters found\n",
      "Created 319 PointCloudNodes created from 08_ShortOffice_01_F1_small_pred\n"
     ]
    }
   ],
   "source": [
    "for f in files[:1]:#, files_t2[:1], files_t3[:1]):\n",
    "    objectNodes=[]\n",
    "    \n",
    "    # check if las/pcd variable is already defined    \n",
    "    print(f'processing {ut.get_filename(f)}...')      \n",
    "    las = laspy.read(f) if 'las' not in globals() else las\n",
    "    pcd=gmu.las_to_pcd(las,getNormals=True) if 'pcd' not in globals() else pcd\n",
    "    \n",
    "    \n",
    "    #seperate initial objects\n",
    "    for c in class_dict['classes']:\n",
    "        \n",
    "        ###------------------------FLOORS CEILINGS--------------------------------------------\n",
    "        if c['id'] in [0,1]: #floors,ceilings CORRECT\n",
    "            idx=np.where((las['classes']==c['id']))[0]\n",
    "            class_pcd=pcd.select_by_index(idx)\n",
    "            \n",
    "            #retrieve objects from planar clusters\n",
    "            clustered_pcds,clustered_planes=t4.split_point_cloud_in_planar_clusters(class_pcd,\n",
    "                                                                                    sample_resolution=resolution,\n",
    "                                                                                    distance_threshold=0.05, \n",
    "                                                                                    min_inliers=1000,\n",
    "                                                                                    eps=0.5,\n",
    "                                                                                    min_cluster_points=200)\n",
    "            \n",
    "            for i,n in enumerate(clustered_pcds):\n",
    "                objectNodes.append(PointCloudNode(resource=n,\n",
    "                                            class_id=c['id'],\n",
    "                                            class_name=c['name'],\n",
    "                                            object_id=i+1+c['id']*100, #+1 because 0 is clutter\n",
    "                                            plane=clustered_planes[i],\n",
    "                                            color=ut.random_color(),\n",
    "                                            name=ut.get_filename(f)+'_'+c['name']+'_'+str(i+1+c['id']*100)))       \n",
    "            print( c['name'], f': {len(clustered_pcds)} clusters found')       \n",
    "        \n",
    "        ###------------------------WALLS--------------------------------------------\n",
    "        if c['id'] in [2]: \n",
    "            counter=0\n",
    "            idx=np.where((las['classes']==c['id']))[0]\n",
    "            class_pcd=pcd.select_by_index(idx)\n",
    "            \n",
    "            #split into boxes (otherwise you will get horizontal planes mostly)\n",
    "            min_bound=pcd.get_min_bound()\n",
    "            max_bound=pcd.get_max_bound()            \n",
    "            box=o3d.geometry.AxisAlignedBoundingBox(min_bound=np.array([min_bound[0]-5,min_bound[1]-5,min_bound[2]-5]),\n",
    "                                        max_bound=np.array([max_bound[0]+5,max_bound[1]+5,max_bound[2]+5]))\n",
    "            boxes,names=gmu.divide_box_in_boxes(box,size=size)\n",
    "            \n",
    "            # select indices per boxes\n",
    "            sub_pcds=[]\n",
    "            for box,name in zip(boxes,names):\n",
    "                idxLists=box.get_point_indices_within_bounding_box(class_pcd.points)\n",
    "                sub_pcd=class_pcd.select_by_index(idxLists)\n",
    "            \n",
    "                #retrieve objects from planar clusters\n",
    "                if len(np.asarray(sub_pcd.points))<min_cluster_points:\n",
    "                    continue\n",
    "                clustered_pcds,clustered_planes=t4.split_point_cloud_in_planar_clusters(sub_pcd,\n",
    "                                                                                    sample_resolution=0.03,\n",
    "                                                                                    distance_threshold=0.03, \n",
    "                                                                                    min_inliers=200,\n",
    "                                                                                    eps=0.5,\n",
    "                                                                                    min_cluster_points=200)\n",
    " \n",
    "                if len(clustered_pcds)!=0:\n",
    "                    for p,pl in zip(clustered_pcds,clustered_planes):\n",
    "                        counter+=1\n",
    "                        objectNodes.append(PointCloudNode(resource=p,\n",
    "                                                    class_id=c['id'],\n",
    "                                                    class_name=c['name'],\n",
    "                                                    object_id=c['id']*100+counter, \n",
    "                                                    plane=pl,\n",
    "                                                    color=ut.random_color(),\n",
    "                                                    name=ut.get_filename(f)+'_'+c['name']+'_'+str(c['id']*100+counter)))       \n",
    "            print( c['name'], f': {counter} clusters found')  \n",
    "            \n",
    "        # ###------------------------COLUMNS--------------------------------------------\n",
    "        if c['id'] in [3]:\n",
    "            idx = np.where((las['classes'] == c['id']))[0]\n",
    "            class_pcd=pcd.select_by_index(idx)\n",
    "            object_labels=las['objects'][idx]\n",
    "            \n",
    "            object_pcds=[]\n",
    "            for i in np.unique(object_labels): \n",
    "                if i==0:\n",
    "                    potential_object_pcds=t4.split_point_cloud_by_dbscan(class_pcd.select_by_index(np.where(object_labels==i)[0]),eps=eps,min_cluster_points=min_cluster_points)\n",
    "                    #retain only clusters with sufficient height\n",
    "                    object_pcds.extend([p for p in potential_object_pcds])\n",
    "                else:           \n",
    "                    object_pcds.append(class_pcd.select_by_index(np.where(object_labels==i)[0]))\n",
    "            \n",
    "            for i,p in enumerate(object_pcds):    \n",
    "                objectNodes.append(PointCloudNode(resource=p,\n",
    "                                            class_id=c['id'],\n",
    "                                            class_name=c['name'],\n",
    "                                            object_id=c['id']+i,\n",
    "                                            color=ut.random_color(),\n",
    "                                            name=ut.get_filename(f)+'_'+c['name']+'_'+str(c['id']*100+i)))\n",
    "            print( c['name'], f': {len(object_pcds)} clusters found')       \n",
    "            \n",
    "        # ###------------------------DOORS--------------------------------------------\n",
    "        if c['id'] in [4]: \n",
    "            idx = np.where((las['classes'] == c['id']))[0]\n",
    "            class_pcd=pcd.select_by_index(idx)\n",
    "            object_labels=las['objects'][idx]\n",
    "            \n",
    "            object_pcds=[]\n",
    "            for i in np.unique(object_labels): \n",
    "                if i==0:\n",
    "                    object_pcds.extend(t4.split_point_cloud_by_dbscan(class_pcd.select_by_index(np.where(object_labels==i)[0]),eps=eps,min_cluster_points=min_cluster_points))\n",
    "                else:           \n",
    "                    object_pcds.append(class_pcd.select_by_index(np.where(object_labels==i)[0]))\n",
    "            \n",
    "            for i,p in enumerate(object_pcds):    \n",
    "                objectNodes.append(PointCloudNode(resource=p,\n",
    "                                            class_id=c['id'],\n",
    "                                            class_name=c['name'],\n",
    "                                            object_id=c['id']+i,\n",
    "                                            color=ut.random_color(),\n",
    "                                            name=ut.get_filename(f)+'_'+c['name']+'_'+str(c['id']*100+i)))\n",
    "            print( c['name'], f': {len(object_pcds)} clusters found')      \n",
    "        else:\n",
    "            idx=np.where((las['classes']==c['id']))[0]\n",
    "            class_pcd=pcd.select_by_index(idx)\n",
    "            thrashNode=PointCloudNode(resource=pcd,\n",
    "                                            class_id=c['id'],\n",
    "                                            class_name=c['name'],\n",
    "                                            color=ut.random_color(),\n",
    "                                            name=ut.get_filename(f)+'_unassigned')\n",
    "\n",
    "    print(f'Created {len(objectNodes)} PointCloudNodes created from {ut.get_filename(f)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VISUALIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_e57Index': 0,\n",
       " 'pointCount': 14959,\n",
       " 'e57XmlPath': None,\n",
       " '_cartesianBounds': array([-2.28800000e+01, -1.35000000e+01,  9.39000000e+00,  1.91700000e+01,\n",
       "        -1.00000000e-02,  5.28571429e-02]),\n",
       " '_orientedBounds': array([[-2.00641522e+01,  2.22818819e+01,  4.63756496e-02],\n",
       "        [-1.12199082e+01,  1.50613484e+01,  5.91188445e-02],\n",
       "        [-2.52897033e+01,  1.58812512e+01,  5.27173734e-02],\n",
       "        [-2.00641253e+01,  2.22817896e+01, -2.45775967e-02],\n",
       "        [-1.64454323e+01,  8.66062540e+00, -5.49267805e-03],\n",
       "        [-2.52896764e+01,  1.58811589e+01, -1.82358730e-02],\n",
       "        [-1.12198813e+01,  1.50612561e+01, -1.18344018e-02],\n",
       "        [-1.64454592e+01,  8.66071767e+00,  6.54605683e-02]]),\n",
       " '_orientedBoundingBox': OrientedBoundingBox: center: (-18.2548, 15.4713, 0.0204415), extent: 11.4174, 8.26284, 0.0709533),\n",
       " '_subject': rdflib.term.URIRef('file:///08_ShortOffice_01_F1_small_pred_floors_2'),\n",
       " '_graph': None,\n",
       " '_graphPath': None,\n",
       " '_path': None,\n",
       " '_name': '08_ShortOffice_01_F1_small_pred_floors_2',\n",
       " '_timestamp': None,\n",
       " '_resource': PointCloud with 14959 points.,\n",
       " '_cartesianTransform': array([[ 1.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         -1.85291309e+01],\n",
       "        [ 0.00000000e+00,  1.00000000e+00,  0.00000000e+00,\n",
       "          1.55886523e+01],\n",
       "        [ 0.00000000e+00,  0.00000000e+00,  1.00000000e+00,\n",
       "          1.60661608e-02],\n",
       "        [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          1.00000000e+00]]),\n",
       " 'class_id': 0,\n",
       " 'class_name': 'floors',\n",
       " 'object_id': 2,\n",
       " 'plane': array([-3.93628552e-04, -5.59139325e-04,  9.99999766e-01, -3.76186822e-03]),\n",
       " 'color': array([0.01176471, 0.07843137, 0.54117647])}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{key:value for key, value in objectNodes[1].__dict__.items() if not key.startswith('__') and not callable(key)}              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcd_slice=t2.slice_point_cloud(pcd, -100, pcd.get_center()[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_pcd=gmu.join_geometries([p.resource.paint_uniform_color(ut.random_color()) for p in objectNodes])\n",
    "o3d.visualization.draw_geometries([joined_pcd,gmu.sample_geometry(class_pcd)[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PROCESS WALLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial number of nodes:238 \n",
      "Retained 153 merged column nodes.\n"
     ]
    }
   ],
   "source": [
    "# wall planes should be near vertical!\n",
    "wallNodes=[n for n in objectNodes if n.class_id == 2]\n",
    "print(f'Initial number of nodes:{len(wallNodes)} ')\n",
    "newWallNodes=[]\n",
    "\n",
    "for n in wallNodes:\n",
    "    dim=n.resource.get_oriented_bounding_box().extent\n",
    "    # check verticality and dimensions\n",
    "    if (np.abs(n.plane[2])<threshold_wall_verticallity) & (dim[0]>threshold_wall_dim) & (dim[1]>threshold_wall_dim):\n",
    "        newWallNodes.append(n)\n",
    "    else:\n",
    "        thrashNode.resource+=n.resource\n",
    "\n",
    "print(f'Retained {len(newWallNodes)} merged column nodes.')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# joined_pcd1=gmu.join_geometries([p.resource.paint_uniform_color([1,0,0]) for p in wallNodes if p not in newWallNodes])\n",
    "\n",
    "# o3d.visualization.draw_geometries([joined_pcd1,gmu.sample_geometry(class_pcd)[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PROCESS DOORS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial number of nodes:5 \n",
      "Retained 1 merged column nodes.\n"
     ]
    }
   ],
   "source": [
    "# wall planes should be near vertical!\n",
    "doorPcdNodes=[n for n in objectNodes if n.class_id == 4]\n",
    "print(f'Initial number of nodes:{len(doorPcdNodes)} ')\n",
    "newDoorPcdNodes=[]\n",
    "\n",
    "for n in doorPcdNodes:\n",
    "    dim=n.resource.get_oriented_bounding_box().extent\n",
    "    # check verticality and dimensions\n",
    "    if (dim[0]>threshold_door_dim) & (dim[1]>threshold_door_dim):\n",
    "        newDoorPcdNodes.append(n)\n",
    "    else:\n",
    "        thrashNode.resource+=n.resource\n",
    "\n",
    "print(f'Retained {len(newDoorPcdNodes)} merged column nodes.')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PROCESS COLUMNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial number of nodes:48 \n",
      "Retained 48 merged column nodes.\n"
     ]
    }
   ],
   "source": [
    "threshold_column_points=100\n",
    "threshold_clustering_distance=0.5\n",
    "threshold_column_height=1\n",
    "threshold_column_verticallity=0.2\n",
    "\n",
    "columnPcdNodes=[n for n in objectNodes if n.class_id == 3]\n",
    "print(f'Initial number of nodes:{len(columnPcdNodes)} ')\n",
    "\n",
    "for n in columnPcdNodes: \n",
    "    \n",
    "    #scrap horizontal columns\n",
    "    n.resource=n.resource.select_by_index(np.where(np.asarray(n.resource.normals)[:,2]<threshold_column_verticallity)[0])\n",
    "    n.get_oriented_bounding_box()\n",
    "    \n",
    "    if len(np.asarray(n.resource.points))<threshold_column_points or  (p.get_axis_aligned_bounding_box().max_bound[2]-p.get_axis_aligned_bounding_box().min_bound[2])>threshold_column_height:\n",
    "        columnPcdNodes.pop(n)\n",
    "        thrashNode.resource+=n.resource\n",
    "    else:\n",
    "        for m in columnPcdNodes:\n",
    "            if n!=m and len(np.asarray(n.resource.points))<len(np.asarray(m.resource.points)) and np.linalg.norm(n.cartesianTransform[0:3,3] - m.cartesianTransform[0:3,3]) < threshold_clustering_distance:\n",
    "                m.resource+=n.resource\n",
    "                columnPcdNodes.pop(n)\n",
    "                break\n",
    "print(f'Retained {len(columnPcdNodes)} merged column nodes.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_pcd=gmu.join_geometries([n.resource.paint_uniform_color(n.color) for n in columnPcdNodes if n.resource is not None])\n",
    "o3d.visualization.draw_geometries([joined_pcd])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OUTPUTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### export graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_pcd_nodes=[n for n in objectNodes if n.class_id in [0,1,2]]+doorPcdNodes+columnPcdNodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Graph identifier=Nbdce8cadde464f199ab7743101b6ca42 (<class 'rdflib.graph.Graph'>)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tl.nodes_to_graph(total_pcd_nodes,\n",
    "                graphPath=str(output_folder/f'{ut.get_filename(t1)}_pcdgraph.ttl'),\n",
    "                save=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### export point cloud\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PointCloud with 401102 points.\n"
     ]
    }
   ],
   "source": [
    "joined_pcd=gmu.join_geometries([n.resource for n  in total_pcd_nodes])\n",
    "print(joined_pcd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#obtain labels\n",
    "labels_segmentation=[]\n",
    "labels_objects=[]\n",
    "\n",
    "for i,n in enumerate(total_pcd_nodes):\n",
    "    length=len(np.asarray(n.resource.points))\n",
    "    labels_segmentation.extend(list(np.full(length,n.class_id)))\n",
    "    labels_objects.extend(list(np.full(length,n.object_id)))  \n",
    "\n",
    "labels_classes=np.array(labels_segmentation)\n",
    "labels_objects=np.array(labels_objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#interpolate labels\n",
    "indices,distances=gmu.compute_nearest_neighbors(np.asarray(las.xyz),np.asarray(joined_pcd.points))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_c=np.full((las.xyz.shape[0],1),255)\n",
    "labels_o=np.full((las.xyz.shape[0],1),0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3472028,)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inliers.shape\n",
    "outliers.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 401938 is out of bounds for axis 0 with size 401938",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[104], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m inliers\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mwhere(distances\u001b[38;5;241m<\u001b[39mresolution)[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m#modify the labels_c array with the labels_classes array based on the inliers\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m labels_c[inliers]\u001b[38;5;241m=\u001b[39m\u001b[43mlabels_classes\u001b[49m\u001b[43m[\u001b[49m\u001b[43minliers\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m      6\u001b[0m labels_o[inliers]\u001b[38;5;241m=\u001b[39mlabels_objects[indices]\n",
      "\u001b[1;31mIndexError\u001b[0m: index 401938 is out of bounds for axis 0 with size 401938"
     ]
    }
   ],
   "source": [
    "#inliers\n",
    "inliers=np.where(distances<resolution)[0]\n",
    "\n",
    "#modify the labels_c array with the labels_classes array based on the inliers\n",
    "labels_c[inliers]=labels_classes[inliers]\n",
    "labels_o[inliers]=labels_objects[indices]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#outliers\n",
    "outliers=np.where(distances>=resolution)[0]\n",
    "labels_c[outliers]=labels_classes[outliers]\n",
    "labels_o[outliers]=labels_objects[outliers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new las\n",
    "header = laspy.LasHeader(point_format=3, version=\"1.2\")\n",
    "las = laspy.LasData(header)\n",
    "las.xyz=np.asarray(total_pcd.points)\n",
    "las.red=(np.asarray(total_pcd.colors)[:,0]*65535).astype(np.uint16)\n",
    "las.green=(np.asarray(total_pcd.colors)[:,1]*65535).astype(np.uint16)\n",
    "las.blue=(np.asarray(total_pcd.colors)[:,2]*65535).astype(np.uint16)\n",
    "\n",
    "gmu.las_add_extra_dimensions(las,(labels_segmentation[:,0],labels_objects[:,0],),['classes','objects'],['uint8','uint16'])\n",
    "print(list(las.point_format.dimension_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "las.write(str(output_folder/f'{ut.get_filename(t1)}_t4.laz'))\n",
    "print(str(output_folder/f'{ut.get_filename(t1)}_t4.laz'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geomapi_installed",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
