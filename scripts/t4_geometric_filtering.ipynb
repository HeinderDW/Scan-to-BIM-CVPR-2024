{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# T4 Combine Detection Results\n",
    "\n",
    "- import the t1 inferenced point clouds\n",
    "- import the t3 doors \n",
    "- export graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#IMPORT PACKAGES\n",
    "from rdflib import Graph, URIRef\n",
    "import os.path\n",
    "import importlib\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import xml.etree.ElementTree as ET\n",
    "import open3d as o3d\n",
    "import uuid    \n",
    "import pye57 \n",
    "import ifcopenshell\n",
    "import ifcopenshell.geom as geom\n",
    "import ifcopenshell.util\n",
    "from ifcopenshell.util.selector import Selector\n",
    "import multiprocessing\n",
    "import random as rd\n",
    "import pandas as pd\n",
    "# from tabulate import tabulate\n",
    "import cv2\n",
    "import laspy\n",
    "\n",
    "import geomapi\n",
    "from geomapi.nodes import *\n",
    "import geomapi.utils as ut\n",
    "from geomapi.utils import geometryutils as gmu\n",
    "import geomapi.tools as tl\n",
    "import geomapi.tools.progresstools as pt\n",
    "\n",
    "#import utils\n",
    "import context \n",
    "import utils as utl\n",
    "import utils.t1_utils as t1\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## INPUTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\u0094523\\OneDrive - KU Leuven\\2024-05 CVPR scan-to-BIM challenge\n"
     ]
    }
   ],
   "source": [
    "#paths\n",
    "path=Path(os.getcwd()).parents[2]\n",
    "print(path)\n",
    "input_folder_t1=path/'data'/'t1'/'input' # this should become t1_results\n",
    "input_folder_t1_temp_graph=path/'data'/'t0'/'results' # this should become t1_results\n",
    "input_folder_t2=path/'data'/'t2'\n",
    "input_folder_t3=path/'data'/'t3'\n",
    "class_file=path/'data'/'_classes.json'\n",
    "\n",
    "output_folder=path/'data'/'t4'\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "#parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'classes': [{'name': 'Unassigned', 'id': 255, 'temp_id': 0, 'color': '#9da2ab'}, {'name': 'floors', 'id': 0, 'temp_id': 1, 'color': '#03c2fc'}, {'name': 'ceilings', 'id': 1, 'temp_id': 2, 'color': '#e81416'}, {'name': 'walls', 'id': 2, 'temp_id': 3, 'color': '#ffa500'}, {'name': 'columns', 'id': 3, 'temp_id': 4, 'color': '#faeb36'}, {'name': 'doors', 'id': 4, 'temp_id': 5, 'color': '#79c314'}, {'name': 'windows', 'id': 5, 'temp_id': 6, 'color': '#4b369d'}], 'default': 255, 'type': 'semantic_segmentation', 'format': 'kitti', 'created_with': {'name': 'Saiga', 'version': '1.0.1'}}\n"
     ]
    }
   ],
   "source": [
    "# Read the JSON file\n",
    "with open(class_file, 'r') as file:\n",
    "    json_data = json.load(file)\n",
    "\n",
    "# Create a dictionary\n",
    "class_dict = {\n",
    "    'classes': json_data['classes'],\n",
    "    'default': json_data['default'],\n",
    "    'type': json_data['type'],\n",
    "    'format': json_data['format'],\n",
    "    'created_with': json_data['created_with']\n",
    "}\n",
    "print(class_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import PCD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "files=utl.get_list_of_files(input_folder_t1, '.laz')\n",
    "files.extend(utl.get_list_of_files(input_folder_t2, '.laz'))\n",
    "files.extend(utl.get_list_of_files(input_folder_t3, '.laz'))\n",
    "\n",
    "# for each file in files\n",
    "print(len(files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing c:/Users/u0094523/OneDrive - KU Leuven/2024-05 CVPR scan-to-BIM challenge/data/t1/input/05_MedOffice_01_F2.laz\n",
      "loaded 44936482 points\n",
      "created 231 from 05_MedOffice_01_F2\n"
     ]
    }
   ],
   "source": [
    "for f in files[0:1]:\n",
    "    pcdNodes=[]\n",
    "    # import pcd\n",
    "    print(f'processing {f}')\n",
    "    # laz  = laspy.read(f) #enable this\n",
    "    print(f'loaded {len(laz.xyz)} points')\n",
    "\n",
    "    #seperate classes\n",
    "    for c in class_dict['classes']:\n",
    "        idx=np.where((laz['classes']==c['id']))\n",
    "        objects_ids=laz['objects'][idx]        \n",
    "        class_points=laz.xyz[idx]\n",
    "        \n",
    "        #separate objects\n",
    "        for u in np.unique(objects_ids):\n",
    "            idx=np.where(objects_ids==u)\n",
    "            object_pcd=o3d.geometry.PointCloud()\n",
    "            object_pcd.points=o3d.utility.Vector3dVector(class_points[idx])\n",
    "            pcdNode=PointCloudNode(resource=object_pcd,\n",
    "                                    name=ut.get_filename(f)+'_'+c['name']+'_'+str(u),\n",
    "                                    class_name=c['name'],\n",
    "                                    class_id=c['id'],\n",
    "                                    object_id=u,\n",
    "                                    color=ut.random_color(),\n",
    "                                    derived_from=ut.get_filename(f))\n",
    "            pcdNode.get_oriented_bounding_box()\n",
    "            pcdNodes.append(pcdNode)\n",
    "    # del laz\n",
    "    # del class_points\n",
    "    print(f'created {len(pcdNodes)} from {ut.get_filename(f)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_pcd=gmu.join_geometries([n.resource.paint_uniform_color(n.color) for n in pcdNodes if n.resource is not None])\n",
    "o3d.visualization.draw_geometries([joined_pcd])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import graph (temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# files=utl.get_list_of_files(input_folder_t1_temp_graph, '.ttl')\n",
    "\n",
    "# for f in files[0:1]:\n",
    "#     meshNodes=[]\n",
    "#     graph=Graph().parse(f)\n",
    "#     nodes=tl.graph_to_nodes(graph)\n",
    "#     for c in class_dict['classes']:\n",
    "#         meshNodes.append([n for n in nodes if n.class_id==c['id']])\n",
    "#         print(f'{len(meshNodes[-1])} {c[\"name\"]} detected!')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OUTPUTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### export graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Graph identifier=N2f126350df9347f89c42a09fcf3123e9 (<class 'rdflib.graph.Graph'>)>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tl.nodes_to_graph(pcdNodes,\n",
    "                graphPath=str(output_folder/f'{ut.get_filename(f)}_graph.ttl'),\n",
    "                save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:/Users/u0094523/OneDrive - KU Leuven/2024-05 CVPR scan-to-BIM challenge/data/t1/train/05_MedOffice_01_F2_small_0_1_0.pth\n",
      "dict_keys(['coord', 'color', 'normal', 'scene_id', 'semantic_gt'])\n",
      "c:/Users/u0094523/OneDrive - KU Leuven/2024-05 CVPR scan-to-BIM challenge/data/t1/train/05_MedOffice_01_F2_small_1_1_0.pth\n",
      "dict_keys(['coord', 'color', 'normal', 'scene_id', 'semantic_gt'])\n",
      "c:/Users/u0094523/OneDrive - KU Leuven/2024-05 CVPR scan-to-BIM challenge/data/t1/train/19_MedOffice_07_F4_small_0_0_0.pth\n",
      "dict_keys(['coord', 'color', 'normal', 'scene_id', 'semantic_gt'])\n",
      "c:/Users/u0094523/OneDrive - KU Leuven/2024-05 CVPR scan-to-BIM challenge/data/t1/train/19_MedOffice_07_F4_small_0_1_0.pth\n",
      "dict_keys(['coord', 'color', 'normal', 'scene_id', 'semantic_gt'])\n",
      "c:/Users/u0094523/OneDrive - KU Leuven/2024-05 CVPR scan-to-BIM challenge/data/t1/train/19_MedOffice_07_F4_small_1_0_0.pth\n",
      "dict_keys(['coord', 'color', 'normal', 'scene_id', 'semantic_gt'])\n",
      "c:/Users/u0094523/OneDrive - KU Leuven/2024-05 CVPR scan-to-BIM challenge/data/t1/train/19_MedOffice_07_F4_small_1_1_0.pth\n",
      "dict_keys(['coord', 'color', 'normal', 'scene_id', 'semantic_gt'])\n",
      "c:/Users/u0094523/OneDrive - KU Leuven/2024-05 CVPR scan-to-BIM challenge/data/t1/train/19_MedOffice_07_F4_small_2_0_0.pth\n",
      "dict_keys(['coord', 'color', 'normal', 'scene_id', 'semantic_gt'])\n",
      "c:/Users/u0094523/OneDrive - KU Leuven/2024-05 CVPR scan-to-BIM challenge/data/t1/train/32_ShortOffice_05_F1_small_0_1_0.pth\n",
      "dict_keys(['coord', 'color', 'normal', 'scene_id', 'semantic_gt'])\n",
      "c:/Users/u0094523/OneDrive - KU Leuven/2024-05 CVPR scan-to-BIM challenge/data/t1/train/32_ShortOffice_05_F1_small_1_0_0.pth\n",
      "dict_keys(['coord', 'color', 'normal', 'scene_id', 'semantic_gt'])\n",
      "c:/Users/u0094523/OneDrive - KU Leuven/2024-05 CVPR scan-to-BIM challenge/data/t1/train/32_ShortOffice_05_F1_small_1_1_0.pth\n",
      "dict_keys(['coord', 'color', 'normal', 'scene_id', 'semantic_gt'])\n",
      "c:/Users/u0094523/OneDrive - KU Leuven/2024-05 CVPR scan-to-BIM challenge/data/t1/train/33_SmallBuilding_03_F1_small_0_1_0.pth\n",
      "dict_keys(['coord', 'color', 'normal', 'scene_id', 'semantic_gt'])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "input_folder=path/'data'/'t1'/'train' # this should become t1_results\n",
    "output_folder=path/'data'/'t7'/'inputs'\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "files=utl.get_list_of_files(input_folder, '.pth')\n",
    "pcds=[]\n",
    "for f in files:\n",
    "    print(f)\n",
    "    #load pth file\n",
    "    data=torch.load(f)\n",
    "    print(data.keys())\n",
    "    #create a point cloud from the coord and color\n",
    "    pcd=o3d.geometry.PointCloud()\n",
    "    pcd.points=o3d.utility.Vector3dVector(data['coord'])\n",
    "    pcd.colors=o3d.utility.Vector3dVector(data['color'])\n",
    "    #get semantic_gt\n",
    "    labels=data['semantic_gt']\n",
    "    \n",
    "    # get filename\n",
    "    name=ut.get_filename(f)\n",
    "    \n",
    "    #create las file\n",
    "    header = laspy.LasHeader(point_format=3, version=\"1.2\")\n",
    "    header.add_extra_dim(laspy.ExtraBytesParams(name=\"classes\", type=np.int32))\n",
    "\n",
    "    las = laspy.LasData(header)\n",
    "    las.header.offset = [0, 0, 0]\n",
    "    las.header.scale = [0.01, 0.01, 0.01]\n",
    "    las.header.min = [0, 0, 0]\n",
    "    las.header.max = [1, 1, 1]\n",
    "    las.x = data['coord'][:,0]\n",
    "    las.y = data['coord'][:,1]\n",
    "    las.z = data['coord'][:,2]\n",
    "    las.red=data['color'][:,0]\n",
    "    las.green=data['color'][:,1]\n",
    "    las.blue=data['color'][:,2]\n",
    "    las.classes=labels\n",
    "    # gmu.las_add_extra_dimensions(las,(labels),['classes'],['uint8'])\n",
    "    las.write(f'{output_folder}/{name}.laz')\n",
    "\n",
    "    #visualize the point cloud\n",
    "    # pcds.append(PointCloudNode(resource=pcd,color=ut.random_color(),name=ut.get_filename(f)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(np.asarray(pcd.colors)[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PointCloud with 20000000 points., PointCloud with 20000000 points., PointCloud with 4936482 points.]\n"
     ]
    }
   ],
   "source": [
    "print([n.resource for n in pcdNodes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_pcd=gmu.join_geometries([n.resource.paint_uniform_color(ut.random_color()) for n in pcdNodes if n.resource is not None])\n",
    "\n",
    "o3d.visualization.draw_geometries([joined_pcd])\n",
    "# o3d.visualization.draw_geometries([pcdNodes[0].resource])\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geomapi_installed",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
