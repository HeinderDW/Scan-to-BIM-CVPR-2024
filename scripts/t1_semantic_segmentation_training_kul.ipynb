{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# T1 SEMANTIC SEGMENTATION TRAINING\n",
    "\n",
    "Small example on how to train Pointcept for semantic segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/mbassier/code/Scan-to-BIM-CVPR-2024/scripts/thirdparty/pointcept', '/home/mbassier/code/Scan-to-BIM-CVPR-2024/scripts/scripts', '/home/mbassier/code/Scan-to-BIM-CVPR-2024/scripts', '/home/mbassier/code/Scan-to-BIM-CVPR-2024/scripts', '/home/mbassier/.conda/envs/pointcept/lib/python310.zip', '/home/mbassier/.conda/envs/pointcept/lib/python3.10', '/home/mbassier/.conda/envs/pointcept/lib/python3.10/lib-dynload', '', '/home/mbassier/.local/lib/python3.10/site-packages', '/home/mbassier/.conda/envs/pointcept/lib/python3.10/site-packages', '/home/mbassier/.conda/envs/pointcept/lib/python3.10/site-packages/pointops-1.0-py3.10-linux-x86_64.egg', '/home/mbassier/.conda/envs/pointcept/lib/python3.10/site-packages/pointgroup_ops-0.0.0-py3.10-linux-x86_64.egg']\n",
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "#IMPORT PACKAGES\n",
    "from pathlib import Path\n",
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, os.path.abspath(os.path.join('.')))\n",
    "sys.path.insert(0, os.path.abspath(os.path.join('scripts')))\n",
    "sys.path.insert(0, os.path.abspath(os.path.join('thirdparty', 'pointcept')))\n",
    "print(sys.path)\n",
    "import numpy as np\n",
    "import laspy\n",
    "import geomapi\n",
    "from geomapi.utils import geometryutils as gmu\n",
    "# import geomapi.utils as ut\n",
    "import torch\n",
    "\n",
    "import context \n",
    "import utils.t1_utils as t1\n",
    "import utils as ut\n",
    "\n",
    "# #MULTIPROCESSING -> didn't help setting this to spawn\n",
    "# import multiprocessing as mp\n",
    "# mp.set_start_method('spawn')  # or 'forkserver'\n",
    "\n",
    "\n",
    "#POINTCEPT\n",
    "from pointcept.engines.defaults import (\n",
    "    default_argument_parser,\n",
    "    default_config_parser,\n",
    "    default_setup,\n",
    ")\n",
    "from pointcept.engines.train import TRAINERS\n",
    "from pointcept.engines.launch import launch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()  # Clear unused memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tensorboard --logdir=/home/mbassier/code/Scan-to-BIM-CVPR-2024/data/t1_data_test/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## INPUT DATA CONVERSION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create config file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root= Path(os.getcwd()).parents[0]/'data'/'t1'\n",
    "\n",
    "#PREPROCESSING\n",
    "input_folder = data_root/'input'\n",
    "training_folder = data_root/'train'\n",
    "validation_folder = data_root/'val'\n",
    "\n",
    "#TRAINING\n",
    "config_path = data_root/'config.py' #Path(os.getcwd())/'data'/'t1_data'/'config.py'\n",
    "# save_path = data_root #Path(os.getcwd())/'data'/'t1_data'\n",
    "# weights =  #Path(os.getcwd())/'data'/'t1_data'/'model'/'model_best.pth'\n",
    "\n",
    "\n",
    "cfg = default_config_parser(str(config_path), {'save_path': str(data_root), \n",
    "                                               'weight': str(data_root/'model'/'model_best.pth'),\n",
    "                                               'data_root': str(data_root),})\n",
    "# cfg = default_config_parser(str(config_path), {})\n",
    "# cfg['data_root'] = f'({str(data_root)}, )'\n",
    "cfg['data']['train']['data_root'] = str(data_root)\n",
    "cfg['data']['val']['data_root'] = str(data_root)\n",
    "cfg['data']['test']['data_root'] = str(data_root)\n",
    "cfg['data']['names']=['floors', 'ceiling', 'wall', 'column', 'door','unassigned'] \n",
    "cfg['data']['labels']=[0,1,2,3,4,255] \n",
    "cfg['data']['num_classes']=6\n",
    "cfg['data']['ignore_index']=-1\n",
    "cfg['num_worker']=1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing of input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # file=[n for n in ut.get_list_of_files(input_folder, '.laz') if 'normals' in n][0]\n",
    "# las = laspy.read('/home/mbassier/code/Scan-to-BIM-CVPR-2024/data/t1/input/05_MedOffice_01_F2_pcdFLtrain.laz')\n",
    "\n",
    "# print(list(las.point_format.dimension_names))\n",
    "# print(np.unique(las['classes']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing /home/mbassier/code/Scan-to-BIM-CVPR-2024/data/t1/input/05_MedOffice_01_F2_pcdFLtrain.laz ...\n",
      "Function handle_process took 117.3973 seconds to execute.\n",
      "processing /home/mbassier/code/Scan-to-BIM-CVPR-2024/data/t1/input/05_MedOffice_01_F2_pcdFLval.laz ...\n",
      "Function handle_process took 135.6447 seconds to execute.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_folder=cfg['data']['train']['data_root']\n",
    "validation_folder=cfg['data']['val']['data_root']\n",
    "\n",
    "os.makedirs(training_folder, exist_ok=True)\n",
    "os.makedirs(validation_folder, exist_ok=True)\n",
    "\n",
    "[t1.handle_process(p, training_folder,cfg) for p in ut.get_list_of_files(input_folder, ext=\".laz\") if \"train\" in p]\n",
    "[t1.handle_process(p, validation_folder,cfg) for p in ut.get_list_of_files(input_folder, ext=\".laz\") if \"val\" in p]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRAINING\n",
    "\n",
    "Training using Point Transformer V3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/home/mbassier/.conda/envs/pointcept/lib/python3.10/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/home/mbassier/.conda/envs/pointcept/lib/python3.10/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "AttributeError: Can't get attribute 'main_worker' on <module '__main__' (built-in)>\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/home/mbassier/.conda/envs/pointcept/lib/python3.10/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/home/mbassier/.conda/envs/pointcept/lib/python3.10/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "AttributeError: Can't get attribute 'main_worker' on <module '__main__' (built-in)>\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/home/mbassier/.conda/envs/pointcept/lib/python3.10/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/home/mbassier/.conda/envs/pointcept/lib/python3.10/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "AttributeError: Can't get attribute 'main_worker' on <module '__main__' (built-in)>\n"
     ]
    },
    {
     "ename": "ProcessExitedException",
     "evalue": "process 1 terminated with exit code 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mProcessExitedException\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m     trainer \u001b[38;5;241m=\u001b[39m TRAINERS\u001b[38;5;241m.\u001b[39mbuild(\u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39mcfg\u001b[38;5;241m.\u001b[39mtrain\u001b[38;5;241m.\u001b[39mtype, cfg\u001b[38;5;241m=\u001b[39mcfg))\n\u001b[1;32m      4\u001b[0m     trainer\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m----> 6\u001b[0m \u001b[43mlaunch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmain_worker\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_gpus_per_machine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# these seems to be a proble with the multiprocessing -> first check spawn vs forkserver methods (we now use spawn)\u001b[39;49;00m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_machines\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmachine_rank\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdist_url\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mauto\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/code/Scan-to-BIM-CVPR-2024/scripts/../thirdparty/pointcept/pointcept/engines/launch.py:74\u001b[0m, in \u001b[0;36mlaunch\u001b[0;34m(main_func, num_gpus_per_machine, num_machines, machine_rank, dist_url, cfg, timeout)\u001b[0m\n\u001b[1;32m     69\u001b[0m         logger \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mgetLogger(\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m     70\u001b[0m         logger\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[1;32m     71\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfile:// is not a reliable init_method in multi-machine jobs. Prefer tcp://\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     72\u001b[0m         )\n\u001b[0;32m---> 74\u001b[0m     \u001b[43mmp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mspawn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_distributed_worker\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnprocs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_gpus_per_machine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmain_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     79\u001b[0m \u001b[43m            \u001b[49m\u001b[43mworld_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnum_gpus_per_machine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     81\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmachine_rank\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdist_url\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     83\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     84\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdaemon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     87\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     89\u001b[0m     main_func(\u001b[38;5;241m*\u001b[39mcfg)\n",
      "File \u001b[0;32m~/.conda/envs/pointcept/lib/python3.10/site-packages/torch/multiprocessing/spawn.py:241\u001b[0m, in \u001b[0;36mspawn\u001b[0;34m(fn, args, nprocs, join, daemon, start_method)\u001b[0m\n\u001b[1;32m    235\u001b[0m     msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    236\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis method only supports start_method=spawn (got: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m).\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    237\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTo use a different start_method use:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    238\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m torch.multiprocessing.start_processes(...)\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m start_method\n\u001b[1;32m    239\u001b[0m     )\n\u001b[1;32m    240\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(msg)\n\u001b[0;32m--> 241\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mstart_processes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnprocs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdaemon\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mspawn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/pointcept/lib/python3.10/site-packages/torch/multiprocessing/spawn.py:197\u001b[0m, in \u001b[0;36mstart_processes\u001b[0;34m(fn, args, nprocs, join, daemon, start_method)\u001b[0m\n\u001b[1;32m    194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m context\n\u001b[1;32m    196\u001b[0m \u001b[38;5;66;03m# Loop on join until it returns True or raises an exception.\u001b[39;00m\n\u001b[0;32m--> 197\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/pointcept/lib/python3.10/site-packages/torch/multiprocessing/spawn.py:148\u001b[0m, in \u001b[0;36mProcessContext.join\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ProcessExitedException(\n\u001b[1;32m    141\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprocess \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m terminated with signal \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (error_index, name),\n\u001b[1;32m    142\u001b[0m             error_index\u001b[38;5;241m=\u001b[39merror_index,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    145\u001b[0m             signal_name\u001b[38;5;241m=\u001b[39mname,\n\u001b[1;32m    146\u001b[0m         )\n\u001b[1;32m    147\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 148\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ProcessExitedException(\n\u001b[1;32m    149\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprocess \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m terminated with exit code \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (error_index, exitcode),\n\u001b[1;32m    150\u001b[0m             error_index\u001b[38;5;241m=\u001b[39merror_index,\n\u001b[1;32m    151\u001b[0m             error_pid\u001b[38;5;241m=\u001b[39mfailed_process\u001b[38;5;241m.\u001b[39mpid,\n\u001b[1;32m    152\u001b[0m             exit_code\u001b[38;5;241m=\u001b[39mexitcode,\n\u001b[1;32m    153\u001b[0m         )\n\u001b[1;32m    155\u001b[0m original_trace \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merror_queues[error_index]\u001b[38;5;241m.\u001b[39mget()\n\u001b[1;32m    156\u001b[0m msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m-- Process \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m terminated with the following error:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m error_index\n",
      "\u001b[0;31mProcessExitedException\u001b[0m: process 1 terminated with exit code 1"
     ]
    }
   ],
   "source": [
    "\n",
    "def main_worker(cfg):\n",
    "    cfg = default_setup(cfg)\n",
    "    trainer = TRAINERS.build(dict(type=cfg.train.type, cfg=cfg))\n",
    "    trainer.train()\n",
    "\n",
    "launch(\n",
    "    main_worker,\n",
    "    num_gpus_per_machine=1, # these seems to be a proble with the multiprocessing -> first check spawn vs forkserver methods (we now use spawn, didn't resolve anything)\n",
    "    num_machines=1,\n",
    "    machine_rank=0,\n",
    "    dist_url='auto',\n",
    "    cfg=(cfg,),\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pointcept",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "orig_nbformat": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
