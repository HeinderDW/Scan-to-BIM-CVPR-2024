{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# T5. REFERENCE LEVELS\n",
    "\n",
    "In this notebook, we extract the reference levels from the t1_semantic segmentation/ t2_instance segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORT PACKAGES\n",
    "import os.path\n",
    "import importlib\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import open3d as o3d\n",
    "from rdflib import Graph, URIRef, Literal, Namespace\n",
    "\n",
    "# from tabulate import tabulate\n",
    "import laspy\n",
    "import json\n",
    "from scipy.spatial.transform import Rotation   \n",
    "import copy\n",
    "\n",
    "import geomapi\n",
    "from geomapi.nodes import *\n",
    "import geomapi.utils as ut\n",
    "from geomapi.utils import geometryutils as gmu\n",
    "import geomapi.tools as tl\n",
    "import geomapi.tools.progresstools as pt\n",
    "\n",
    "#import utils\n",
    "import context \n",
    "import utils as utl\n",
    "import utils.t5_utils as t5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## INPUTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\u0094523\\OneDrive - KU Leuven\\2024-05 CVPR scan-to-BIM challenge\n"
     ]
    }
   ],
   "source": [
    "#paths\n",
    "path=Path(os.getcwd()).parents[2] # On Onedrive this is 2, on GPU server this is 0\n",
    "\n",
    "print(path)\n",
    "# input_folder=path/'data'/'t4'/'test' \n",
    "input_folder=path/'data'/'t1'/'train' \n",
    "\n",
    "class_file=path/'data'/'_classes.json'\n",
    "# output_folder=path/'data'/'t5'/ 'test'\n",
    "output_folder=path/'data'/'t5'/ 'train'\n",
    "\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "#parameters\n",
    "threshold_horizontal_clustering=100#m\n",
    "threshold_vertical_clustering=0.5#m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'classes': [{'name': 'unassigned', 'id': 255, 'temp_id': 0, 'color': '#9da2ab'}, {'name': 'floors', 'id': 0, 'temp_id': 1, 'color': '#03c2fc'}, {'name': 'ceilings', 'id': 1, 'temp_id': 2, 'color': '#e81416'}, {'name': 'walls', 'id': 2, 'temp_id': 3, 'color': '#ffa500'}, {'name': 'columns', 'id': 3, 'temp_id': 4, 'color': '#faeb36'}, {'name': 'doors', 'id': 4, 'temp_id': 5, 'color': '#79c314'}], 'default': 255, 'type': 'semantic_segmentation', 'format': 'kitti', 'created_with': {'name': 'Saiga', 'version': '1.0.1'}}\n"
     ]
    }
   ],
   "source": [
    "# Read the JSON file\n",
    "with open(class_file, 'r') as file:\n",
    "    json_data = json.load(file)\n",
    "\n",
    "# Create a dictionary\n",
    "class_dict = {\n",
    "    'classes': json_data['classes'],\n",
    "    'default': json_data['default'],\n",
    "    'type': json_data['type'],\n",
    "    'format': json_data['format'],\n",
    "    'created_with': json_data['created_with']\n",
    "}\n",
    "print(class_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PROCESS LEVELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\u0094523\\OneDrive - KU Leuven\\2024-05 CVPR scan-to-BIM challenge\\data\\t1\\train\\05_MedOffice_01_F2_small1.ttl\n",
      "processing 05_MedOffice_01_F2_small1 ...\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MeshNode' object has no attribute 'object_id'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 24\u001b[0m\n\u001b[0;32m     22\u001b[0m         indices\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mwhere(object_labels\u001b[38;5;241m==\u001b[39mj)[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     23\u001b[0m         object_pcd\u001b[38;5;241m=\u001b[39mclass_pcd\u001b[38;5;241m.\u001b[39mselect_by_index(indices)\n\u001b[1;32m---> 24\u001b[0m         pcdNode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpcdNodes\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobject_id\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mj\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m         pcdNode\u001b[38;5;241m.\u001b[39mresource\u001b[38;5;241m=\u001b[39mobject_pcd \u001b[38;5;28;01mif\u001b[39;00m pcdNode \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(pcdNodes)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Nodes found\u001b[39m\u001b[38;5;124m'\u001b[39m)     \n",
      "Cell \u001b[1;32mIn[14], line 24\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     22\u001b[0m         indices\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mwhere(object_labels\u001b[38;5;241m==\u001b[39mj)[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     23\u001b[0m         object_pcd\u001b[38;5;241m=\u001b[39mclass_pcd\u001b[38;5;241m.\u001b[39mselect_by_index(indices)\n\u001b[1;32m---> 24\u001b[0m         pcdNode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mnext\u001b[39m((x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m pcdNodes \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobject_id\u001b[49m \u001b[38;5;241m==\u001b[39m j), \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m     25\u001b[0m         pcdNode\u001b[38;5;241m.\u001b[39mresource\u001b[38;5;241m=\u001b[39mobject_pcd \u001b[38;5;28;01mif\u001b[39;00m pcdNode \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(pcdNodes)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Nodes found\u001b[39m\u001b[38;5;124m'\u001b[39m)     \n",
      "\u001b[1;31mAttributeError\u001b[0m: 'MeshNode' object has no attribute 'object_id'"
     ]
    }
   ],
   "source": [
    "files=utl.get_list_of_files(input_folder,'.laz')\n",
    "\n",
    "for f in files: \n",
    "    \n",
    "    #import graph\n",
    "    f_g=Path(f).with_suffix('.ttl')\n",
    "    print(f_g)\n",
    "    pcdNodes=tl.graph_path_to_nodes(graphPath=str(f_g))\n",
    "    \n",
    "    #import pcd and check if las/pcd variable is already defined    \n",
    "    print(f'processing {ut.get_filename(f)} ...')      \n",
    "    las = laspy.read(f) #if 'las' not in globals() else las\n",
    "    pcd=gmu.las_to_pcd(las) #if 'pcd' not in globals() else pcd # this is the slowest step\n",
    "        \n",
    "    #match pcd to nodes\n",
    "    for c in class_dict['classes']:\n",
    "        idx=np.where((las['classes']==c['id']))[0]\n",
    "        class_pcd=pcd.select_by_index(idx)\n",
    "        object_labels=las['objects'][idx]\n",
    "        \n",
    "        for j in np.unique(object_labels):\n",
    "            indices=np.where(object_labels==j)[0]\n",
    "            object_pcd=class_pcd.select_by_index(indices)\n",
    "            pcdNode=next((x for x in pcdNodes if x.object_id == j), None)\n",
    "            pcdNode.resource=object_pcd if pcdNode is not None else None\n",
    "            \n",
    "    print(f'{len(pcdNodes)} Nodes found')     \n",
    "    \n",
    "    #retrieve levelNodes\n",
    "    floorNodes=[n for n in pcdNodes if n.class_id ==0]\n",
    "    ceilingNodes=[n for n in pcdNodes if n.class_id ==1]    \n",
    "    print(f'{len(floorNodes)} floor nodes and {len(ceilingNodes)} ceiling nodes found')\n",
    "    levelNodes=t5.create_level_nodes((floorNodes+ceilingNodes),threshold_horizontal_clustering=threshold_horizontal_clustering,threshold_vertical_clustering=threshold_vertical_clustering)\n",
    "    print(f'{len(levelNodes)} levels created at heights {[n.height for n in levelNodes]}')      \n",
    "    \n",
    "    #write this information to the 3D detection json\n",
    "    json_data=t5.levels_to_json(levelNodes,f)\n",
    "    with open(os.path.join(output_folder,f'{ut.get_filename(f)}_levels.json'), 'w') as file:\n",
    "        json.dump(json_data, file, indent=4)\n",
    "    print(\"JSON data written to file:\", os.path.join(output_folder,f'{ut.get_filename(f)}_levels.json') )\n",
    "    \n",
    "    #write geometries to file\n",
    "    joined_references=gmu.join_geometries([n.plane for n in levelNodes])\n",
    "    success=o3d.io.write_triangle_mesh(filename=os.path.join(output_folder,f'{ut.get_filename(f)}_levels.obj'), mesh=joined_references) \n",
    "    print(f' Saving joint references : {success}')\n",
    "    \n",
    "    #write graph to file\n",
    "    graphPath=os.path.join(output_folder,f'{ut.get_filename(f)}_levels.ttl')\n",
    "    graph=tl.nodes_to_graph(levelNodes,graphPath=graphPath,save=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VISUALIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# joined_pcd=gmu.join_geometries([p.resource.paint_uniform_color(ut.random_color()) for p in objectNodes])\n",
    "# o3d.visualization.draw_geometries([joined_pcd,gmu.sample_geometry(class_pcd)[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# joined_pcd=gmu.join_geometries([n.plane.paint_uniform_color(ut.random_color()) for n in levelNodes if n.resource is not None])\n",
    "# joined_pcd2=gmu.join_geometries([n.resource.paint_uniform_color(ut.random_color()) for n in (floorNodes+ceilingNodes) if n.resource is not None])\n",
    "# o3d.visualization.draw_geometries([joined_pcd2]+[n.box for n in levelNodes if n.resource is not None])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geomapi_installed",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
