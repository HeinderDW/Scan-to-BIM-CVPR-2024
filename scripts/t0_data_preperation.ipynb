{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# T0. PREPARE POINT CLOUDS\n",
    "\n",
    "Import and prepare point clouds for semantic segmentation, instance segmentation, etc.\n",
    "To run these scripts, create a python 3.10 environment & install geomapi (numpy, opend3d, ifcopenshell, trimesh, ...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORT PACKAGES\n",
    "from rdflib import Graph, URIRef\n",
    "import os.path\n",
    "import importlib\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import xml.etree.ElementTree as ET\n",
    "import open3d as o3d\n",
    "import uuid    \n",
    "import pye57 \n",
    "import ifcopenshell\n",
    "import ifcopenshell.geom as geom\n",
    "import ifcopenshell.util\n",
    "from ifcopenshell.util.selector import Selector\n",
    "import multiprocessing\n",
    "import random as rd\n",
    "import pandas as pd\n",
    "# from tabulate import tabulate\n",
    "import cv2\n",
    "import laspy\n",
    "import time\n",
    "import json\n",
    "from scipy.spatial.transform import Rotation   \n",
    "import copy\n",
    "from datetime import datetime\n",
    "\n",
    "import geomapi\n",
    "from geomapi.nodes import *\n",
    "import geomapi.utils as ut\n",
    "from geomapi.utils import geometryutils as gmu\n",
    "from geomapi.tools import progresstools as pt\n",
    "\n",
    "import geomapi.tools as tl\n",
    "\n",
    "#import utils\n",
    "from context import utils\n",
    "import utils as utl\n",
    "import utils.t1_utils as t1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INPUTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "name='e003'\n",
    "\n",
    "path=Path(os.getcwd()).parents[2]/'data'\n",
    "pcd_input_path=os.path.join(path,f'{name}.laz')\n",
    "pcd_input_folder=os.path.join(path,'connected_components') \n",
    "class_file=path/'_classes.json'\n",
    "pcd_output_path= os.path.join(path,f'{name}_labels.laz') \n",
    "objects_output_path=os.path.join(path,f'{name}_objects.json') \n",
    "\n",
    "distance_threshold=0.1 #! transfer distance threshold\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import PCD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:/Users/Maarten/OneDrive - KU Leuven/2024-05 CVPR scan-to-BIM challenge/data/connected_components/-1_rest.las\n",
      "c:/Users/Maarten/OneDrive - KU Leuven/2024-05 CVPR scan-to-BIM challenge/data/connected_components/0_Floors.las\n",
      "c:/Users/Maarten/OneDrive - KU Leuven/2024-05 CVPR scan-to-BIM challenge/data/connected_components/1_Ceilings.las\n",
      "c:/Users/Maarten/OneDrive - KU Leuven/2024-05 CVPR scan-to-BIM challenge/data/connected_components/2_Walls.las\n",
      "c:/Users/Maarten/OneDrive - KU Leuven/2024-05 CVPR scan-to-BIM challenge/data/connected_components/3_Columns.las\n",
      "c:/Users/Maarten/OneDrive - KU Leuven/2024-05 CVPR scan-to-BIM challenge/data/connected_components/4_doors.las\n",
      "['X', 'Y', 'Z', 'intensity', 'return_number', 'number_of_returns', 'scan_direction_flag', 'edge_of_flight_line', 'classification', 'synthetic', 'key_point', 'withheld', 'scan_angle_rank', 'user_data', 'point_source_id', 'object']\n",
      "48 pcdNodes created!\n"
     ]
    }
   ],
   "source": [
    "pcdNodes=[]\n",
    "for f in [l for l in ut.get_list_of_files(pcd_input_folder) if l.endswith('.las')]: # cluster the remainder\n",
    "    \n",
    "    #read pcd\n",
    "    print(f)\n",
    "    las=laspy.read(f)\n",
    "    \n",
    "    #split into components\n",
    "    if 'object' in list(las.point_format.dimension_names):\n",
    "        pcds,_=gmu.split_pcd_by_labels(gmu.las_to_pcd(las),las['object'])   #Original cloud index\n",
    "    else:\n",
    "        pcds= [gmu.las_to_pcd(las)]\n",
    "    \n",
    "    #create nodes\n",
    "    for p in pcds:\n",
    "        pcdNodes.append(PointCloudNode(resource=p,\n",
    "                                        name=ut.get_filename(f),\n",
    "                                        class_id=255,\n",
    "                                        object_id=0,\n",
    "                                        color=ut.random_color()))\n",
    "print(list(las.point_format.dimension_names))\n",
    "print(f'{len(pcdNodes)} pcdNodes created!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'classes': [{'name': 'Unassigned', 'id': 255, 'temp_id': -1, 'color': '#9da2ab'}, {'name': 'Floors', 'id': 0, 'temp_id': 0, 'color': '#03c2fc'}, {'name': 'Ceilings', 'id': 1, 'temp_id': 1, 'color': '#e81416'}, {'name': 'Walls', 'id': 2, 'temp_id': 2, 'color': '#ffa500'}, {'name': 'Columns', 'id': 3, 'temp_id': 3, 'color': '#faeb36'}, {'name': 'Doors', 'id': 4, 'temp_id': 4, 'color': '#79c314'}, {'name': 'Windows', 'id': 5, 'temp_id': 5, 'color': '#4b369d'}], 'default': 255, 'type': 'semantic_segmentation', 'format': 'kitti', 'created_with': {'name': 'Saiga', 'version': '1.0.1'}}\n"
     ]
    }
   ],
   "source": [
    "# Read the JSON file\n",
    "with open(class_file, 'r') as file:\n",
    "    json_data = json.load(file)\n",
    "\n",
    "# Create a dictionary\n",
    "class_dict = {\n",
    "    'classes': json_data['classes'],\n",
    "    'default': json_data['default'],\n",
    "    'type': json_data['type'],\n",
    "    'format': json_data['format'],\n",
    "    'created_with': json_data['created_with']\n",
    "}\n",
    "print(class_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PROCESSING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add segmentation classes to pcdNodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for every pcdNode, assign class_id and material_id (if present)\n",
    "class_names = [class_obj['name'] for class_obj in json_data['classes']]\n",
    "for i,n in enumerate(pcdNodes):\n",
    "    class_id=float(n.name.split('_')[0])\n",
    " \n",
    "    #select segmantation class\n",
    "    class_obj=next((class_obj for class_obj in json_data['classes'] if float(class_obj['id']) ==class_id), json_data['classes'][0])\n",
    "    n.class_id=class_obj['id']\n",
    "    n.object_id=i\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_e57Index': 0,\n",
       " 'pointCount': 44939,\n",
       " 'e57XmlPath': None,\n",
       " '_cartesianBounds': array([ 0.8993955, 10.6763582, -1.3840361,  5.9701691, -1.528324 ,\n",
       "        -1.4674684]),\n",
       " '_orientedBounds': array([[ 1.54688597, -2.84788198, -1.52300241],\n",
       "        [12.05509986,  1.36744864, -1.53766972],\n",
       "        [-0.36582051,  1.92021689, -1.52406274],\n",
       "        [ 1.54694897, -2.84784426, -1.4670205 ],\n",
       "        [10.14245639,  6.13558524, -1.48274814],\n",
       "        [-0.3657575 ,  1.92025462, -1.46808083],\n",
       "        [12.05516287,  1.36748637, -1.48168781],\n",
       "        [10.14239339,  6.13554752, -1.53873005]]),\n",
       " '_orientedBoundingBox': OrientedBoundingBox: center: (5.84467, 1.64385, -1.50288), extent: 11.3222, 5.13743, 0.055982),\n",
       " '_subject': rdflib.term.URIRef('file:///0_Floors'),\n",
       " '_graph': None,\n",
       " '_graphPath': None,\n",
       " '_path': None,\n",
       " '_name': '0_Floors',\n",
       " '_timestamp': None,\n",
       " '_resource': PointCloud with 44939 points.,\n",
       " '_cartesianTransform': array([[ 1.        ,  0.        ,  0.        ,  2.63570959],\n",
       "        [ 0.        ,  1.        ,  0.        ,  0.54501205],\n",
       "        [ 0.        ,  0.        ,  1.        , -1.51264508],\n",
       "        [ 0.        ,  0.        ,  0.        ,  1.        ]]),\n",
       " 'class_id': 0,\n",
       " 'object_id': 1,\n",
       " 'color': array([0.37647059, 0.39215686, 0.83137255])}"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{key:value for key, value in pcdNodes[1].__dict__.items() if not key.startswith('__') and not callable(key)}              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #visualize\n",
    "# joined_pcd=gmu.join_geometries([n.resource.paint_uniform_color(n.color) for n in pcdNodes])\n",
    "# o3d.visualization.draw_geometries([joined_pcd])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute 3D objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract parameters for each total_pcd_nodes\n",
    "for n in pcdNodes:\n",
    "    \n",
    "    #take points\n",
    "    points=np.asarray(n.resource.points)\n",
    "    \n",
    "    #project points in 2D\n",
    "    points2d=points[:,0:2]\n",
    "    \n",
    "    #select lowest and highest point\n",
    "    zmin=np.min(points[:,2])\n",
    "    zmax=np.max(points[:,2])\n",
    "    \n",
    "    #translate data\n",
    "    new_points=np.vstack((np.hstack((points2d,np.full((points2d.shape[0],1),zmin))),\n",
    "                          np.hstack((points2d,np.full((points2d.shape[0],1),zmax+50)))))\n",
    "    pcd=o3d.geometry.PointCloud()\n",
    "    pcd.points=o3d.utility.Vector3dVector(new_points)\n",
    "    n.box=pcd.get_oriented_bounding_box()\n",
    "    n.box.color=[1,0,0]\n",
    "    \n",
    "    n.center=[n.box.center[0],n.box.center[1],np.mean(points[:,2])]\n",
    "    n.dimensions=[n.box.extent[1],n.box.extent[2],zmax-zmin]\n",
    "    rotation_matrix=copy.deepcopy(n.box.R) #! can these angles be negative?\n",
    "    r =  Rotation.from_matrix(np.asarray(rotation_matrix))\n",
    "    n.rotations = r.as_euler(\"zyx\",degrees=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## las file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge point clouds\n",
    "joined_pcd=gmu.join_geometries([n.resource for n  in pcdNodes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "#obtain labels\n",
    "labels_segmentation=[]\n",
    "labels_objects=[]\n",
    "\n",
    "for i,n in enumerate(pcdNodes):\n",
    "    length=len(np.asarray(n.resource.points))\n",
    "    labels_segmentation.extend(list(np.full(length,n.class_id)))\n",
    "    labels_objects.extend(list(np.full(length,n.object_id)))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_segmentation=np.array([labels_segmentation])\n",
    "labels_objects=np.array([labels_objects])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_segmentation=np.array(labels_segmentation)\n",
    "labels_objects=np.array(labels_objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 3)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.asarray(joined_pcd.colors).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (0,) into shape (1900509,)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[125], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m las \u001b[38;5;241m=\u001b[39m laspy\u001b[38;5;241m.\u001b[39mLasData(header)\n\u001b[0;32m      4\u001b[0m las\u001b[38;5;241m.\u001b[39mxyz\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39masarray(joined_pcd\u001b[38;5;241m.\u001b[39mpoints)\n\u001b[1;32m----> 5\u001b[0m \u001b[43mlas\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mred\u001b[49m\u001b[38;5;241m=\u001b[39m(np\u001b[38;5;241m.\u001b[39masarray(joined_pcd\u001b[38;5;241m.\u001b[39mcolors)[:,\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m65535\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39muint16)\n\u001b[0;32m      6\u001b[0m las\u001b[38;5;241m.\u001b[39mgreen\u001b[38;5;241m=\u001b[39m(np\u001b[38;5;241m.\u001b[39masarray(joined_pcd\u001b[38;5;241m.\u001b[39mcolors)[:,\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m65535\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39muint16)\n\u001b[0;32m      7\u001b[0m las\u001b[38;5;241m.\u001b[39mblue\u001b[38;5;241m=\u001b[39m(np\u001b[38;5;241m.\u001b[39masarray(joined_pcd\u001b[38;5;241m.\u001b[39mcolors)[:,\u001b[38;5;241m2\u001b[39m]\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m65535\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39muint16)\n",
      "File \u001b[1;32mc:\\Users\\Maarten\\.conda\\envs\\geomapi_installed\\lib\\site-packages\\laspy\\lasdata.py:403\u001b[0m, in \u001b[0;36mLasData.__setattr__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m    401\u001b[0m name_validity \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpoints\u001b[38;5;241m.\u001b[39mvalidate_dimension_name(key)\n\u001b[0;32m    402\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name_validity \u001b[38;5;241m==\u001b[39m DimensionNameValidity\u001b[38;5;241m.\u001b[39mValid:\n\u001b[1;32m--> 403\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m value\n\u001b[0;32m    404\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name_validity \u001b[38;5;241m==\u001b[39m DimensionNameValidity\u001b[38;5;241m.\u001b[39mUnsupported:\n\u001b[0;32m    405\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    406\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPoint format \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpoint_format\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not support \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m dimension\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    407\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Maarten\\.conda\\envs\\geomapi_installed\\lib\\site-packages\\laspy\\lasdata.py:435\u001b[0m, in \u001b[0;36mLasData.__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m    434\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__setitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key, value):\n\u001b[1;32m--> 435\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpoints\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m value\n",
      "File \u001b[1;32mc:\\Users\\Maarten\\.conda\\envs\\geomapi_installed\\lib\\site-packages\\laspy\\point\\record.py:222\u001b[0m, in \u001b[0;36mPackedPointRecord.__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m    220\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_append_zeros_if_too_small(value)\n\u001b[0;32m    221\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m--> 222\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m value\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    224\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39marray[key] \u001b[38;5;241m=\u001b[39m value\n",
      "\u001b[1;31mValueError\u001b[0m: could not broadcast input array from shape (0,) into shape (1900509,)"
     ]
    }
   ],
   "source": [
    "# create new las\n",
    "header = laspy.LasHeader(point_format=3, version=\"1.2\")\n",
    "las = laspy.LasData(header)\n",
    "las.xyz=np.asarray(joined_pcd.points)\n",
    "las.red=(np.asarray(joined_pcd.colors)[:,0]*65535).astype(np.uint16)\n",
    "las.green=(np.asarray(joined_pcd.colors)[:,1]*65535).astype(np.uint16)\n",
    "las.blue=(np.asarray(joined_pcd.colors)[:,2]*65535).astype(np.uint16)\n",
    "\n",
    "gmu.las_add_extra_dimensions(las,(labels_segmentation,labels_objects),['classes','objects'],['uint8','uint8'])\n",
    "print(list(las.point_format.dimension_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "las.write(pcd_output_path)\n",
    "print(pcd_output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## json with object labels\n",
    "json contains class_id, material_id, object_id, box and ifcGuid + status if present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#declare json\n",
    "json_data = {\n",
    "        \"filename\": ut.get_filename(objects_output_path),\n",
    "        \"objects\": []\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myList=list(np.unique(las['object_labels']))\n",
    "print(myList)\n",
    "nodes=[n for n in pcdNodes if n.object_id in myList]\n",
    "print(len(nodes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill json\n",
    "for n in nodes:\n",
    "    obj = {\n",
    "            \"name\": n.name,\n",
    "            \"class_id\":n.class_id,\n",
    "            \"material_id\":n.material_id,\n",
    "            \"object_id\":n.object_id,\n",
    "            \"ifc_id\":n.ifc_id,\n",
    "            \"status_id\":n.status_id,\n",
    "            \"centroid\": {\n",
    "                \"x\": n.center[0],\n",
    "                \"y\": n.center[1],\n",
    "                \"z\": n.center[2]\n",
    "            },\n",
    "            \"dimensions\": {\n",
    "                \"length\": n.dimensions[0],\n",
    "                \"width\": n.dimensions[1],\n",
    "                \"height\": n.dimensions[2]\n",
    "            },\n",
    "            \"rotations\": {\n",
    "                \"x\": 0,\n",
    "                \"y\": 0,\n",
    "                \"z\": n.rotations[0]\n",
    "            }\n",
    "            }\n",
    "    json_data[\"objects\"].append(obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FINISH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.now()\n",
    "print(\"Current Time =\", now.strftime(\"%H:%M:%S\"))\n",
    "\n",
    "print(\"runtime: --- %s seconds ---\" % (time.time() - start_time))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geomapi_installed",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
