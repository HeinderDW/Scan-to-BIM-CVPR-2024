{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "#IMPORT PACKAGES\n",
    "from rdflib import Graph\n",
    "import rdflib\n",
    "import os.path\n",
    "import importlib\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import xml.etree.ElementTree as ET\n",
    "import open3d as o3d\n",
    "import uuid    \n",
    "import pye57 \n",
    "import ifcopenshell\n",
    "import ifcopenshell.geom as geom\n",
    "import ifcopenshell.util\n",
    "from ifcopenshell.util.selector import Selector\n",
    "import multiprocessing\n",
    "import random as rd\n",
    "import pandas as pd\n",
    "# from tabulate import tabulate\n",
    "import cv2\n",
    "import laspy\n",
    "import json\n",
    "from scipy.spatial.transform import Rotation   \n",
    "import copy\n",
    "import geomapi\n",
    "from geomapi.nodes import *\n",
    "import geomapi.utils as ut\n",
    "from geomapi.utils import geometryutils as gmu\n",
    "import geomapi.tools as tl\n",
    "from scipy.linalg import orthogonal_procrustes\n",
    "import matplotlib.pyplot as plt\n",
    "import geomapi.tools.progresstools as pt\n",
    "\n",
    "from sklearn.cluster import DBSCAN\n",
    "from PIL import Image\n",
    "\n",
    "import geomapi\n",
    "from geomapi.nodes import *\n",
    "import geomapi.utils as ut\n",
    "from geomapi.utils import geometryutils as gmu\n",
    "import geomapi.tools as tl\n",
    "import geomapi.tools.progresstools as pt\n",
    "\n",
    "#import utils\n",
    "import context \n",
    "import utils as utl\n",
    "import utils.t8_utils as t8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## INPUTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/sdegeyter/Code/Scan-to-BIM-CVPR-2024\n"
     ]
    }
   ],
   "source": [
    "#paths\n",
    "path=Path(os.getcwd()).parents[0]\n",
    "\n",
    "print(path)\n",
    "input_folder_t4=path/'data'/'t4'/'test' \n",
    "input_folder_t6=path/'data'/'t6'/'test'\n",
    "class_file=path/'data'/'_classes.json'\n",
    "output_folder=path/'data'/'t8'/ 'test'\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "#parameters\n",
    "grid_resolution = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'classes': [{'name': 'Unassigned', 'id': 255, 'temp_id': 0, 'color': '#9da2ab'}, {'name': 'Floors', 'id': 0, 'temp_id': 1, 'color': '#03c2fc'}, {'name': 'Ceilings', 'id': 1, 'temp_id': 2, 'color': '#e81416'}, {'name': 'Walls', 'id': 2, 'temp_id': 3, 'color': '#ffa500'}, {'name': 'Columns', 'id': 3, 'temp_id': 4, 'color': '#faeb36'}, {'name': 'Doors', 'id': 4, 'temp_id': 5, 'color': '#79c314'}, {'name': 'Windows', 'id': 5, 'temp_id': 6, 'color': '#4b369d'}], 'default': 255, 'type': 'semantic_segmentation', 'format': 'kitti', 'created_with': {'name': 'Saiga', 'version': '1.0.1'}}\n"
     ]
    }
   ],
   "source": [
    "# Read the JSON file\n",
    "with open(class_file, 'r') as file:\n",
    "    json_data = json.load(file)\n",
    "\n",
    "# Create a dictionary\n",
    "class_dict = {\n",
    "    'classes': json_data['classes'],\n",
    "    'default': json_data['default'],\n",
    "    'type': json_data['type'],\n",
    "    'format': json_data['format'],\n",
    "    'created_with': json_data['created_with']\n",
    "}\n",
    "print(class_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing 05_MedOffice_01_F2_small1_walls...\n",
      "145 wallNodes detected!\n"
     ]
    }
   ],
   "source": [
    "graphfiles=utl.get_list_of_files(input_folder_t6,'.ttl')\n",
    "for f in graphfiles[:1]: #only read the first one\n",
    "    print(f'processing {ut.get_filename(f)}...')      \n",
    "    wallNodes=tl.graph_path_to_nodes(f)\n",
    "    for n in wallNodes:\n",
    "        n.resource=o3d.geometry.TriangleMesh.create_from_oriented_bounding_box(o3d.geometry.OrientedBoundingBox.create_from_points(o3d.utility.Vector3dVector(n.orientedBounds)))\n",
    "\n",
    "    print(f'{len(wallNodes)} wallNodes detected!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import PCD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing 05_MedOffice_01_F2_small1...\n",
      "Unassigned : 1 Nodes found\n",
      "Floors : 2 Nodes found\n",
      "Ceilings : 3 Nodes found\n",
      "Walls : 148 Nodes found\n",
      "Columns : 173 Nodes found\n",
      "Doors : 289 Nodes found\n",
      "Windows : 289 Nodes found\n"
     ]
    }
   ],
   "source": [
    "pcdfiles=utl.get_list_of_files(input_folder_t4,'.laz')\n",
    "\n",
    "for f in pcdfiles[:1]: #only read the first one\n",
    "    pcdNodes=[]\n",
    "    \n",
    "    # check if las/pcd variable is already defined    \n",
    "    print(f'processing {ut.get_filename(f)}...')      \n",
    "    las = laspy.read(f) if 'las' not in globals() else las\n",
    "    pcd=gmu.las_to_pcd(las,getNormals=True) if 'pcd' not in globals() else pcd # this is the slowest step\n",
    "    \n",
    "    #seperate initial objects\n",
    "    for c in class_dict['classes']:\n",
    "        if c['id'] in [255,0,1,2,3,4,5]:\n",
    "            idx=np.where((las['classes']==c['id']))[0]\n",
    "            class_pcd=pcd.select_by_index(idx)\n",
    "            object_labels=las['objects'][idx]\n",
    "            \n",
    "            for j in np.unique(object_labels):\n",
    "                indices=np.where(object_labels==j)[0]\n",
    "                object_pcd=class_pcd.select_by_index(indices)\n",
    "                pcdNodes.append(PointCloudNode(resource=object_pcd,\n",
    "                                            class_id=c['id'],\n",
    "                                            object_id=j,\n",
    "                                            color=ut.random_color(),\n",
    "                                            name=c['name']+f'_{str(j)}'))\n",
    "                \n",
    "            \n",
    "            #all further processing will be placed here (or in functions)!\n",
    "            print( c['name'], f': {len(pcdNodes)} Nodes found')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 clutterNodes detected!\n",
      "1 floorsNodes detected!\n",
      "1 ceilingsNodes detected!\n",
      "145 wallNodes detected!\n",
      "25 columnNodes detected!\n",
      "116 doorNodes detected!\n",
      "0 windowNodes detected!\n"
     ]
    }
   ],
   "source": [
    "clutterPCDNodes=[n for n in pcdNodes if 'Unassigned' in n.subject and type(n)==PointCloudNode]\n",
    "floorPCDNodes=[n for n in pcdNodes if 'Floors' in n.subject and type(n)==PointCloudNode]\n",
    "ceilingPCDNodes=[n for n in pcdNodes if 'Ceilings' in n.subject and type(n)==PointCloudNode]\n",
    "wallPCDNodes=[n for n in pcdNodes if 'Walls' in n.subject and type(n)==PointCloudNode]\n",
    "columnPCDNodes=[n for n in pcdNodes if 'Columns' in n.subject and type(n)==PointCloudNode]\n",
    "doorPCDNodes=[n for n in pcdNodes if 'Doors' in n.subject and type(n)==PointCloudNode]\n",
    "windowPCDNodes=[n for n in pcdNodes if 'Windows' in n.subject and type(n)==PointCloudNode]\n",
    "\n",
    "print(f'{len(clutterPCDNodes)} clutterNodes detected!')\n",
    "print(f'{len(floorPCDNodes)} floorsNodes detected!')\n",
    "print(f'{len(ceilingPCDNodes)} ceilingsNodes detected!')\n",
    "print(f'{len(wallPCDNodes)} wallNodes detected!')\n",
    "print(f'{len(columnPCDNodes)} columnNodes detected!')\n",
    "print(f'{len(doorPCDNodes)} doorNodes detected!')\n",
    "print(f'{len(windowPCDNodes)} windowNodes detected!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "match point clouds with graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in clutterPCDNodes+floorPCDNodes+ceilingPCDNodes+columnPCDNodes+doorPCDNodes+windowPCDNodes: # this is quite slow because you iterate through 2 scalar fields every time\n",
    "    idx=np.where((las['classes']==n.class_id) & (las['objects']==n.object_id))\n",
    "    pcd=o3d.geometry.PointCloud()\n",
    "    pcd.points=o3d.utility.Vector3dVector(las.xyz[idx])\n",
    "    red = las['red'][idx]\n",
    "    green = las['green'][idx]\n",
    "    blue = las['blue'][idx]\n",
    "    #if color is 32 bit, only keep 8 bit color\n",
    "    if red.max()>255:\n",
    "        red = las['red'][idx] >> 8 & 0xFF\n",
    "        green = las['green'][idx] >> 8 & 0xFF\n",
    "        blue = las['blue'][idx] >> 8 & 0xFF\n",
    "    # if colorspace is [0-255] -> remap to [0-1]\n",
    "    if red.max() >1:\n",
    "        red=red/255\n",
    "        green=green/255\n",
    "        blue=blue/255\n",
    "    pcd.colors=o3d.utility.Vector3dVector(np.vstack((red,green,blue)).transpose())\n",
    "\n",
    "    n.resource=pcd\n",
    "    n.get_oriented_bounding_box()\n",
    "    n.orientedBoundingBox.color=[1,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in wallPCDNodes:#+ceilingsNodes+floorsNodes: # this is quite slow because you iterate through 2 scalar fields every time\n",
    "    idx=np.where((las['classes']==n.class_id) & (las['objects']==n.object_id))\n",
    "    pcd=o3d.geometry.PointCloud()\n",
    "    pcd.points=o3d.utility.Vector3dVector(las.xyz[idx])\n",
    "    pcd.paint_uniform_color([0.5,0.5,0.5])\n",
    "    \n",
    "    red = las['red'][idx]\n",
    "    green = las['green'][idx]\n",
    "    blue = las['blue'][idx]\n",
    "    #if color is 32 bit, only keep 8 bit color\n",
    "    if red.max()>255:\n",
    "        red = las['red'][idx] >> 8 & 0xFF\n",
    "        green = las['green'][idx] >> 8 & 0xFF\n",
    "        blue = las['blue'][idx] >> 8 & 0xFF\n",
    "    # if colorspace is [0-255] -> remap to [0-1]\n",
    "    if red.max() >1:\n",
    "        red=red/255\n",
    "        green=green/255\n",
    "        blue=blue/255\n",
    "    \n",
    "    pcd.colors=o3d.utility.Vector3dVector(np.column_stack((red, green, blue)))\n",
    "\n",
    "    n.resource=pcd\n",
    "    n.get_oriented_bounding_box()\n",
    "    n.orientedBoundingBox.color=[1,0,0] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "match PointCloudNodes to BIMNodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in wallNodes:\n",
    "    n.derivedFrom = next(p for p in wallPCDNodes if p.subject.toPython() in [w.derivedFrom for w in wallNodes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# joined_pcd=gmu.join_geometries([n.resource.paint_uniform_color(ut.literal_to_array(n.color)) for n in wallPCDNodes if n.resource is not None])\n",
    "# o3d.visualization.draw_geometries([joined_pcd])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Reference Levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# levelNodes=[n for n in nodes if 'level' in n.subject]\n",
    "# referenceNodes=[]\n",
    "# for l in levelNodes:\n",
    "#     new_graph=ut.get_subject_graph(graph,levelNodes[0].subject)\n",
    "#     n=SessionNode(graph=new_graph)\n",
    "#     n.get_oriented_bounding_box()\n",
    "#     n.resource=o3d.geometry.TriangleMesh.create_from_oriented_bounding_box(n.orientedBoundingBox)\n",
    "#     referenceNodes.append(n) # something is wrong in the tl.graph_to_nodes function\n",
    "# levelNodes=referenceNodes\n",
    "# print(f'{len(levelNodes)} levelNodes detected!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import ceilings and floors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for n in ceilingsNodes+floorsNodes: # this is quite slow because you iterate through 2 scalar fields every time\n",
    "#     idx=np.where((laz['classes']==n.class_id) & (laz['objects']==n.object_id))\n",
    "#     pcd=o3d.geometry.PointCloud()\n",
    "#     pcd.points=o3d.utility.Vector3dVector(laz.xyz[idx])\n",
    "#     n.resource=pcd\n",
    "#     n.get_oriented_bounding_box()\n",
    "#     n.orientedBoundingBox.color=[1,1,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the ground truth data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62\n"
     ]
    }
   ],
   "source": [
    "groundtruthPath = '/home/sdegeyter/Code/Scan-to-BIM-CVPR-2024/data/t0/05_MedOffice_01_F2_doors.json'\n",
    "groundtruthNodes = []\n",
    "\n",
    "with open(groundtruthPath) as gt:\n",
    "    data = json.load(gt)\n",
    "    \n",
    "for item in data:\n",
    "    doorNode = Node(\n",
    "        id = item['id'],\n",
    "        width = item['width'],\n",
    "        height = item['height'],\n",
    "        depth = item['depth'],\n",
    "        center = item['loc'], \n",
    "        rotation = item['rotation'], \n",
    "        host = item['host_id']\n",
    "    )\n",
    "    groundtruthNodes.append(doorNode)\n",
    "print(len(groundtruthNodes))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PROCESSING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert dtrings from the graph to arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in wallNodes:\n",
    "    n.startpoint = np.asarray(n.startpoint[1:-1].split(), dtype=float)\n",
    "    n.endpoint = np.asarray(n.endpoint[1:-1].split(), dtype=float)\n",
    "    n.normal = np.asarray(n.normal[1:-1].split(), dtype=float)\n",
    "    n.height = float(n.height)\n",
    "    n.name = n.subject.split('///')[-1]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def points_on_line(point1, point2, step_size):\n",
    "    \"\"\"\n",
    "    Generate points on a line between two given points with a specified step size.\n",
    "\n",
    "    Parameters:\n",
    "    - point1: The starting point of the line.\n",
    "    - point2: The ending point of the line.\n",
    "    - step_size: The step size between consecutive points.\n",
    "\n",
    "    Returns:\n",
    "    - points: A list of points on the line.\n",
    "    \"\"\"\n",
    "    # Calculate the direction vector\n",
    "    direction = point2 - point1\n",
    "\n",
    "    # Calculate the length of the line segment\n",
    "    length = np.linalg.norm(direction)\n",
    "\n",
    "    # Normalize the direction vector\n",
    "    direction /= length\n",
    "\n",
    "    # Calculate the number of steps needed\n",
    "    num_steps = int(length / step_size)\n",
    "\n",
    "    # Generate points along the line\n",
    "    points = np.array([point1 + i * step_size * direction for i in range(num_steps + 1)])\n",
    "\n",
    "    return points\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the full resolution point cloud for a more accurate result (unlabeled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# laz = laspy.read(os.path.join(Path(os.getcwd()).parents[0]/'data',\"full_resolution_populierenhof.las\"))\n",
    "full_res_point_cloud_o3d = gmu.las_to_pcd(las)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the full point cloud into a mesh and add it to a raycasting scene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voxelsize =  0.02052154296875\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Cut a part out of the full resolution pointcloud\n",
    "# joined_pcd = full_res_point_cloud_o3d.crop(expanded_bounding_box)\n",
    "#Create a messh from this point cloud \n",
    "octree=pt.pcd_to_octree(full_res_point_cloud_o3d,12) #if octree is None else octree\n",
    "full_res_point_cloud_o3d = None\n",
    "mesh=gmu.octree_to_voxelmesh(octree) #if mesh is None else mesh\n",
    "\n",
    "\n",
    "#Create a identity array containing the color so this can be retrieved afterwards\n",
    "original_colors=np.asarray(mesh.vertex_colors)\n",
    "indices=np.asarray(mesh.triangles)[:,0]\n",
    "triangle_colors=original_colors[indices]\n",
    "#append black color at the end of the array for the invalid hits\n",
    "triangle_colors=np.vstack((triangle_colors,np.array([0,0,0])))\n",
    "\n",
    "# Create raycasting scene\n",
    "scene = o3d.t.geometry.RaycastingScene()\n",
    "mesh=o3d.t.geometry.TriangleMesh.from_legacy(mesh)\n",
    "scene.add_triangles(mesh) \n",
    "\n",
    "# Calculate the size of each octree node based on octree depth and overall size\n",
    "def calculate_node_size(octree_depth, octree_size):\n",
    "    num_voxels_per_dim = 2 ** octree_depth\n",
    "    voxel_size = octree_size / num_voxels_per_dim\n",
    "    return voxel_size\n",
    "\n",
    "# Example usage:\n",
    "octree_depth = octree.max_depth  # Example value for max_depth\n",
    "octree_size = octree.size  # Example size of the octree in world units\n",
    "voxel_size = calculate_node_size(octree_depth, octree_size)\n",
    "print(\"Voxelsize = \", voxel_size)\n",
    "octree = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def is_door(openingwidth, openingheight, t_min_width = 0.5, t_max_width = 3, t_min_height = 1.5, t_max_height = 2.3):\n",
    "\n",
    "#     if t_min_width < openingwidth < t_max_width and t_min_height < openingheight < t_max_height:\n",
    "#         return True\n",
    "#     else: \n",
    "#         return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 1: Using the pointcloud and wall data to retrieve potential openings in the walls \n",
    "(Can also be used to retrieve wall detailing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_opening_pcds(startpoint, endpoint, height, resolution, direction, scene, offset =0.7, path = None, show = False, min_samples = 5000, eps = 0.2, wallThickness = 0.1, voxel_size = 0.01):\n",
    "    \n",
    "#     min_z = np.min([endpoint[2], startpoint[2]])\n",
    "#     max_z = min_z + height\n",
    "#     num_z_steps = int(height /resolution)\n",
    "#     z_grid = np.linspace(min_z, max_z, num_z_steps)  # Adjust the number of grid points as needed\n",
    "#     xyz_grid = []\n",
    "#     for z in z_grid:\n",
    "#         start = n.startpoint.copy()\n",
    "#         end =  n.endpoint.copy()\n",
    "#         start[2] = z\n",
    "#         end[2] = z\n",
    "#         xyz_grid.append(points_on_line(start, end, resolution))\n",
    "\n",
    "#     grid = np.asarray(xyz_grid).reshape((-1, 3), order='C') \n",
    "    \n",
    "#     openingpcds = []\n",
    "#     # Create Open3D point cloud\n",
    "#     grid_center_pcd = o3d.geometry.PointCloud()\n",
    "#     grid_center_pcd.points = o3d.utility.Vector3dVector(np.asarray(grid))\n",
    "#     grid_center_pcd.paint_uniform_color([1,0,0])\n",
    "\n",
    "#     #In face is the dominant side of the wall\n",
    "#     grid_in = grid + direction*offset\n",
    "#     #out face is the other side of the dominant side\n",
    "#     grid_out = grid - direction*offset\n",
    "\n",
    "#     #create rays for the in side (towards the dominant side\n",
    "#     ori_x = direction[0] * np.ones(len(grid))\n",
    "#     ori_y = direction[1] * np.ones(len(grid))\n",
    "#     ori_z = direction[2] * np.ones(len(grid))\n",
    "    \n",
    "#     pos_x = grid_in[:,0]\n",
    "#     pos_y = grid_in[:,1]\n",
    "#     pos_z = grid_in[:,2]\n",
    "\n",
    "#     # Stack the calculated values along the third axis to create the grid\n",
    "#     rays_in_values = np.stack((pos_x, pos_y, pos_z, -ori_x, -ori_y, -ori_z), axis=1)\n",
    "#     rays_in_tensor = o3d.core.Tensor(rays_in_values, dtype=o3d.core.Dtype.Float32)\n",
    "\n",
    "#     pos_x = grid_out[:,0]\n",
    "#     pos_y = grid_out[:,1]\n",
    "#     pos_z = grid_out[:,2]\n",
    "\n",
    "#     rays_out_values = np.stack((pos_x, pos_y, pos_z, ori_x, ori_y, ori_z), axis=1)\n",
    "#     rays_out_tensor = o3d.core.Tensor(rays_out_values, dtype=o3d.core.Dtype.Float32)       \n",
    "\n",
    "#     ans_in = scene.cast_rays(rays_in_tensor)\n",
    "#     ans_out = scene.cast_rays(rays_out_tensor)\n",
    "\n",
    "#     hits_in = ans_in['t_hit'].numpy()\n",
    "#     hits_out = ans_out['t_hit'].numpy()\n",
    "\n",
    "#     opening_points = []\n",
    "#     opening_colors = []\n",
    "    \n",
    "#     colors = np.zeros((len(hits_in), 3))\n",
    "#     for i, c in enumerate(colors):\n",
    "#         if hits_in[i] > 2*offset and hits_out[i] > 2*offset:\n",
    "#             colors[i] = [0,1,0]\n",
    "#             opening_points.append(grid[i])\n",
    "#             opening_colors.append([0,1,0])\n",
    "\n",
    "#         elif hits_in[i] <2*offset or hits_out[i] < 2*offset:\n",
    "#             colors[i] = [0.5,0.5,0.5]\n",
    "#             thickness = 2*offset-hits_out[i]-hits_in[i]\n",
    "    \n",
    "#             if 1.2*voxel_size < thickness < 0.5*wallThickness:\n",
    "#                 # colors[i] = [1,0.5,0]\n",
    "#                 opening_points.append(grid[i])\n",
    "#                 opening_colors.append([0,1,0])\n",
    "\n",
    "\n",
    "#     # grid_center_pcd.colors =o3d.utility.Vector3dVector(np.asarray(colors))\n",
    "#     opening_pcd = o3d.geometry.PointCloud()\n",
    "#     opening_pcd.points = o3d.utility.Vector3dVector(np.asarray(opening_points))\n",
    "#     opening_pcd.colors = o3d.utility.Vector3dVector(np.asarray(opening_colors))\n",
    "    \n",
    "#     opening_pcd, ind = opening_pcd.remove_radius_outlier(nb_points = 100, radius = 0.1)\n",
    "\n",
    "#     # o3d.visualization.draw_geometries([opening_pcd])\n",
    "\n",
    "#     points = np.asarray(opening_pcd.points)\n",
    "#     if len(points) > min_samples:\n",
    "\n",
    "#         # Perform clustering using DBSCAN\n",
    "#         dbscan = DBSCAN(eps=eps, min_samples=min_samples)\n",
    "#         labels = dbscan.fit_predict(points)\n",
    "\n",
    "#         # Extract unique cluster labels (excluding noise label -1)\n",
    "#         unique_labels = np.unique(labels[labels != -1])\n",
    "\n",
    "#         # Iterate over each cluster label and save corresponding points to a separate point cloud\n",
    "#         for label in unique_labels:\n",
    "#             cluster_points = points[labels == label]\n",
    "#             cluster_pcd = o3d.geometry.PointCloud()\n",
    "#             cluster_pcd.points = o3d.utility.Vector3dVector(cluster_points)\n",
    "#             openingpcds.append(cluster_pcd)\n",
    "#     if show:\n",
    "#         o3d.visualization.draw_geometries(openingpcds)\n",
    "#     # o3d.visualization.draw_geometries([grid_center_pcd])\n",
    "   \n",
    "#     return openingpcds\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pcd_resolution = 0.01\n",
    "# for n in wallBIMNodes:\n",
    "    \n",
    "#     length = np.sqrt(np.sum((n.endpoint - n.startpoint)**2))\n",
    "#     surface = length * n.height\n",
    "#     n.openings1 = []\n",
    "\n",
    "#     if not surface < 3 and n.height > 1.5 and length > 0.8:\n",
    "                \n",
    "#         n.openings1 = create_opening_pcds(startpoint = n.startpoint, endpoint = n.endpoint, height=n.height, resolution= 0.01, direction= n.normal, scene= scene, offset =0.5, path = None, show = False, min_samples = 1000, eps = 0.25, wallThickness = n.wallThickness, voxel_size=voxel_size)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# doors = []\n",
    "# other = []\n",
    "# for n in wallBIMNodes:\n",
    "#     n.baseConstraint = next(l for l in levelNodes if l.subject.toPython() in [w.base_constraint for w in wallBIMNodes])\n",
    "    \n",
    "#     if len(n.openings1) > 0:\n",
    "#         for opening in n.openings1:\n",
    "#             # Extract the z-coordinates\n",
    "#             points2 = np.asarray(opening.points)\n",
    "#             z_values = points2[:, 2]\n",
    "#             unique_z_values = np.unique(z_values)\n",
    "\n",
    "#             #Compute the width of the opening\n",
    "#             opening_width = 0.0\n",
    "#             for z_value in unique_z_values:\n",
    "#                 # Get points with the current z-value\n",
    "#                 points_with_same_z = points2[z_values == z_value]\n",
    "\n",
    "#                 # Find the outermost points based on XY coordinates\n",
    "#                 min_x = np.min(points_with_same_z[:, 0])\n",
    "#                 max_x = np.max(points_with_same_z[:, 0])\n",
    "#                 min_y = np.min(points_with_same_z[:, 1])\n",
    "#                 max_y = np.max(points_with_same_z[:, 1])\n",
    "\n",
    "#                 # Compute the diagonal length of the bounding box\n",
    "#                 diagonal_length = np.linalg.norm([max_x - min_x, max_y - min_y])\n",
    "\n",
    "#                 if diagonal_length > opening_width:\n",
    "#                     opening_width = diagonal_length\n",
    "                    \n",
    "#             print(\"Opening Width:\", opening_width)\n",
    "            \n",
    "#             #Compute the Height of the door\n",
    "#             lowest_z = np.min(z_values)\n",
    "#             highest_z = np.max(z_values)\n",
    "#             opening_height = highest_z - lowest_z   \n",
    "#             print(\"Opening height:\", opening_height)\n",
    "            \n",
    "#             #Depth should be equal to the wall thickness\n",
    "            \n",
    "#             if is_door(openingwidth = opening_width, openingheight = opening_height):\n",
    "#                 doors.append(opening)\n",
    "#                 print(\"This is most likely a door\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # o3d.visualization.draw_geometries(doors)\n",
    "# joined_pcd=gmu.join_geometries(doors)\n",
    "# o3d.io.write_point_cloud(os.path.join(Path(os.getcwd()).parents[0]/'data', \"doors.pcd\"), joined_pcd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 2: Using the pointcloud and wall data to create an ortho foto of the wall and use object detection\n",
    "(Can also be used to retrieve other elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_wall_ortho(startpoint, endpoint, height, resolution, direction, scene, offset =1, path = None, show = False, dominant = True, max_distance = 0.5, min_distance = 0.5):\n",
    "    image_size = (int(np.sqrt(np.sum((endpoint - startpoint)**2)) / resolution)+1, int(height / resolution))\n",
    "    \n",
    "    min_z = np.min([endpoint[2], startpoint[2]])\n",
    "    max_z = min_z + height\n",
    "    num_z_steps = int(height /resolution)\n",
    "    z_grid = np.linspace(min_z, max_z, num_z_steps)  # Adjust the number of grid points as needed\n",
    "    z_grid = z_grid[::-1]\n",
    "    xyz_grid = []\n",
    "    for z in z_grid:\n",
    "        start = startpoint.copy()\n",
    "        end =  endpoint.copy()\n",
    "        start[2] = z\n",
    "        end[2] = z\n",
    "        if not dominant:\n",
    "            xyz_grid.append(points_on_line(start, end, resolution)[::-1])\n",
    "        else: \n",
    "            xyz_grid.append(points_on_line(start, end, resolution))\n",
    "\n",
    "    grid = np.asarray(xyz_grid).reshape((-1, 3), order='C') \n",
    "    ray_grid = grid + direction*offset\n",
    "    \n",
    "    #create rays for the in side (towards the dominant side\n",
    "    ori_x = direction[0] * np.ones(len(ray_grid))\n",
    "    ori_y = direction[1] * np.ones(len(ray_grid))\n",
    "    ori_z = direction[2] * np.ones(len(ray_grid))\n",
    "    \n",
    "    pos_x = ray_grid[:,0]\n",
    "    pos_y = ray_grid[:,1]\n",
    "    pos_z = ray_grid[:,2]\n",
    "    \n",
    "    # Stack the calculated values along the third axis to create the grid\n",
    "    rays_values = np.stack((pos_x, pos_y, pos_z, -ori_x, -ori_y, -ori_z), axis=1)\n",
    "    rays_tensor = o3d.core.Tensor(rays_values, dtype=o3d.core.Dtype.Float32)\n",
    "    \n",
    "    ans= scene.cast_rays(rays_tensor) \n",
    "    \n",
    "    \n",
    "    triangle_ids = ans[\"primitive_ids\"].numpy() # triangles     \n",
    "    triangle_ids = triangle_ids.flatten()\n",
    "    np.put(triangle_ids,np.where(triangle_ids==scene.INVALID_ID),triangle_colors.shape[0]-1) # replace invalid id's by last (which is the above added black color)\n",
    "    \n",
    "    # Get the hit distances for each ray\n",
    "    hit_distances = ans[\"t_hit\"].numpy().flatten()\n",
    "    \n",
    "    # Filter out hits that are too far or too close\n",
    "    if max_distance is not None:\n",
    "        triangle_ids[hit_distances > max_distance+offset] = triangle_colors.shape[0] - 1  # Set to black\n",
    "        \n",
    "    if min_distance is not None:\n",
    "        triangle_ids[hit_distances < min_distance] = triangle_colors.shape[0] - 1  # Set to black\n",
    "    \n",
    "    colors = triangle_colors[triangle_ids]\n",
    "    ortho = np.reshape(colors,(image_size[1],image_size[0],3))\n",
    "    \n",
    "    if show:\n",
    "        plt.imshow(ortho)\n",
    "        plt.show()\n",
    "    if path:\n",
    "        image = Image.fromarray((ortho * 255).astype(np.uint8))\n",
    "        # Save the image\n",
    "        image.save(path)\n",
    "        \n",
    "    return ortho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_black_pixels(image:np.array,region:int=5)->np.array:\n",
    "    \"\"\"Fill in the black pixels in an RGB image given a search distance.\\n\n",
    " \n",
    "    Args:\n",
    "        image (np.array)\\n\n",
    "        region (int, optional): search distance. Defaults to 5.\\n\n",
    " \n",
    "    Returns:\n",
    "        np.array: image\n",
    "    \"\"\"\n",
    "    kernel = np.ones((region,region),np.uint8)\n",
    "    return cv2.morphologyEx(image, cv2.MORPH_CLOSE, kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_resolution = 0.01\n",
    "\n",
    "for n in wallNodes:\n",
    "    \n",
    "    length = np.sqrt(np.sum((n.endpoint - n.startpoint)**2))\n",
    "    surface = length * n.height\n",
    "    image_size = (int(length / image_resolution), int(n.height / image_resolution))\n",
    "    n.orthos = []\n",
    "    \n",
    "\n",
    "    if not surface < 3 and n.height > 1.5 and length > 0.8:  \n",
    "        #Create an ortho of the dominant side of the wall      \n",
    "        ortho = create_wall_ortho(startpoint = n.startpoint, endpoint= n.endpoint, height= n.height, resolution = image_resolution, direction = n.normal, scene=scene)\n",
    "        ortho = fill_black_pixels(ortho, region = 10)\n",
    "        n.orthos.append(ortho)\n",
    "        #Also create an ortho of the other side of the wall\n",
    "        if not n.wallThickness == 0.1: #Single faced wall only needs one side\n",
    "            ortho = create_wall_ortho(startpoint = n.startpoint, endpoint= n.endpoint, height= n.height, resolution = image_resolution, direction = -n.normal, scene=scene, dominant = False)\n",
    "            ortho = fill_black_pixels(ortho, region = 10)\n",
    "            n.orthos.append(ortho)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "from torchvision.ops import box_convert\n",
    "\n",
    "# Grounding DINO\n",
    "from groundingdino.models import build_model\n",
    "from groundingdino.util.slconfig import SLConfig\n",
    "from groundingdino.util.utils import clean_state_dict\n",
    "from groundingdino.util.inference import annotate, load_image, predict\n",
    "\n",
    "import supervision as sv\n",
    "\n",
    "# segment anything\n",
    "# from segment_anything import build_sam, SamPredictor \n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# diffusers\n",
    "import torch\n",
    "\n",
    "from huggingface_hub import hf_hub_download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_hf(repo_id, filename, ckpt_config_filename, device='cpu'):\n",
    "    cache_config_file = hf_hub_download(repo_id=repo_id, filename=ckpt_config_filename)\n",
    "\n",
    "    args = SLConfig.fromfile(cache_config_file) \n",
    "    model = build_model(args)\n",
    "    args.device = device\n",
    "\n",
    "    cache_file = hf_hub_download(repo_id=repo_id, filename=filename)\n",
    "    checkpoint = torch.load(cache_file, map_location=device)\n",
    "    log = model.load_state_dict(clean_state_dict(checkpoint['model']), strict=False)\n",
    "    print(\"Model loaded from {} \\n => {}\".format(cache_file, log))\n",
    "    _ = model.eval()\n",
    "    return model   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this command for evaluate the Grounding DINO model\n",
    "# Or you can download the model by yourself\n",
    "ckpt_repo_id = \"ShilongLiu/GroundingDINO\"\n",
    "ckpt_filenmae = \"groundingdino_swinb_cogcoor.pth\"\n",
    "ckpt_config_filename = \"GroundingDINO_SwinB.cfg.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final text_encoder_type: bert-base-uncased\n",
      "Model loaded from /home/sdegeyter/.cache/huggingface/hub/models--ShilongLiu--GroundingDINO/snapshots/a94c9b567a2a374598f05c584e96798a170c56fb/groundingdino_swinb_cogcoor.pth \n",
      " => _IncompatibleKeys(missing_keys=[], unexpected_keys=['label_enc.weight', 'bert.embeddings.position_ids'])\n"
     ]
    }
   ],
   "source": [
    "from torch.cuda.amp import autocast\n",
    "with autocast():\n",
    "    groundingdino_model = load_model_hf(ckpt_repo_id, ckpt_filenmae, ckpt_config_filename, device=\"cuda:1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "2024-05-16 14:54:35.259889: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-16 14:54:39.625484: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/sdegeyter/.conda/envs/pointcept/lib/python3.10/site-packages/cv2/../../lib64:\n",
      "2024-05-16 14:54:39.625852: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/sdegeyter/.conda/envs/pointcept/lib/python3.10/site-packages/cv2/../../lib64:\n",
      "2024-05-16 14:54:39.625871: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "pointcloud = []\n",
    "\n",
    "\n",
    "for n in wallNodes:\n",
    "    TEXT_PROMPT = \"Door\"\n",
    "    BOX_TRESHOLD = 0.30\n",
    "    TEXT_TRESHOLD = 0.5\n",
    "    \n",
    "    n.boxes = []\n",
    "    n.logits = []\n",
    "    n.phrases = []\n",
    "    \n",
    "    if len(n.orthos) > 0:\n",
    "        \n",
    "        for ortho in n.orthos:\n",
    "            boxes = None\n",
    "            image = load_image(Image.fromarray((ortho * 255).astype(np.uint8)))\n",
    "\n",
    "            boxes, logits, phrases = predict(\n",
    "                model=groundingdino_model, \n",
    "                image=image, \n",
    "                caption=TEXT_PROMPT, \n",
    "                box_threshold=BOX_TRESHOLD, \n",
    "                text_threshold=TEXT_TRESHOLD\n",
    "            )\n",
    "            \n",
    "            n.boxes.append(boxes)\n",
    "            n.logits.append(logits)\n",
    "            n.phrases.append(phrases)                  \n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_point_cloud(img, startpoint, endpoint, box):\n",
    "    # Define the UV coordinate ranges\n",
    "    u_range = np.linspace(0, 1, img.shape[1])  # Width of the image corresponds to U\n",
    "    v_range = np.linspace(0, 1, img.shape[0])  # Height of the image corresponds to V\n",
    "    print(u_range)\n",
    "    print(v_range)\n",
    "    if not img[0].shape == img[1].shape:\n",
    "        print(\"PROBLEM\")\n",
    "    # Initialize arrays to store points and colors\n",
    "    points = []\n",
    "    colors = []\n",
    "\n",
    "    # Precalculate box boundaries\n",
    "    box_boundaries_0 = []\n",
    "    opening_width = int(np.asarray(box)[2]*img.shape[1])* image_resolution\n",
    "    opening_height =   int(np.asarray(box)[3]*img.shape[0]) * image_resolution\n",
    "    \n",
    "    detection_center_u = int(np.asarray(box)[0]*img.shape[1]) * image_resolution\n",
    "    detection_center_v = int(np.asarray(box)[1]*img.shape[0]) * image_resolution  \n",
    "                \n",
    "    u_min = detection_center_u - opening_width / 2\n",
    "    u_max = detection_center_u + opening_width / 2\n",
    "    v_min = detection_center_v - opening_height / 2\n",
    "    v_max = detection_center_v + opening_height / 2\n",
    "    \n",
    "    box_boundaries_0.append((u_min, u_max, v_min, v_max))\n",
    "            \n",
    "    # Iterate over each pixel in the image\n",
    "    if len(box_boundaries_0) > 0:\n",
    "        for v, u, a in np.ndindex(img.shape):\n",
    "            # Map UV coordinates to XYZ coordinates\n",
    "            x = (1 - u_range[u]) * startpoint[0] + u_range[u] * endpoint[0]\n",
    "            y = (1 - u_range[u]) * startpoint[1] + u_range[u] * endpoint[1]\n",
    "            z = (1 - v_range[v]) * endpoint[2]  # Since V represents Z\n",
    "            \n",
    "            # Check if the point falls inside any of the boxes\n",
    "            in_box_0 = False\n",
    "            for box_boundary in box_boundaries_0:\n",
    "                    u_min, u_max, v_min, v_max = box_boundary\n",
    "                    if u_min <= u*image_resolution < u_max and v_min <= v*image_resolution < v_max:\n",
    "                        in_box_0 = True\n",
    "                        break\n",
    "        \n",
    "            # Assign the color based on whether the point is inside any of the boxes\n",
    "            if in_box_0: \n",
    "                colors.append([0, 0, 1])  # Red\n",
    "                points.append([x, y, z])\n",
    "\n",
    "    return np.array(points), np.array(colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_box_with_margin(image, box, margin = 10):\n",
    "    # Extract center and size from the detection array\n",
    "    width = int(np.asarray(box)[2]*image.shape[1])\n",
    "    height =   int(np.asarray(box)[3]*image.shape[0])\n",
    "    \n",
    "    center_x = int(np.asarray(box)[0]*image.shape[1])\n",
    "    center_y = int(np.asarray(box)[1]*image.shape[0])  \n",
    "    \n",
    "\n",
    "    # Calculate coordinates of the bounding box with extra margin\n",
    "    x1 = int(center_x - width/2) - margin\n",
    "    y1 = int(center_y - height/2) - margin\n",
    "    x2 = int(center_x + width/2) + margin\n",
    "    y2 = int(center_y + height/2) + margin\n",
    "\n",
    "    # Ensure the box is within the image bounds\n",
    "    x1 = max(x1, 0)\n",
    "    y1 = max(y1, 0)\n",
    "    x2 = min(x2, image.shape[1])\n",
    "    y2 = min(y2, image.shape[0])\n",
    "\n",
    "    # Create a new image containing pixels within the bounding box\n",
    "    extracted_image = np.copy(image[y1:y2, x1:x2])\n",
    "    normalized_image = cv2.normalize(extracted_image, None, 0, 255, cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n",
    "\n",
    "    return normalized_image.astype(np.uint8)\n",
    "\n",
    "def compute_center(point1, point2):\n",
    "    center = [(point1[0] + point2[0]) / 2,\n",
    "              (point1[1] + point2[1]) / 2,\n",
    "              (point1[2] + point2[2]) / 2]\n",
    "    return center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_door(probability, width, height, reference_level, prob_weight=0.25, width_weight=0.25, height_weight=0.25, ref_level_weight=0.25):\n",
    "    # Ensure parameters are within valid ranges\n",
    "    if height < 1.5 or height > 2.5:\n",
    "        return 0  # Invalid height for a door\n",
    "\n",
    "    # Width score calculation with two ideal ranges and additional penalty\n",
    "    if 0.6 <= width <= 1.0 or 1.2 <= width <= 2.0:\n",
    "        width_score = 1\n",
    "    elif width < 0.6:\n",
    "        width_score = width / 0.6 - 0.2\n",
    "    elif width < 1.2:\n",
    "        width_score = max(0, (1.2 - width) / (1.2 - 1.0)) - 0.2\n",
    "    elif width > 2.0:\n",
    "        width_score = max(0, 2.0 / width) - 0.5\n",
    "    else:\n",
    "        width_score = 0 - 0.2  # Should not reach here\n",
    "\n",
    "    # Height score calculation with ideal range of 2m to 2.4m and additional penalty\n",
    "    if 2.0 <= height <= 2.4:\n",
    "        height_score = 1\n",
    "    elif height < 2.0:\n",
    "        height_score = max(0, (height - 1.5) / 0.5) - 0.2\n",
    "    else:\n",
    "        height_score = max(0, (2.5 - height) / 0.1) - 0.2\n",
    "\n",
    "    # Reference level score calculation with additional penalty\n",
    "    if reference_level <= 0.05:\n",
    "        reference_level_score = 1\n",
    "    else:\n",
    "        reference_level_score = max(0, 1 - (reference_level - 0.05) / 0.95) - 0.2\n",
    "\n",
    "    # Return 0 if any score is 0\n",
    "    if width_score <= 0 or height_score <= 0 or reference_level_score <= 0:\n",
    "        return 0\n",
    "\n",
    "    # Normalize weights so that their sum is 1\n",
    "    total_weight = prob_weight + width_weight + height_weight + ref_level_weight\n",
    "    normalized_prob_weight = prob_weight / total_weight\n",
    "    normalized_width_weight = width_weight / total_weight\n",
    "    normalized_height_weight = height_weight / total_weight\n",
    "    normalized_ref_level_weight = ref_level_weight / total_weight\n",
    "\n",
    "    # Weighted scores\n",
    "    weighted_prob = probability * normalized_prob_weight\n",
    "    weighted_width = width_score * normalized_width_weight\n",
    "    weighted_height = height_score * normalized_height_weight\n",
    "    weighted_ref_level = reference_level_score * normalized_ref_level_weight\n",
    "\n",
    "    # Combine weighted scores\n",
    "    combined_score = weighted_prob + weighted_width + weighted_height + weighted_ref_level\n",
    "\n",
    "\n",
    "        \n",
    "    # print(\"Probability: %s - SCORE: %s\" %(probability, weighted_prob))\n",
    "    # print(\"Width: %s - SCORE: %s\" %(width, weighted_width))\n",
    "    # print(\"Height: %s - SCORE: %s\" %(height, weighted_height))\n",
    "    # print(\"Reference Level: %s - SCORE: %s\" %(reference_level, weighted_ref_level))\n",
    "    # print(\"==========================================================================\")\n",
    "    # print(\"Total SCORE: %s\" %(combined_score))\n",
    "    # print(\"\")\n",
    "\n",
    "    return combined_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def box_to_corners(box):\n",
    "    u_center, v_center, u_size, v_size = box\n",
    "    half_u_size = u_size / 2\n",
    "    half_v_size = v_size / 2\n",
    "    u_min = u_center - half_u_size\n",
    "    u_max = u_center + half_u_size\n",
    "    v_min = v_center - half_v_size\n",
    "    v_max = v_center + half_v_size\n",
    "    return u_min, v_min, u_max, v_max\n",
    "\n",
    "def compute_iou(box1, box2):\n",
    "    # Convert boxes to corners\n",
    "    u_min1, v_min1, u_max1, v_max1 = box_to_corners(box1)\n",
    "    u_min2, v_min2, u_max2, v_max2 = box_to_corners(box2)\n",
    "    \n",
    "    # Calculate intersection coordinates\n",
    "    inter_u_min = max(u_min1, u_min2)\n",
    "    inter_v_min = max(v_min1, v_min2)\n",
    "    inter_u_max = min(u_max1, u_max2)\n",
    "    inter_v_max = min(v_max1, v_max2)\n",
    "    \n",
    "    # Calculate intersection area\n",
    "    inter_area = max(0, inter_u_max - inter_u_min) * max(0, inter_v_max - inter_v_min)\n",
    "    \n",
    "    # Calculate areas of each box\n",
    "    area1 = (u_max1 - u_min1) * (v_max1 - v_min1)\n",
    "    area2 = (u_max2 - u_min2) * (v_max2 - v_min2)\n",
    "    \n",
    "    # Calculate union area\n",
    "    union_area = area1 + area2 - inter_area\n",
    "    \n",
    "    # Calculate IoU\n",
    "    iou = inter_area / union_area if union_area > 0 else 0\n",
    "    \n",
    "    return iou\n",
    "def compute_parameter_similarity(params1, params2):\n",
    "    # Example: use Euclidean distance and convert it to a similarity score\n",
    "    distance = np.linalg.norm(np.array(params1) - np.array(params2))\n",
    "    similarity = 1 / (1 + distance)  # similarity decreases with distance\n",
    "    return similarity\n",
    "\n",
    "def compute_doorness_similarity(score1, score2):\n",
    "    # Assuming score1 and score2 are probabilities or confidence scores\n",
    "    # Convert them into numpy arrays for easier computation\n",
    "    score1 = np.array(score1)\n",
    "    score2 = np.array(score2)\n",
    "    \n",
    "    # Compute Euclidean distance between the scores\n",
    "    distance = np.linalg.norm(score1 - score2)\n",
    "    \n",
    "    # Similarity is inversely proportional to distance\n",
    "    similarity = 1 / (1 + distance)\n",
    "    \n",
    "    return similarity\n",
    "\n",
    "def find_best_matches(boxes1, boxes2, params1, params2, iou_weight=0.33, param_weight=0.33, doorness_weight=0.33):\n",
    "    matches = []\n",
    "    used_boxes2 = set()\n",
    "\n",
    "    for i, box1 in enumerate(boxes1):\n",
    "        max_score = -1\n",
    "        best_match = -1\n",
    "\n",
    "        for j, box2 in enumerate(boxes2):\n",
    "            if j in used_boxes2:\n",
    "                continue\n",
    "            \n",
    "            iou = compute_iou(box1, box2)\n",
    "            param_similarity = compute_parameter_similarity(params1[i][0:2], params2[j][0:2])\n",
    "            doorness_similarity = compute_doorness_similarity(params1[i][4:5], params2[j][4:5])\n",
    "            \n",
    "            # Combine IoU, parameter similarity, and doorness score into a single score\n",
    "            combined_score = iou_weight * iou + param_weight * param_similarity + doorness_weight * doorness_similarity\n",
    "            \n",
    "            if combined_score > max_score:\n",
    "                max_score = combined_score\n",
    "                best_match = j\n",
    "        \n",
    "        if best_match != -1:\n",
    "            matches.append((i, best_match, max_score))\n",
    "            used_boxes2.add(best_match)\n",
    "        else:\n",
    "            matches.append((i, None, None))\n",
    "\n",
    "    return matches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_boxes(box1, box2):\n",
    "    u_min1, v_min1, u_max1, v_max1 = box_to_corners(box1)\n",
    "    u_min2, v_min2, u_max2, v_max2 = box_to_corners(box2)\n",
    "\n",
    "    combined_u_min = min(u_min1, u_min2)\n",
    "    combined_v_min = min(v_min1, v_min2)\n",
    "    combined_u_max = max(u_max1, u_max2)\n",
    "    combined_v_max = max(v_max1, v_max2)\n",
    "\n",
    "    combined_u_center = (combined_u_min + combined_u_max) / 2\n",
    "    combined_v_center = (combined_v_min + combined_v_max) / 2\n",
    "    combined_u_size = combined_u_max - combined_u_min\n",
    "    combined_v_size = combined_v_max - combined_v_min\n",
    "\n",
    "    return np.array([[combined_u_center, combined_v_center, combined_u_size, combined_v_size]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def line_with_width_coordinates(start, end, percentage, width):\n",
    "    # Calculate the coordinates of the point on the line segment\n",
    "    point_on_line = start + (end - start) * percentage\n",
    "    \n",
    "    # Calculate the direction vector of the line segment\n",
    "    direction = (end - start) / np.linalg.norm(end - start)\n",
    "    \n",
    "    # Calculate the offset for the new line\n",
    "    offset = direction * (width / 2)\n",
    "    \n",
    "    # Calculate the start and end points of the new line\n",
    "    new_start = point_on_line - offset\n",
    "    new_end = point_on_line + offset\n",
    "    \n",
    "    return [new_start, new_end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: Doors_1, doorWidth: 1.1, height: 2.29\n",
      "name: Doors_2, doorWidth: 1.11, height: 2.32\n",
      "name: Doors_3, doorWidth: 1.12, height: 2.33\n",
      "name: Doors_4, doorWidth: 1.11, height: 2.31\n",
      "name: Doors_5, doorWidth: 1.58, height: 2.34\n",
      "name: Doors_6, doorWidth: 1.59, height: 2.32\n",
      "name: Doors_7, doorWidth: 1.6, height: 2.3\n",
      "name: Doors_8, doorWidth: 1.62, height: 2.28\n",
      "name: Doors_9, doorWidth: 3.36, height: 2.3\n",
      "name: Doors_10, doorWidth: 1.12, height: 2.32\n",
      "name: Doors_11, doorWidth: 2.2, height: 2.33\n",
      "name: Doors_12, doorWidth: 1.57, height: 2.29\n",
      "name: Doors_13, doorWidth: 1.61, height: 2.28\n",
      "name: Doors_14, doorWidth: 1.59, height: 2.32\n",
      "name: Doors_15, doorWidth: 1.61, height: 2.3\n",
      "name: Doors_16, doorWidth: 0.87, height: 2.12\n",
      "name: Doors_17, doorWidth: 0.95, height: 2.14\n",
      "name: Doors_18, doorWidth: 0.87, height: 2.12\n",
      "name: Doors_19, doorWidth: 0.89, height: 2.1\n",
      "name: Doors_20, doorWidth: 0.94, height: 2.14\n",
      "name: Doors_21, doorWidth: 0.9, height: 2.11\n",
      "name: Doors_22, doorWidth: 0.96, height: 2.15\n",
      "name: Doors_23, doorWidth: 1.03, height: 2.16\n",
      "name: Doors_24, doorWidth: 0.73, height: 2.04\n",
      "name: Doors_25, doorWidth: 0.58, height: 2.09\n",
      "name: Doors_26, doorWidth: 0.88, height: 2.09\n",
      "name: Doors_27, doorWidth: 0.89, height: 2.09\n",
      "name: Doors_28, doorWidth: 0.87, height: 2.1\n",
      "name: Doors_29, doorWidth: 0.88, height: 2.1\n",
      "name: Doors_30, doorWidth: 0.87, height: 2.1\n",
      "name: Doors_31, doorWidth: 0.92, height: 2.13\n",
      "name: Doors_32, doorWidth: 0.84, height: 2.34\n",
      "name: Doors_33, doorWidth: 1.01, height: 2.35\n",
      "name: Doors_34, doorWidth: 0.85, height: 2.11\n",
      "name: Doors_35, doorWidth: 0.78, height: 2.08\n",
      "name: Doors_36, doorWidth: 0.92, height: 2.11\n",
      "name: Doors_37, doorWidth: 0.84, height: 2.14\n",
      "name: Doors_38, doorWidth: 0.99, height: 2.13\n",
      "name: Doors_39, doorWidth: 0.89, height: 2.08\n",
      "name: Doors_40, doorWidth: 0.89, height: 2.13\n",
      "name: Doors_41, doorWidth: 0.87, height: 2.05\n",
      "name: Doors_42, doorWidth: 0.92, height: 2.11\n",
      "name: Doors_43, doorWidth: 0.82, height: 2.05\n",
      "name: Doors_44, doorWidth: 0.76, height: 2.06\n",
      "name: Doors_45, doorWidth: 0.82, height: 2.11\n",
      "name: Doors_46, doorWidth: 0.82, height: 2.1\n",
      "name: Doors_47, doorWidth: 0.94, height: 2.08\n",
      "name: Doors_48, doorWidth: 4.68, height: 2.13\n",
      "name: Doors_49, doorWidth: 0.73, height: 2.08\n",
      "name: Doors_50, doorWidth: 0.93, height: 2.12\n",
      "name: Doors_51, doorWidth: 0.85, height: 1.76\n",
      "name: Doors_52, doorWidth: 0.78, height: 1.7\n",
      "name: Doors_53, doorWidth: 0.88, height: 2.1\n",
      "name: Doors_54, doorWidth: 0.86, height: 2.14\n",
      "name: Doors_55, doorWidth: 0.91, height: 2.1\n",
      "name: Doors_56, doorWidth: 1.02, height: 2.23\n",
      "name: Doors_57, doorWidth: 0.86, height: 2.09\n",
      "name: Doors_58, doorWidth: 0.85, height: 2.09\n",
      "name: Doors_59, doorWidth: 0.87, height: 2.09\n",
      "name: Doors_60, doorWidth: 0.88, height: 2.09\n",
      "name: Doors_61, doorWidth: 0.71, height: 2.11\n",
      "name: Doors_62, doorWidth: 0.84, height: 2.1\n",
      "name: Doors_63, doorWidth: 0.88, height: 2.09\n",
      "name: Doors_64, doorWidth: 0.88, height: 2.1\n",
      "name: Doors_65, doorWidth: 0.9, height: 1.75\n",
      "name: Doors_66, doorWidth: 0.71, height: 1.77\n",
      "name: Doors_67, doorWidth: 0.73, height: 2.1\n",
      "name: Doors_68, doorWidth: 0.88, height: 2.11\n"
     ]
    }
   ],
   "source": [
    "doorNodes = []\n",
    "pointcloud = []\n",
    "\n",
    "wall = 0\n",
    "count = 0\n",
    "for n in wallNodes: #^22:24 interessante muren\n",
    "    potential_door_boxes_wall = []\n",
    "    potential_door_info_wall = []\n",
    "    potential_door_Nodes = []\n",
    "    if len(n.orthos) > 0 and (len(n.boxes[0]) > 0 or len(n.boxes[1]) > 0):\n",
    "        \n",
    "        for j, boxes in enumerate(n.boxes):\n",
    "            potential_door_boxes_face = []\n",
    "            potential_door_info_face = []\n",
    "            if len(boxes) > 0: \n",
    "                for i, box in enumerate(boxes):\n",
    "                    probability = float(n.logits[j][i])\n",
    "                    # print(\"Probability: \", probability)\n",
    "                    \n",
    "                    opening_width = round(int(np.asarray(box)[2]*n.orthos[j].shape[1])* image_resolution, 2)\n",
    "                    # print(\"Opening Width:\", opening_width)\n",
    "                    \n",
    "                    opening_height = round(int(np.asarray(box)[3]*n.orthos[j].shape[0]) * image_resolution, 2)\n",
    "                    # print(\"Opening height:\", opening_height)\n",
    "                    \n",
    "            \n",
    "                    detection_center_u = int(np.asarray(box)[0]*n.orthos[j].shape[1]) * image_resolution\n",
    "                    detection_center_v = int(np.asarray(box)[1]*n.orthos[j].shape[0]) * image_resolution\n",
    "                    \n",
    "                    reference_level = round((n.orthos[j].shape[0]*image_resolution) - (detection_center_v + opening_height/2), 2)\n",
    "                    # print(\"Reference Level:\", reference_level)\n",
    "                    \n",
    "                    score = is_door(probability, opening_width, opening_height, reference_level)\n",
    "                    # if stand == 1:\n",
    "                    #     points, colors = create_point_cloud(n.orthos[stand], n.endpoint,n.startpoint, box)\n",
    "                    # else:\n",
    "                    #     points, colors = create_point_cloud(n.orthos[stand],n.startpoint, n.endpoint, box)\n",
    "                    if score >= 0.5:\n",
    "                        box1 = copy.deepcopy(box)\n",
    "                        box = box.unsqueeze(0)\n",
    "\n",
    "                        if j == 1:\n",
    "                            box1[0] = 1-box1[0]\n",
    "\n",
    "                        image = extract_box_with_margin(n.orthos[j], box[0])\n",
    "                        image = image[...,::-1] # BGR to RGB\n",
    "                        # if wall == 53:\n",
    "                        #     print(wall)\n",
    "                        #     Image.fromarray(image)#.save(os.path.join(output_folder,(str(wall) +\"-\"+ str(stand)+\"-\" + str(count) +'-DOOR.png')))\n",
    "                        #     annotated_frame_doorness = annotate(image_source= n.orthos[j], boxes=box, logits=torch.from_numpy(np.array([score])), phrases=[n.phrases[j][i]])\n",
    "                        #     # annotated_frame = annotate(image_source= n.orthos[j], boxes=box, logits=n.logits[j][i].unsqueeze(0), phrases=[n.phrases[j][i]])\n",
    "                        #     annotated_frame = annotated_frame[...,::-1] # BGR to RGB\n",
    "                        #     Image.fromarray(annotated_frame_doorness).save(os.path.join(output_folder,(str(wall) +\"-\"+ str(j)+\"-\" + str(count) + '-DOOR-'+str(score*100)+'.png')))\n",
    "                        #     print(\"%s : Door => Referencelevel: %s; Width: %s; Height: %s\" %((str(wall) + \"-\" + str(j) + \"-\" + str(count)), reference_level, opening_width, opening_height))\n",
    "\n",
    "                        # count += 1\n",
    "                        potential_door_boxes_face.append(np.asarray(box1))\n",
    "                        potential_door_info_face.append([opening_width, opening_height, image, reference_level, score])\n",
    "                        \n",
    "                    # else:\n",
    "                    #     image = extract_box_with_margin(n.orthos[stand], box.unsqueeze(0)[0])\n",
    "                    #     image = image[...,::-1] # BGR to RGB\n",
    "                    #     Image.fromarray(image)#.save(os.path.join(output_folder,(str(wall) +\"-\"+ str(stand)+\"-\" + str(count) +'-DOOR.png')))\n",
    "                    #     annotated_frame = annotate(image_source= n.orthos[stand], boxes=box.unsqueeze(0), logits=n.logits[stand][i].unsqueeze(0), phrases=[n.phrases[stand][i]])\n",
    "                    #     annotated_frame = annotated_frame[...,::-1] # BGR to RGB\n",
    "                    #     Image.fromarray(annotated_frame).save(os.path.join(output_folder,(str(wall) +\"-\"+ str(stand)+\"-\" + str(count) +'-DOOR-'+str(score*100)+'.png')))\n",
    "                    #     print(\"%s : No Door => Referencelevel: %s; Width: %s; Height: %s\" %((str(wall) + \"-\" + str(stand) + \"-\" + str(count)), reference_level, opening_width, opening_height))\n",
    "                    #     count += 1\n",
    "                        \n",
    "                    #     if points.size > 0:\n",
    "                    #         # Create Open3D point cloud\n",
    "                    #         pcd_o3d = o3d.geometry.PointCloud()\n",
    "                    #         pcd_o3d.points = o3d.utility.Vector3dVector(points)\n",
    "                    #         pcd_o3d.colors = o3d.utility.Vector3dVector(colors)\n",
    "                    #         o3d.io.write_point_cloud(os.path.join(output_folder,(str(wall) + \"-\" + str(stand) + \"-\" + str(count) + '-DOOR.pcd')), pcd_o3d)\n",
    "                    #         base_points = points[points[:, 2] == 0, :2]\n",
    "                    #         # print(base_points)\n",
    "                    #         min_x_index = np.argmin(points[:, 0])\n",
    "                    #         max_x_index = np.argmax(points[:, 0])\n",
    "                                                        \n",
    "                    #         startpoint = [points[min_x_index][0],points[min_x_index][1],0 ]\n",
    "                    #         endpoint = [points[max_x_index][0],points[max_x_index][1],0 ]\n",
    "                    #         center = compute_center(startpoint, endpoint)\n",
    "                    #         distance = np.sqrt((endpoint[0] - startpoint[0])**2 + (endpoint[1] - startpoint[1])**2)\n",
    "                            \n",
    "                            \n",
    "                    #         # pcd_node = PointCloudNode(resource = pcd_o3d, path = os.path.join(Path(os.getcwd()).parents[0]/'data',(str(wall) + \"-\" + str(stand) + \"-\" + str(count) + '-DOOR.pcd')))\n",
    "                            \n",
    "                    #     on = Node()\n",
    "                    #     on.width = opening_width\n",
    "                    #     on.height = opening_height\n",
    "                    #     on.depth = n.wallThickness\n",
    "                    #     on.pcd = pcd_o3d\n",
    "                    #     on.image = image\n",
    "                    #     on.startpoint = startpoint\n",
    "                    #     on.endpoint = endpoint\n",
    "                    #     on.center = center\n",
    "                    #     on.normal = n.normal\n",
    "                    #     on.host = n\n",
    "                    #     potential_doors.append(on)            \n",
    "            potential_door_boxes_wall.append(potential_door_boxes_face)\n",
    "            potential_door_info_wall.append(potential_door_info_face)\n",
    "        \n",
    "        if len(potential_door_boxes_wall) == len(n.orthos) and not len(potential_door_boxes_wall[0]) == 0 and not len(potential_door_boxes_wall[1]) == 0:\n",
    "            matches = find_best_matches(potential_door_boxes_wall[0], potential_door_boxes_wall[1], potential_door_info_wall[0], potential_door_info_wall[1])\n",
    "            for id0, id1, bestscore in matches:\n",
    "                if not id0 == None and not id1 == None:\n",
    "                    # compare the parameters of the different matches\n",
    "                    info0 = potential_door_info_wall[0][id0]\n",
    "                    info1 = potential_door_info_wall[1][id1]\n",
    "                    image = info0[2]\n",
    "                    # boxestemp = np.array([potential_door_boxes_wall[0][id0],potential_door_boxes_wall[1][id1]])\n",
    "                    detectionbox = combine_boxes(potential_door_boxes_wall[0][id0], potential_door_boxes_wall[1][id1])\n",
    "                    # Image.fromarray(image).save(os.path.join(output_folder,(str(count) +'-DOOR.png')))\n",
    "                    # annotated_frame = annotate(image_source= n.orthos[0], boxes=torch.from_numpy(detectionbox), logits=torch.from_numpy(np.array([bestscore])), phrases=[n.phrases[0][id0]])\n",
    "                    # annotated_frame = annotated_frame[...,::-1] # BGR to RGB\n",
    "                    # Image.fromarray(annotated_frame).save(os.path.join(output_folder,(str(count) +'-DOOR.png')))\n",
    "                    \n",
    "                    \n",
    "                    opening_width = round(int(np.asarray(detectionbox)[0][2]*n.orthos[j].shape[1])* image_resolution, 2)\n",
    "                    # print(\"Opening Width:\", opening_width)\n",
    "                    \n",
    "                    opening_height = round(int(np.asarray(detectionbox)[0][3]*n.orthos[j].shape[0]) * image_resolution, 2)\n",
    "                    \n",
    "                    detection_center_u = int(np.asarray(detectionbox)[0][0]*n.orthos[j].shape[1]) * image_resolution\n",
    "                    detection_center_v = int(np.asarray(detectionbox)[0][1]*n.orthos[j].shape[0]) * image_resolution\n",
    "                    reference_level = round((n.orthos[j].shape[0]*image_resolution) - (detection_center_v + opening_height/2), 2)\n",
    "                    \n",
    "                    # print(\"%s : Door Score: %s => Referencelevel: %s; Width: %s; Height: %s\" %((str(count)), bestscore, reference_level, opening_width, opening_height))\n",
    "                    count += 1\n",
    "                    boundaryPoints = line_with_width_coordinates(n.startpoint, n.endpoint, detectionbox[0][0], opening_width)\n",
    "                    \n",
    "                    doornode = Node()\n",
    "                    doornode.name= \"Doors_\" + str(count)\n",
    "                    doornode.axis=o3d.geometry.LineSet(points=o3d.utility.Vector3dVector(boundaryPoints),lines=o3d.utility.Vector2iVector([[0,1]])).paint_uniform_color([0,0,1])\n",
    "                    doornode.startPoint= boundaryPoints[0]\n",
    "                    doornode.endPoint= boundaryPoints[1]\n",
    "                    doornode.doorWidth = np.round(np.linalg.norm(boundaryPoints[0] - boundaryPoints[1]),2)\n",
    "                    doornode.height = opening_height\n",
    "                    \n",
    "                    pointList=[]\n",
    "                    points=np.asarray(doornode.axis.points)\n",
    "                    # pointList.extend(points+n.sign*n.normal*n.wallThickness/2)\n",
    "                    pointList.extend(points+n.normal*n.wallThickness/2)\n",
    "\n",
    "                    # pointList.extend(points-n.sign*n.normal*n.wallThickness/2)\n",
    "                    pointList.extend(points-n.normal*n.wallThickness/2)\n",
    "\n",
    "                    pointList.extend(np.array(pointList)+np.array([0,0,doornode.height]))\n",
    "                    pcd=o3d.geometry.PointCloud(points=o3d.utility.Vector3dVector(pointList))\n",
    "\n",
    "                    box=pcd.get_oriented_bounding_box()\n",
    "                    doornode.door=o3d.geometry.TriangleMesh.create_from_oriented_bounding_box(box)\n",
    "                    doornode.door.paint_uniform_color(ut.literal_to_array(n.color))\n",
    "                    doornode.doorBox=o3d.geometry.LineSet.create_from_oriented_bounding_box(box)\n",
    "                    doornode.doorBox.paint_uniform_color([0,0,1])\n",
    "                    \n",
    "                    doornode.host = n\n",
    "                    doorNodes.append(doornode)\n",
    "\n",
    "\n",
    "                    print(f'name: {doornode.name}, doorWidth: {doornode.doorWidth}, height: {doornode.height}')\n",
    "                    \n",
    "                    # on.width = opening_width\n",
    "                    # on.height = opening_height\n",
    "                    # on.depth = n.wallThickness\n",
    "                    # # on.pcd = pcd_o3d\n",
    "                    # on.image = image\n",
    "                    # # on.startpoint = startpoint\n",
    "                    # # on.endpoint = endpoint\n",
    "                    # # on.center = center\n",
    "                    # on.normal = n.normal\n",
    "                    # on.host = n\n",
    "                    # potential_doors.append(on)\n",
    "                    # points, colors = create_point_cloud(n.orthos[0],n.startpoint, n.endpoint, detectionbox[0])\n",
    "                    # if points.size > 0:\n",
    "                    # #   # Create Open3D point cloud\n",
    "                    #     pcd_o3d = o3d.geometry.PointCloud()\n",
    "                    #     pcd_o3d.points = o3d.utility.Vector3dVector(points)\n",
    "                    #     pcd_o3d.colors = o3d.utility.Vector3dVector(colors)\n",
    "                    #     o3d.io.write_point_cloud(os.path.join(output_folder,(str(count) + '-DOOR.pcd')), pcd_o3d)\n",
    "                    #     base_points = points[points[:, 2] == 0, :2]\n",
    "                    #     # print(base_points)\n",
    "                    #     min_x_index = np.argmin(points[:, 0])\n",
    "                    #     max_x_index = np.argmax(points[:, 0])\n",
    "                                                    \n",
    "                    #     startpoint = [points[min_x_index][0],points[min_x_index][1],0 ]\n",
    "                    #     endpoint = [points[max_x_index][0],points[max_x_index][1],0 ]\n",
    "                    #     center = compute_center(startpoint, endpoint)\n",
    "                    #     distance = np.sqrt((endpoint[0] - startpoint[0])**2 + (endpoint[1] - startpoint[1])**2)\n",
    "                        \n",
    "                        # pcd_node = PointCloudNode(resource = pcd_o3d, path = os.path.join(Path(os.getcwd()).parents[0]/'data',(str(wall) + \"-\" + str(stand) + \"-\" + str(count) + '-DOOR.pcd')))\n",
    "                \n",
    "\n",
    "        \n",
    "        #compute the IoU of the detections on bopth sides\n",
    "        #Find a matching box with a large IoU on both\n",
    "        \n",
    "            \n",
    "        \n",
    "        \n",
    "         \n",
    "        wall += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_obj_with_submeshes(filename, meshes, mesh_names):\n",
    "    \"\"\"\n",
    "    Write multiple Open3D TriangleMesh objects to a single OBJ file with submeshes.\n",
    "\n",
    "    Parameters:\n",
    "    - filename: str, the name of the output OBJ file.\n",
    "    - meshes: list of open3d.geometry.TriangleMesh, the meshes to write.\n",
    "    - mesh_names: list of str, the names of the submeshes.\n",
    "    \"\"\"\n",
    "    if len(meshes) != len(mesh_names):\n",
    "        raise ValueError(\"meshes and mesh_names must have the same length\")\n",
    "\n",
    "    vertex_offset = 1  # OBJ files are 1-indexed\n",
    "    with open(filename, 'w') as file:\n",
    "        for mesh, name in zip(meshes, mesh_names):\n",
    "            file.write(f\"g {name}\\n\")  # Start a new group for the submesh\n",
    "\n",
    "            # Write vertices\n",
    "            for vertex in mesh.vertices:\n",
    "                file.write(f\"v {vertex[0]} {vertex[1]} {vertex[2]}\\n\")\n",
    "\n",
    "            # Write faces, adjusting indices based on the current offset\n",
    "            for triangle in mesh.triangles:\n",
    "                adjusted_triangle = triangle + vertex_offset\n",
    "                file.write(f\"f {adjusted_triangle[0]} {adjusted_triangle[1]} {adjusted_triangle[2]}\\n\")\n",
    "\n",
    "            # Update the vertex offset for the next mesh\n",
    "            vertex_offset += len(mesh.vertices)\n",
    "\n",
    "# Example usage:\n",
    "# Assuming mesh1 and mesh2 are your Open3D TriangleMesh objects\n",
    "mesh1 = o3d.geometry.TriangleMesh.create_sphere(radius=1.0)\n",
    "mesh1.compute_vertex_normals()\n",
    "\n",
    "mesh2 = o3d.geometry.TriangleMesh.create_box(width=1.0, height=1.0, depth=1.0)\n",
    "mesh2.compute_vertex_normals()\n",
    "\n",
    "write_obj_with_submeshes(os.path.join(output_folder,f'{ut.get_filename(f)}_doors.obj') , [n.door for n in doorNodes], [n.name for n in doorNodes])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def plot_lines(lines, show_centers=True):\n",
    "#     fig, ax = plt.subplots()\n",
    "\n",
    "#     # Iterate over each line and plot it with a different color\n",
    "#     if len(lines[0]) == 2:\n",
    "#         for i, (start, end) in enumerate(lines):\n",
    "#             color = plt.cm.viridis(i / len(lines))  # Get a color from the Viridis colormap\n",
    "#             ax.plot([start[0], end[0]], [start[1], end[1]], color=color)\n",
    "            \n",
    "#             if show_centers:\n",
    "#                 # Compute the center of the line\n",
    "#                 center = compute_center(start, end)\n",
    "                \n",
    "#                 # Plot the center with the same color as the line\n",
    "#                 ax.scatter(center[0], center[1], color=color, label=f'Center {i+1}')\n",
    "\n",
    "#         ax.set_aspect('equal', adjustable='box')  # Set aspect ratio to equal\n",
    "#         ax.set_xlabel('X')\n",
    "#         ax.set_ylabel('Y')\n",
    "#         ax.set_title('Lines with Centers')\n",
    "#         if show_centers:\n",
    "#             ax.legend()\n",
    "#         plt.show()\n",
    "#     else:\n",
    "#         for i, (start, end, _) in enumerate(lines):\n",
    "#             color = plt.cm.viridis(i / len(lines))  # Get a color from the Viridis colormap\n",
    "#             ax.plot([start[0], end[0]], [start[1], end[1]], color=color)\n",
    "            \n",
    "#             if show_centers:\n",
    "#                 # Compute the center of the line\n",
    "#                 center = compute_center(start, end)\n",
    "                \n",
    "#                 # Plot the center with the same color as the line\n",
    "#                 ax.scatter(center[0], center[1], color=color, label=f'Center {i+1}')\n",
    "\n",
    "#         ax.set_aspect('equal', adjustable='box')  # Set aspect ratio to equal\n",
    "#         ax.set_xlabel('X')\n",
    "#         ax.set_ylabel('Y')\n",
    "#         ax.set_title('Lines with Centers')\n",
    "#         if show_centers:\n",
    "#             ax.legend()\n",
    "#         plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def compute_normal(start, end):\n",
    "#     \"\"\"\n",
    "#     Compute the normal vector of a line given its start and end points.\n",
    "    \n",
    "#     Parameters:\n",
    "#         start (tuple): The start point of the line.\n",
    "#         end (tuple): The end point of the line.\n",
    "    \n",
    "#     Returns:\n",
    "#         numpy.ndarray: The computed normal vector.\n",
    "#     \"\"\"\n",
    "#     # Compute the direction vector of the line\n",
    "#     direction = np.array(end) - np.array(start)\n",
    "#     # Compute the normal vector by rotating the direction vector 90 degrees\n",
    "#     normal = np.array([-direction[1], direction[0]])\n",
    "#     # Normalize the normal vector\n",
    "#     normal /= np.linalg.norm(normal)\n",
    "    \n",
    "#     return normal\n",
    "\n",
    "# # Function to calculate the center point of a line segment\n",
    "# def calculate_center(line):\n",
    "#     startpoint, endpoint, _ = line\n",
    "#     return [(startpoint[0] + endpoint[0]) / 2, (startpoint[1] + endpoint[1]) / 2]\n",
    "\n",
    "# # Function to calculate the distance between two points\n",
    "# def calculate_distance(point1, point2):\n",
    "#     return np.linalg.norm(np.array(point1) - np.array(point2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Function to cluster lines based on normals and centers\n",
    "# def cluster_lines(lines, distance_threshold=1, equal_normals = True):\n",
    "    \n",
    "#     cluster_ids = [-1] * len(lines)\n",
    "#     current_cluster_id = 0\n",
    "#     if equal_normals:\n",
    "#         normals = set(tuple(line[2]) for line in lines)  # Convert numpy array to tuple\n",
    "#         for normal in normals:\n",
    "#             lines_with_normal = [line for line in lines if np.array_equal(line[2], normal)]\n",
    "            \n",
    "#             centers = [calculate_center(line) for line in lines_with_normal]\n",
    "            \n",
    "#             # Using DBSCAN for clustering centers\n",
    "#             dbscan = DBSCAN(eps=distance_threshold, min_samples=1, metric=calculate_distance)\n",
    "#             labels = dbscan.fit_predict(centers)\n",
    "            \n",
    "#             unique_labels = set(labels)\n",
    "#             for label in unique_labels:\n",
    "#                 cluster_lines = [lines_with_normal[i] for i in range(len(lines_with_normal)) if labels[i] == label]\n",
    "#                 for line in cluster_lines:\n",
    "#                     line_index = None\n",
    "#                     for i, l in enumerate(lines):\n",
    "#                         if np.array_equal(l, line):\n",
    "#                             line_index = i\n",
    "#                             break\n",
    "#                     cluster_ids[line_index] = current_cluster_id\n",
    "#                 current_cluster_id += 1\n",
    "#     else:            \n",
    "#         centers = [calculate_center(line) for line in lines]\n",
    "        \n",
    "#         # Using DBSCAN for clustering centers\n",
    "#         dbscan = DBSCAN(eps=distance_threshold, min_samples=1, metric=calculate_distance)\n",
    "#         labels = dbscan.fit_predict(centers)\n",
    "        \n",
    "#         unique_labels = set(labels)\n",
    "#         for label in unique_labels:\n",
    "#             cluster_lines = [lines[i] for i in range(len(lines)) if labels[i] == label]\n",
    "#             for line in cluster_lines:\n",
    "#                 line_index = None\n",
    "#                 for i, l in enumerate(lines):\n",
    "#                     if np.array_equal(l, line):\n",
    "#                         line_index = i\n",
    "#                         break\n",
    "#                 cluster_ids[line_index] = current_cluster_id\n",
    "#             current_cluster_id += 1\n",
    "    \n",
    "#     return cluster_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eerste clustering om detecties langst beide kanten te bundelen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def find_outer_points(points):\n",
    "#     # Convert points to numpy array for easier manipulation\n",
    "#     points = np.array(points)\n",
    "    \n",
    "#     # Find the index of the point with the smallest coordinate along the line\n",
    "#     min_index = np.argmin(points[:, 0])  # Assuming the line is along the x-axis\n",
    "    \n",
    "#     # Find the index of the point with the largest coordinate along the line\n",
    "#     max_index = np.argmax(points[:, 0])  # Assuming the line is along the x-axis\n",
    "    \n",
    "#     # Retrieve the two outer points\n",
    "#     outer_point_min = points[min_index]\n",
    "#     outer_point_max = points[max_index]\n",
    "    \n",
    "#     return outer_point_min, outer_point_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def retrieve_all_clusters_indices(cluster_labels):\n",
    "#     all_clusters_indices = []\n",
    "    \n",
    "#     # Get unique cluster labels\n",
    "#     unique_labels = np.unique(cluster_labels)\n",
    "    \n",
    "#     # Iterate through each unique cluster label\n",
    "#     for cluster_label in unique_labels:\n",
    "#         if not cluster_label == -1:\n",
    "#             cluster_indices = [i for i, label in enumerate(cluster_labels) if label == cluster_label]\n",
    "#             all_clusters_indices.append(cluster_indices)\n",
    "#         else: \n",
    "#             for i, label in enumerate(cluster_labels):\n",
    "#                 if label == cluster_label:\n",
    "#                     all_clusters_indices.append([i])\n",
    "    \n",
    "#     return all_clusters_indices\n",
    "\n",
    "# def are_normals_same_direction(objects):\n",
    "#     # Check if all normals have the same direction\n",
    "#     reference_normal = objects[0].normal\n",
    "#     for obj in objects[1:]:\n",
    "#         if not np.allclose(obj.normal, reference_normal):\n",
    "#             return False\n",
    "#     return True\n",
    "\n",
    "# def merge_objects(openings):\n",
    "#     if not are_normals_same_direction(openings):\n",
    "#         on = openings[0]\n",
    "#         return on\n",
    "    \n",
    "#     # Merge objects by finding extreme start and end points\n",
    "#     on = Node()\n",
    "#     on.startpoint, on.endpoint = find_outer_points([obj.startpoint for obj in openings] + [obj.endpoint for obj in openings])\n",
    "#     on.height = sum(n.height for n in openings)/len(openings)\n",
    "#     on.depth = openings[0].depth\n",
    "#     on.pcd = [n.pcd for n in openings]\n",
    "#     on.image = [n.image for n in openings]\n",
    "#     on.center = compute_center(on.startpoint, on.endpoint)\n",
    "#     on.normal = openings[0].normal\n",
    "#     on.host = openings[0].host\n",
    "#     on.width = np.sqrt((on.endpoint[0] - on.startpoint[0])**2 + (on.endpoint[1] - on.startpoint[1])**2)\n",
    "    \n",
    "#     return on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lines = []\n",
    "\n",
    "# for n in potential_doors:\n",
    "#     lines.append([n.startpoint, n.endpoint, n.normal])\n",
    "# print(len(lines))\n",
    "# # plot_lines(lines)\n",
    "# clustered_ids = cluster_lines(lines) \n",
    "# # plot_clustered_lines_separately(lines, clustered_ids)\n",
    "# all_clusters_indices = retrieve_all_clusters_indices(clustered_ids)\n",
    "# clustered_lines = []\n",
    "\n",
    "# for cluster_indices in all_clusters_indices:\n",
    "#     openings = []\n",
    "#     for i in cluster_indices:\n",
    "#         openings.append(potential_doors[i])\n",
    "#     on = merge_objects(openings)\n",
    "#     clustered_lines.append(on)\n",
    "    \n",
    "# lines = []\n",
    "# for n in clustered_lines:\n",
    "#     lines.append([n.startpoint, n.endpoint])\n",
    "    \n",
    "# print(len(lines))\n",
    "\n",
    "# plot_lines(lines, show_centers=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def calculate_percentage_black_pixels(image):\n",
    "#     # Check if the image is a color image (3 channels) or a grayscale image (1 channel)\n",
    "#     if len(image.shape) == 3 and image.shape[2] == 3:\n",
    "#         # Convert the color image to grayscale\n",
    "#         grayscale_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "#     elif len(image.shape) == 2:\n",
    "#         # Image is already grayscale\n",
    "#         grayscale_image = image\n",
    "#     else:\n",
    "#         # Handle other cases or raise an error\n",
    "#         raise ValueError(\"Unsupported image format. Expected color (3 channels) or grayscale (1 channel).\")\n",
    "\n",
    "#     # # Convert the image to grayscale\n",
    "#     # grayscale_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "#     # Count black pixels\n",
    "#     black_pixel_count = cv2.countNonZero(grayscale_image)\n",
    "\n",
    "#     # Calculate total number of pixels\n",
    "#     total_pixels = grayscale_image.shape[0] * grayscale_image.shape[1]\n",
    "\n",
    "#     # Calculate percentage of black pixels\n",
    "#     percentage_black_pixels = (black_pixel_count / total_pixels) * 100\n",
    "\n",
    "#     return percentage_black_pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lines = []\n",
    "\n",
    "# for n in clustered_lines:\n",
    "#     lines.append([n.startpoint, n.endpoint, n.normal])\n",
    "    \n",
    "# clustered_ids = cluster_lines(lines, distance_threshold=1.2, equal_normals = False)\n",
    "# all_clusters_indices = retrieve_all_clusters_indices(clustered_ids)\n",
    "\n",
    "# openings = []\n",
    "# for cluster in all_clusters_indices:\n",
    "#     if len(cluster) > 1:\n",
    "#         l = [clustered_lines[i] for i in cluster]\n",
    "        \n",
    "#         # Plotting the images\n",
    "#         # fig, axes = plt.subplots(1, len(l))            \n",
    "        \n",
    "#         lines = []\n",
    "#         i = 0\n",
    "#         for j, n in enumerate(l):\n",
    "#             lines.append([n.startpoint, n.endpoint, n.normal])\n",
    "#             # axes[i].imshow(Image.fromarray(n.image[0][0]))\n",
    "#             # axes[i].axis('off')\n",
    "#             i+=1\n",
    "#             if calculate_percentage_black_pixels(n.image[0][0]) < 50:\n",
    "#                 openings.append(n)\n",
    "#                 for jj, n2 in enumerate(l): \n",
    "#                     if not jj == j:\n",
    "#                         if np.array_equal(n.normal, n2.normal):\n",
    "#                             openings.append(n2)\n",
    "                \n",
    "#         # plot_lines(lines)\n",
    "#     else:\n",
    "#         openings.append(clustered_lines[cluster[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lines =[]\n",
    "# for n in openings:\n",
    "#     # n.center = compute_center(n.startpoint, n.endpoint)\n",
    "#     lines.append([n.startpoint, n.endpoint, n.normal])\n",
    "    \n",
    "    \n",
    "# print(len(lines))\n",
    "# plot_lines(lines, show_centers=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Compare ground truth nodes with computed nodes\n",
    "# # print(len(groundtruthNodes))\n",
    "# for ground_truth_node in groundtruthNodes:\n",
    "#     min_distance = float('inf')\n",
    "#     best_node = None\n",
    "#     for computed_node in openings:\n",
    "#         # print(ground_truth_node.center)\n",
    "#         # print(compute_center(computed_node.startpoint, computed_node.endpoint))\n",
    "#         # print(computed_node.center)\n",
    "#         distance = calculate_distance(ground_truth_node.center, computed_node.center)\n",
    "#         if distance < min_distance:\n",
    "#             min_distance = distance\n",
    "#             best_node = computed_node\n",
    "#     print('Found match on: %s'% (min_distance))\n",
    "#     print('WIDTH = GT: %s, Computed: %s' %(ground_truth_node.width, best_node.width))\n",
    "#     print('DEPTH = GT: %s, Computed: %s' %(ground_truth_node.depth, best_node.depth))\n",
    "#     print('HEIGHT = GT: %s, Computed: %s' %(ground_truth_node.height, best_node.height))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Lists to store coordinates of matched, unmatched ground truth nodes, and unmatched computed nodes\n",
    "# matched_gt_x = []\n",
    "# matched_gt_y = []\n",
    "# matched_near_gt_x = []\n",
    "# matched_near_gt_y = []\n",
    "# unmatched_gt_x = []\n",
    "# unmatched_gt_y = []\n",
    "# unmatched_calc_x = []\n",
    "# unmatched_calc_y = []\n",
    "\n",
    "# # Iterate through each ground truth node\n",
    "# for ground_truth_node in groundtruthNodes:\n",
    "#     min_distance = float('inf')\n",
    "#     best_node = None\n",
    "    \n",
    "#     # Iterate through each computed node\n",
    "#     for computed_node in openings:\n",
    "#         distance = calculate_distance(ground_truth_node.center, computed_node.center)\n",
    "        \n",
    "#         if distance < min_distance:\n",
    "#             min_distance = distance\n",
    "#             best_node = computed_node\n",
    "    \n",
    "#     # Check if a match was found\n",
    "#     if min_distance < 0.25:\n",
    "#         matched_gt_x.append(ground_truth_node.center[0])\n",
    "#         matched_gt_y.append(ground_truth_node.center[1])\n",
    "#     elif min_distance < 0.5:  # Check if the matched node is less than 1m\n",
    "#         matched_near_gt_x.append(ground_truth_node.center[0])\n",
    "#         matched_near_gt_y.append(ground_truth_node.center[1])\n",
    "#     else:\n",
    "#         unmatched_gt_x.append(ground_truth_node.center[0])\n",
    "#         unmatched_gt_y.append(ground_truth_node.center[1])\n",
    "\n",
    "# # Iterate through each computed node and check if it was matched\n",
    "# for computed_node in openings:\n",
    "#     matched = False\n",
    "#     for ground_truth_node in groundtruthNodes:\n",
    "#         distance = calculate_distance(ground_truth_node.center, computed_node.center)\n",
    "#         if distance < 0.5:\n",
    "#             matched = True\n",
    "#             break\n",
    "#     if not matched:\n",
    "#         unmatched_calc_x.append(computed_node.center[0])\n",
    "#         unmatched_calc_y.append(computed_node.center[1])\n",
    "\n",
    "# # Plot matched ground truth nodes in green\n",
    "# plt.scatter(matched_gt_x, matched_gt_y, color='green', label='Matched Ground Truth (<0.5m)')\n",
    "\n",
    "# # Plot matched ground truth nodes in orange (between 0.5m and 1m)\n",
    "# plt.scatter(matched_near_gt_x, matched_near_gt_y, color='orange', label='Matched Ground Truth (0.5m-1m)')\n",
    "\n",
    "# # Plot unmatched ground truth nodes in gray\n",
    "# plt.scatter(unmatched_gt_x, unmatched_gt_y, color='gray', label='Unmatched Ground Truth')\n",
    "\n",
    "# # Plot unmatched computed nodes in red\n",
    "# plt.scatter(unmatched_calc_x, unmatched_calc_y, color='red', label='Unmatched Computed')\n",
    "\n",
    "# plt.xlabel('X Coordinate')\n",
    "# plt.ylabel('Y Coordinate')\n",
    "# plt.title('Matching Results')\n",
    "# plt.legend()\n",
    "# plt.grid(True)\n",
    "# plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CVPR2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
