{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "#IMPORT PACKAGES\n",
    "from rdflib import Graph\n",
    "import rdflib\n",
    "import os.path\n",
    "import importlib\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import xml.etree.ElementTree as ET\n",
    "import open3d as o3d\n",
    "import uuid    \n",
    "import pye57 \n",
    "import ifcopenshell\n",
    "import ifcopenshell.geom as geom\n",
    "import ifcopenshell.util\n",
    "from ifcopenshell.util.selector import Selector\n",
    "import multiprocessing\n",
    "import random as rd\n",
    "import pandas as pd\n",
    "# from tabulate import tabulate\n",
    "import cv2\n",
    "import laspy\n",
    "import json\n",
    "from scipy.spatial.transform import Rotation   \n",
    "import copy\n",
    "import geomapi\n",
    "from geomapi.nodes import *\n",
    "import geomapi.utils as ut\n",
    "from geomapi.utils import geometryutils as gmu\n",
    "import geomapi.tools as tl\n",
    "from scipy.linalg import orthogonal_procrustes\n",
    "import matplotlib.pyplot as plt\n",
    "import geomapi.tools.progresstools as pt\n",
    "\n",
    "from sklearn.cluster import DBSCAN\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## INPUTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "name='05_MedOffice_01_F2'\n",
    "\n",
    "path=Path(os.getcwd()).parents[0]/'data'\n",
    "pcd_input_path=os.path.join(path, 't0', 'results',f'{name}_pcd.laz')\n",
    "class_file=path/'_classes.json'\n",
    "\n",
    "# name=name.split('_')[0]\n",
    "# json_output_path=os.path.join(path,f'{name}_walls.json') \n",
    "# geometry_output_path= os.path.join(path,f'{name}_walls.obj') # these are the bounding surfaces of the reference levels (optional)\n",
    "output_dir = \"C:\\Data\\temp\"\n",
    "\n",
    "graphPath=str(os.path.join(path, 't0', 'results',f'{name}_graph.ttl'))\n",
    "\n",
    "grid_resolution = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'classes': [{'name': 'Unassigned', 'id': 255, 'temp_id': 0, 'color': '#9da2ab'}, {'name': 'Floors', 'id': 0, 'temp_id': 1, 'color': '#03c2fc'}, {'name': 'Ceilings', 'id': 1, 'temp_id': 2, 'color': '#e81416'}, {'name': 'Walls', 'id': 2, 'temp_id': 3, 'color': '#ffa500'}, {'name': 'Columns', 'id': 3, 'temp_id': 4, 'color': '#faeb36'}, {'name': 'Doors', 'id': 4, 'temp_id': 5, 'color': '#79c314'}, {'name': 'Windows', 'id': 5, 'temp_id': 6, 'color': '#4b369d'}], 'default': 255, 'type': 'semantic_segmentation', 'format': 'kitti', 'created_with': {'name': 'Saiga', 'version': '1.0.1'}}\n"
     ]
    }
   ],
   "source": [
    "# Read the JSON file\n",
    "with open(class_file, 'r') as file:\n",
    "    json_data = json.load(file)\n",
    "\n",
    "# Create a dictionary\n",
    "class_dict = {\n",
    "    'classes': json_data['classes'],\n",
    "    'default': json_data['default'],\n",
    "    'type': json_data['type'],\n",
    "    'format': json_data['format'],\n",
    "    'created_with': json_data['created_with']\n",
    "}\n",
    "print(class_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 wallNodes detected!\n",
      "0 wallNodes detected!\n",
      "0 ceilingsNodes detected!\n",
      "0 floorsNodes detected!\n",
      "0 clutterNodes detected!\n"
     ]
    }
   ],
   "source": [
    "graph=Graph().parse(graphPath)\n",
    "nodes=tl.graph_to_nodes(graph)\n",
    "wallBIMNodes=[n for n in nodes if 'Walls' in n.subject and type(n)==BIMNode]\n",
    "wallPCDNodes=[n for n in nodes if 'Walls' in n.subject and type(n)==PointCloudNode]\n",
    "ceilingsNodes=[n for n in nodes if 'Ceilings' in n.subject and type(n)==PointCloudNode]\n",
    "floorsNodes=[n for n in nodes if 'Floors' in n.subject and type(n)==PointCloudNode]\n",
    "clutterNodes=[n for n in nodes if 'Clutter' in n.subject and type(n)==PointCloudNode]\n",
    "print(f'{len(wallBIMNodes)} wallNodes detected!')\n",
    "print(f'{len(wallPCDNodes)} wallNodes detected!')\n",
    "print(f'{len(ceilingsNodes)} ceilingsNodes detected!')\n",
    "print(f'{len(floorsNodes)} floorsNodes detected!')\n",
    "print(f'{len(clutterNodes)} clutterNodes detected!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print({key:value for key, value in wallBIMNodes[1].__dict__.items() if not key.startswith('__') and not callable(key)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import PCD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "laz=laspy.read(pcd_input_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "match point clouds with graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in clutterNodes:#+ceilingsNodes+floorsNodes: # this is quite slow because you iterate through 2 scalar fields every time\n",
    "    idx=np.where((laz['classes']==n.class_id) & (laz['objects']==n.object_id))\n",
    "    pcd=o3d.geometry.PointCloud()\n",
    "    pcd.points=o3d.utility.Vector3dVector(laz.xyz[idx])\n",
    "    red = laz['red'][idx]\n",
    "    green = laz['green'][idx]\n",
    "    blue = laz['blue'][idx]\n",
    "    #if color is 32 bit, only keep 8 bit color\n",
    "    if red.max()>255:\n",
    "        red = laz['red'][idx] >> 8 & 0xFF\n",
    "        green = laz['green'][idx] >> 8 & 0xFF\n",
    "        blue = laz['blue'][idx] >> 8 & 0xFF\n",
    "    # if colorspace is [0-255] -> remap to [0-1]\n",
    "    if red.max() >1:\n",
    "        red=red/255\n",
    "        green=green/255\n",
    "        blue=blue/255\n",
    "    pcd.colors=o3d.utility.Vector3dVector(np.vstack((red,green,blue)).transpose())\n",
    "\n",
    "    n.resource=pcd\n",
    "    n.get_oriented_bounding_box()\n",
    "    n.orientedBoundingBox.color=[1,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in wallPCDNodes:#+ceilingsNodes+floorsNodes: # this is quite slow because you iterate through 2 scalar fields every time\n",
    "    idx=np.where((laz['classes']==n.class_id) & (laz['objects']==n.object_id))\n",
    "    pcd=o3d.geometry.PointCloud()\n",
    "    pcd.points=o3d.utility.Vector3dVector(laz.xyz[idx])\n",
    "    pcd.paint_uniform_color([0.5,0.5,0.5])\n",
    "    \n",
    "    red = laz['red'][idx]\n",
    "    green = laz['green'][idx]\n",
    "    blue = laz['blue'][idx]\n",
    "    #if color is 32 bit, only keep 8 bit color\n",
    "    if red.max()>255:\n",
    "        red = laz['red'][idx] >> 8 & 0xFF\n",
    "        green = laz['green'][idx] >> 8 & 0xFF\n",
    "        blue = laz['blue'][idx] >> 8 & 0xFF\n",
    "    # if colorspace is [0-255] -> remap to [0-1]\n",
    "    if red.max() >1:\n",
    "        red=red/255\n",
    "        green=green/255\n",
    "        blue=blue/255\n",
    "    \n",
    "    pcd.colors=o3d.utility.Vector3dVector(np.column_stack((red, green, blue)))\n",
    "\n",
    "    n.resource=pcd\n",
    "    n.get_oriented_bounding_box()\n",
    "    n.orientedBoundingBox.color=[1,0,0] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "match PointCloudNodes to BIMNodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in wallBIMNodes:\n",
    "    n.derivedFrom = next(p for p in wallPCDNodes if p.subject.toPython() in [w.derivedFrom for w in wallBIMNodes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# joined_pcd=gmu.join_geometries([n.resource.paint_uniform_color(ut.literal_to_array(n.color)) for n in wallPCDNodes if n.resource is not None])\n",
    "# o3d.visualization.draw_geometries([joined_pcd])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Reference Levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "levelNodes=[n for n in nodes if 'level' in n.subject]\n",
    "referenceNodes=[]\n",
    "for l in levelNodes:\n",
    "    new_graph=ut.get_subject_graph(graph,levelNodes[0].subject)\n",
    "    n=SessionNode(graph=new_graph)\n",
    "    n.get_oriented_bounding_box()\n",
    "    n.resource=o3d.geometry.TriangleMesh.create_from_oriented_bounding_box(n.orientedBoundingBox)\n",
    "    referenceNodes.append(n) # something is wrong in the tl.graph_to_nodes function\n",
    "levelNodes=referenceNodes\n",
    "print(f'{len(levelNodes)} levelNodes detected!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import ceilings and floors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in ceilingsNodes+floorsNodes: # this is quite slow because you iterate through 2 scalar fields every time\n",
    "    idx=np.where((laz['classes']==n.class_id) & (laz['objects']==n.object_id))\n",
    "    pcd=o3d.geometry.PointCloud()\n",
    "    pcd.points=o3d.utility.Vector3dVector(laz.xyz[idx])\n",
    "    n.resource=pcd\n",
    "    n.get_oriented_bounding_box()\n",
    "    n.orientedBoundingBox.color=[1,1,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PROCESSING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert dtrings from the graph to arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in wallBIMNodes:\n",
    "    n.startpoint = np.asarray(n.startpoint[1:-1].split(), dtype=float)\n",
    "    n.endpoint = np.asarray(n.endpoint[1:-1].split(), dtype=float)\n",
    "    n.normal = np.asarray(n.normal[1:-1].split(), dtype=float)\n",
    "    n.height = float(n.height)\n",
    "    n.name = n.subject.split('///')[-1]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def points_on_line(point1, point2, step_size):\n",
    "    \"\"\"\n",
    "    Generate points on a line between two given points with a specified step size.\n",
    "\n",
    "    Parameters:\n",
    "    - point1: The starting point of the line.\n",
    "    - point2: The ending point of the line.\n",
    "    - step_size: The step size between consecutive points.\n",
    "\n",
    "    Returns:\n",
    "    - points: A list of points on the line.\n",
    "    \"\"\"\n",
    "    # Calculate the direction vector\n",
    "    direction = point2 - point1\n",
    "\n",
    "    # Calculate the length of the line segment\n",
    "    length = np.linalg.norm(direction)\n",
    "\n",
    "    # Normalize the direction vector\n",
    "    direction /= length\n",
    "\n",
    "    # Calculate the number of steps needed\n",
    "    num_steps = int(length / step_size)\n",
    "\n",
    "    # Generate points along the line\n",
    "    points = np.array([point1 + i * step_size * direction for i in range(num_steps + 1)])\n",
    "\n",
    "    return points\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the full resolution point cloud for a more accurate result (unlabeled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "laz = laspy.read(os.path.join(Path(os.getcwd()).parents[0]/'data',\"full_resolution_populierenhof.las\"))\n",
    "full_res_point_cloud_o3d = gmu.las_to_pcd(laz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the full point cloud into a mesh and add it to a raycasting scene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Cut a part out of the full resolution pointcloud\n",
    "# joined_pcd = full_res_point_cloud_o3d.crop(expanded_bounding_box)\n",
    "#Create a messh from this point cloud \n",
    "octree=pt.pcd_to_octree(full_res_point_cloud_o3d,10) #if octree is None else octree\n",
    "mesh=gmu.octree_to_voxelmesh(octree) #if mesh is None else mesh\n",
    "\n",
    "\n",
    "#Create a identity array containing the color so this can be retrieved afterwards\n",
    "original_colors=np.asarray(mesh.vertex_colors)\n",
    "indices=np.asarray(mesh.triangles)[:,0]\n",
    "triangle_colors=original_colors[indices]\n",
    "#append black color at the end of the array for the invalid hits\n",
    "triangle_colors=np.vstack((triangle_colors,np.array([0,0,0])))\n",
    "\n",
    "# Create raycasting scene\n",
    "scene = o3d.t.geometry.RaycastingScene()\n",
    "mesh=o3d.t.geometry.TriangleMesh.from_legacy(mesh)\n",
    "scene.add_triangles(mesh) \n",
    "\n",
    "# Calculate the size of each octree node based on octree depth and overall size\n",
    "def calculate_node_size(octree_depth, octree_size):\n",
    "    num_voxels_per_dim = 2 ** octree_depth\n",
    "    voxel_size = octree_size / num_voxels_per_dim\n",
    "    return voxel_size\n",
    "\n",
    "# Example usage:\n",
    "octree_depth = octree.max_depth  # Example value for max_depth\n",
    "octree_size = octree.size  # Example size of the octree in world units\n",
    "voxel_size = calculate_node_size(octree_depth, octree_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_door(openingwidth, openingheight, t_min_width = 0.5, t_max_width = 3, t_min_height = 1.5, t_max_height = 2.3):\n",
    "\n",
    "    if t_min_width < openingwidth < t_max_width and t_min_height < openingheight < t_max_height:\n",
    "        return True\n",
    "    else: \n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 1: Using the pointcloud and wall data to retrieve potential openings in the walls \n",
    "(Can also be used to retrieve wall detailing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_opening_pcds(startpoint, endpoint, height, resolution, direction, scene, offset =0.7, path = None, show = False, min_samples = 5000, eps = 0.2, wallThickness = 0.1, voxel_size = 0.01):\n",
    "    \n",
    "#     min_z = np.min([endpoint[2], startpoint[2]])\n",
    "#     max_z = min_z + height\n",
    "#     num_z_steps = int(height /resolution)\n",
    "#     z_grid = np.linspace(min_z, max_z, num_z_steps)  # Adjust the number of grid points as needed\n",
    "#     xyz_grid = []\n",
    "#     for z in z_grid:\n",
    "#         start = n.startpoint.copy()\n",
    "#         end =  n.endpoint.copy()\n",
    "#         start[2] = z\n",
    "#         end[2] = z\n",
    "#         xyz_grid.append(points_on_line(start, end, resolution))\n",
    "\n",
    "#     grid = np.asarray(xyz_grid).reshape((-1, 3), order='C') \n",
    "    \n",
    "#     openingpcds = []\n",
    "#     # Create Open3D point cloud\n",
    "#     grid_center_pcd = o3d.geometry.PointCloud()\n",
    "#     grid_center_pcd.points = o3d.utility.Vector3dVector(np.asarray(grid))\n",
    "#     grid_center_pcd.paint_uniform_color([1,0,0])\n",
    "\n",
    "#     #In face is the dominant side of the wall\n",
    "#     grid_in = grid + direction*offset\n",
    "#     #out face is the other side of the dominant side\n",
    "#     grid_out = grid - direction*offset\n",
    "\n",
    "#     #create rays for the in side (towards the dominant side\n",
    "#     ori_x = direction[0] * np.ones(len(grid))\n",
    "#     ori_y = direction[1] * np.ones(len(grid))\n",
    "#     ori_z = direction[2] * np.ones(len(grid))\n",
    "    \n",
    "#     pos_x = grid_in[:,0]\n",
    "#     pos_y = grid_in[:,1]\n",
    "#     pos_z = grid_in[:,2]\n",
    "\n",
    "#     # Stack the calculated values along the third axis to create the grid\n",
    "#     rays_in_values = np.stack((pos_x, pos_y, pos_z, -ori_x, -ori_y, -ori_z), axis=1)\n",
    "#     rays_in_tensor = o3d.core.Tensor(rays_in_values, dtype=o3d.core.Dtype.Float32)\n",
    "\n",
    "#     pos_x = grid_out[:,0]\n",
    "#     pos_y = grid_out[:,1]\n",
    "#     pos_z = grid_out[:,2]\n",
    "\n",
    "#     rays_out_values = np.stack((pos_x, pos_y, pos_z, ori_x, ori_y, ori_z), axis=1)\n",
    "#     rays_out_tensor = o3d.core.Tensor(rays_out_values, dtype=o3d.core.Dtype.Float32)       \n",
    "\n",
    "#     ans_in = scene.cast_rays(rays_in_tensor)\n",
    "#     ans_out = scene.cast_rays(rays_out_tensor)\n",
    "\n",
    "#     hits_in = ans_in['t_hit'].numpy()\n",
    "#     hits_out = ans_out['t_hit'].numpy()\n",
    "\n",
    "#     opening_points = []\n",
    "#     opening_colors = []\n",
    "    \n",
    "#     colors = np.zeros((len(hits_in), 3))\n",
    "#     for i, c in enumerate(colors):\n",
    "#         if hits_in[i] > 2*offset and hits_out[i] > 2*offset:\n",
    "#             colors[i] = [0,1,0]\n",
    "#             opening_points.append(grid[i])\n",
    "#             opening_colors.append([0,1,0])\n",
    "\n",
    "#         elif hits_in[i] <2*offset or hits_out[i] < 2*offset:\n",
    "#             colors[i] = [0.5,0.5,0.5]\n",
    "#             thickness = 2*offset-hits_out[i]-hits_in[i]\n",
    "    \n",
    "#             if 1.2*voxel_size < thickness < 0.5*wallThickness:\n",
    "#                 # colors[i] = [1,0.5,0]\n",
    "#                 opening_points.append(grid[i])\n",
    "#                 opening_colors.append([0,1,0])\n",
    "\n",
    "\n",
    "#     # grid_center_pcd.colors =o3d.utility.Vector3dVector(np.asarray(colors))\n",
    "#     opening_pcd = o3d.geometry.PointCloud()\n",
    "#     opening_pcd.points = o3d.utility.Vector3dVector(np.asarray(opening_points))\n",
    "#     opening_pcd.colors = o3d.utility.Vector3dVector(np.asarray(opening_colors))\n",
    "    \n",
    "#     opening_pcd, ind = opening_pcd.remove_radius_outlier(nb_points = 100, radius = 0.1)\n",
    "\n",
    "#     # o3d.visualization.draw_geometries([opening_pcd])\n",
    "\n",
    "#     points = np.asarray(opening_pcd.points)\n",
    "#     if len(points) > min_samples:\n",
    "\n",
    "#         # Perform clustering using DBSCAN\n",
    "#         dbscan = DBSCAN(eps=eps, min_samples=min_samples)\n",
    "#         labels = dbscan.fit_predict(points)\n",
    "\n",
    "#         # Extract unique cluster labels (excluding noise label -1)\n",
    "#         unique_labels = np.unique(labels[labels != -1])\n",
    "\n",
    "#         # Iterate over each cluster label and save corresponding points to a separate point cloud\n",
    "#         for label in unique_labels:\n",
    "#             cluster_points = points[labels == label]\n",
    "#             cluster_pcd = o3d.geometry.PointCloud()\n",
    "#             cluster_pcd.points = o3d.utility.Vector3dVector(cluster_points)\n",
    "#             openingpcds.append(cluster_pcd)\n",
    "#     if show:\n",
    "#         o3d.visualization.draw_geometries(openingpcds)\n",
    "#     # o3d.visualization.draw_geometries([grid_center_pcd])\n",
    "   \n",
    "#     return openingpcds\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pcd_resolution = 0.01\n",
    "# for n in wallBIMNodes:\n",
    "    \n",
    "#     length = np.sqrt(np.sum((n.endpoint - n.startpoint)**2))\n",
    "#     surface = length * n.height\n",
    "#     n.openings1 = []\n",
    "\n",
    "#     if not surface < 3 and n.height > 1.5 and length > 0.8:\n",
    "                \n",
    "#         n.openings1 = create_opening_pcds(startpoint = n.startpoint, endpoint = n.endpoint, height=n.height, resolution= 0.01, direction= n.normal, scene= scene, offset =0.5, path = None, show = False, min_samples = 1000, eps = 0.25, wallThickness = n.wallThickness, voxel_size=voxel_size)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# doors = []\n",
    "# other = []\n",
    "# for n in wallBIMNodes:\n",
    "#     n.baseConstraint = next(l for l in levelNodes if l.subject.toPython() in [w.base_constraint for w in wallBIMNodes])\n",
    "    \n",
    "#     if len(n.openings1) > 0:\n",
    "#         for opening in n.openings1:\n",
    "#             # Extract the z-coordinates\n",
    "#             points2 = np.asarray(opening.points)\n",
    "#             z_values = points2[:, 2]\n",
    "#             unique_z_values = np.unique(z_values)\n",
    "\n",
    "#             #Compute the width of the opening\n",
    "#             opening_width = 0.0\n",
    "#             for z_value in unique_z_values:\n",
    "#                 # Get points with the current z-value\n",
    "#                 points_with_same_z = points2[z_values == z_value]\n",
    "\n",
    "#                 # Find the outermost points based on XY coordinates\n",
    "#                 min_x = np.min(points_with_same_z[:, 0])\n",
    "#                 max_x = np.max(points_with_same_z[:, 0])\n",
    "#                 min_y = np.min(points_with_same_z[:, 1])\n",
    "#                 max_y = np.max(points_with_same_z[:, 1])\n",
    "\n",
    "#                 # Compute the diagonal length of the bounding box\n",
    "#                 diagonal_length = np.linalg.norm([max_x - min_x, max_y - min_y])\n",
    "\n",
    "#                 if diagonal_length > opening_width:\n",
    "#                     opening_width = diagonal_length\n",
    "                    \n",
    "#             print(\"Opening Width:\", opening_width)\n",
    "            \n",
    "#             #Compute the Height of the door\n",
    "#             lowest_z = np.min(z_values)\n",
    "#             highest_z = np.max(z_values)\n",
    "#             opening_height = highest_z - lowest_z   \n",
    "#             print(\"Opening height:\", opening_height)\n",
    "            \n",
    "#             #Depth should be equal to the wall thickness\n",
    "            \n",
    "#             if is_door(openingwidth = opening_width, openingheight = opening_height):\n",
    "#                 doors.append(opening)\n",
    "#                 print(\"This is most likely a door\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # o3d.visualization.draw_geometries(doors)\n",
    "# joined_pcd=gmu.join_geometries(doors)\n",
    "# o3d.io.write_point_cloud(os.path.join(Path(os.getcwd()).parents[0]/'data', \"doors.pcd\"), joined_pcd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 2: Using the pointcloud and wall data to create an ortho foto of the wall and use object detection\n",
    "(Can also be used to retrieve other elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_wall_ortho(startpoint, endpoint, height, resolution, direction, scene, offset =1, path = None, show = False, dominant = True, max_distance = 0.5, min_distance = 0.5):\n",
    "    image_size = (int(np.sqrt(np.sum((endpoint - startpoint)**2)) / resolution)+1, int(height / resolution))\n",
    "    \n",
    "    min_z = np.min([endpoint[2], startpoint[2]])\n",
    "    max_z = min_z + height\n",
    "    num_z_steps = int(height /resolution)\n",
    "    z_grid = np.linspace(min_z, max_z, num_z_steps)  # Adjust the number of grid points as needed\n",
    "    z_grid = z_grid[::-1]\n",
    "    xyz_grid = []\n",
    "    for z in z_grid:\n",
    "        start = startpoint.copy()\n",
    "        end =  endpoint.copy()\n",
    "        start[2] = z\n",
    "        end[2] = z\n",
    "        if not dominant:\n",
    "            xyz_grid.append(points_on_line(start, end, resolution)[::-1])\n",
    "        else: \n",
    "            xyz_grid.append(points_on_line(start, end, resolution))\n",
    "\n",
    "    grid = np.asarray(xyz_grid).reshape((-1, 3), order='C') \n",
    "    ray_grid = grid + direction*offset\n",
    "    \n",
    "    #create rays for the in side (towards the dominant side\n",
    "    ori_x = direction[0] * np.ones(len(ray_grid))\n",
    "    ori_y = direction[1] * np.ones(len(ray_grid))\n",
    "    ori_z = direction[2] * np.ones(len(ray_grid))\n",
    "    \n",
    "    pos_x = ray_grid[:,0]\n",
    "    pos_y = ray_grid[:,1]\n",
    "    pos_z = ray_grid[:,2]\n",
    "    \n",
    "    # Stack the calculated values along the third axis to create the grid\n",
    "    rays_values = np.stack((pos_x, pos_y, pos_z, -ori_x, -ori_y, -ori_z), axis=1)\n",
    "    rays_tensor = o3d.core.Tensor(rays_values, dtype=o3d.core.Dtype.Float32)\n",
    "    \n",
    "    ans= scene.cast_rays(rays_tensor) \n",
    "    \n",
    "    \n",
    "    triangle_ids = ans[\"primitive_ids\"].numpy() # triangles     \n",
    "    triangle_ids = triangle_ids.flatten()\n",
    "    np.put(triangle_ids,np.where(triangle_ids==scene.INVALID_ID),triangle_colors.shape[0]-1) # replace invalid id's by last (which is the above added black color)\n",
    "    \n",
    "    # Get the hit distances for each ray\n",
    "    hit_distances = ans[\"t_hit\"].numpy().flatten()\n",
    "    \n",
    "    # Filter out hits that are too far or too close\n",
    "    if max_distance is not None:\n",
    "        triangle_ids[hit_distances > max_distance+offset] = triangle_colors.shape[0] - 1  # Set to black\n",
    "        \n",
    "    if min_distance is not None:\n",
    "        triangle_ids[hit_distances < min_distance] = triangle_colors.shape[0] - 1  # Set to black\n",
    "    \n",
    "    colors = triangle_colors[triangle_ids]\n",
    "    ortho = np.reshape(colors,(image_size[1],image_size[0],3))\n",
    "    \n",
    "    if show:\n",
    "        plt.imshow(ortho)\n",
    "        plt.show()\n",
    "    if path:\n",
    "        image = Image.fromarray((ortho * 255).astype(np.uint8))\n",
    "        # Save the image\n",
    "        image.save(path)\n",
    "        \n",
    "    return ortho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_resolution = 0.01\n",
    "\n",
    "for n in wallBIMNodes:\n",
    "    \n",
    "    length = np.sqrt(np.sum((n.endpoint - n.startpoint)**2))\n",
    "    surface = length * n.height\n",
    "    image_size = (int(length / image_resolution), int(n.height / image_resolution))\n",
    "    n.orthos = []\n",
    "    \n",
    "\n",
    "    if not surface < 3 and n.height > 1.5 and length > 0.8:  \n",
    "        #Create an ortho of the dominant side of the wall      \n",
    "        ortho = create_wall_ortho(startpoint = n.startpoint, endpoint= n.endpoint, height= n.height, resolution = image_resolution, direction = n.normal, scene=scene)\n",
    "        n.orthos.append(ortho)\n",
    "        #Also create an ortho of the other side of the wall\n",
    "        if not n.wallThickness == 0.1: #Single faced wall only needs one side\n",
    "            ortho = create_wall_ortho(startpoint = n.startpoint, endpoint= n.endpoint, height= n.height, resolution = image_resolution, direction = -n.normal, scene=scene, dominant = False)\n",
    "            n.orthos.append(ortho)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "from torchvision.ops import box_convert\n",
    "\n",
    "# Grounding DINO\n",
    "from groundingdino.models import build_model\n",
    "from groundingdino.util.slconfig import SLConfig\n",
    "from groundingdino.util.utils import clean_state_dict\n",
    "from groundingdino.util.inference import annotate, load_image, predict\n",
    "\n",
    "import supervision as sv\n",
    "\n",
    "# segment anything\n",
    "# from segment_anything import build_sam, SamPredictor \n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# diffusers\n",
    "import torch\n",
    "\n",
    "from huggingface_hub import hf_hub_download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_hf(repo_id, filename, ckpt_config_filename, device='cpu'):\n",
    "    cache_config_file = hf_hub_download(repo_id=repo_id, filename=ckpt_config_filename)\n",
    "\n",
    "    args = SLConfig.fromfile(cache_config_file) \n",
    "    model = build_model(args)\n",
    "    args.device = device\n",
    "\n",
    "    cache_file = hf_hub_download(repo_id=repo_id, filename=filename)\n",
    "    checkpoint = torch.load(cache_file, map_location='cpu')\n",
    "    log = model.load_state_dict(clean_state_dict(checkpoint['model']), strict=False)\n",
    "    print(\"Model loaded from {} \\n => {}\".format(cache_file, log))\n",
    "    _ = model.eval()\n",
    "    return model   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this command for evaluate the Grounding DINO model\n",
    "# Or you can download the model by yourself\n",
    "ckpt_repo_id = \"ShilongLiu/GroundingDINO\"\n",
    "ckpt_filenmae = \"groundingdino_swinb_cogcoor.pth\"\n",
    "ckpt_config_filename = \"GroundingDINO_SwinB.cfg.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groundingdino_model = load_model_hf(ckpt_repo_id, ckpt_filenmae, ckpt_config_filename, device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "pointcloud = []\n",
    "\n",
    "\n",
    "for n in wallBIMNodes:\n",
    "    TEXT_PROMPT = \"Door\"\n",
    "    BOX_TRESHOLD = 0.20\n",
    "    TEXT_TRESHOLD = 0.5\n",
    "    \n",
    "    n.boxes = []\n",
    "    n.logits = []\n",
    "    n.phrases = []\n",
    "    \n",
    "    if len(n.orthos) > 0:\n",
    "        \n",
    "        for ortho in n.orthos:\n",
    "            boxes = None\n",
    "            image = load_image(Image.fromarray((ortho * 255).astype(np.uint8)))\n",
    "\n",
    "            boxes, logits, phrases = predict(\n",
    "                model=groundingdino_model, \n",
    "                image=image, \n",
    "                caption=TEXT_PROMPT, \n",
    "                box_threshold=BOX_TRESHOLD, \n",
    "                text_threshold=TEXT_TRESHOLD\n",
    "            )\n",
    "            \n",
    "            n.boxes.append(boxes)\n",
    "            n.logits.append(logits)\n",
    "            n.phrases.append(phrases)                  \n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_point_cloud(img, startpoint, endpoint, box):\n",
    "    # Define the UV coordinate ranges\n",
    "    u_range = np.linspace(0, 1, img.shape[1])  # Width of the image corresponds to U\n",
    "    v_range = np.linspace(0, 1, img.shape[0])  # Height of the image corresponds to V\n",
    "    \n",
    "    if not img[0].shape == img[1].shape:\n",
    "        print(\"PROBLEM\")\n",
    "    # Initialize arrays to store points and colors\n",
    "    points = []\n",
    "    colors = []\n",
    "\n",
    "    # Precalculate box boundaries\n",
    "    box_boundaries_0 = []\n",
    "    opening_width = int(np.asarray(box)[2]*img.shape[1])* image_resolution\n",
    "    opening_height =   int(np.asarray(box)[3]*img.shape[0]) * image_resolution\n",
    "    \n",
    "    detection_center_u = int(np.asarray(box)[0]*img.shape[1]) * image_resolution\n",
    "    detection_center_v = int(np.asarray(box)[1]*img.shape[0]) * image_resolution  \n",
    "                \n",
    "    u_min = detection_center_u - opening_width / 2\n",
    "    u_max = detection_center_u + opening_width / 2\n",
    "    v_min = detection_center_v - opening_height / 2\n",
    "    v_max = detection_center_v + opening_height / 2\n",
    "    reference_level = (detection_center_v + opening_height/2)\n",
    "    \n",
    "    if is_door(openingwidth = opening_width, openingheight = opening_height) and reference_level > (img.shape[0]*image_resolution-0.5):\n",
    "        box_boundaries_0.append((u_min, u_max, v_min, v_max))\n",
    "            \n",
    "\n",
    "    # Iterate over each pixel in the image\n",
    "    if len(box_boundaries_0) > 0:\n",
    "        for v, u, a in np.ndindex(img.shape):\n",
    "            # Map UV coordinates to XYZ coordinates\n",
    "            x = (1 - u_range[u]) * startpoint[0] + u_range[u] * endpoint[0]\n",
    "            y = (1 - u_range[u]) * startpoint[1] + u_range[u] * endpoint[1]\n",
    "            z = (1 - v_range[v]) * endpoint[2]  # Since V represents Z\n",
    "            \n",
    "            # Check if the point falls inside any of the boxes\n",
    "            in_box_0 = False\n",
    "            for box_boundary in box_boundaries_0:\n",
    "                    u_min, u_max, v_min, v_max = box_boundary\n",
    "                    if u_min <= u*image_resolution < u_max and v_min <= v*image_resolution < v_max:\n",
    "                        in_box_0 = True\n",
    "                        break\n",
    "        \n",
    "            # Assign the color based on whether the point is inside any of the boxes\n",
    "            if in_box_0: \n",
    "                colors.append([0, 0, 1])  # Red\n",
    "                points.append([x, y, z])\n",
    "\n",
    "    return np.array(points), np.array(colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_box_with_margin(image, box, margin = 10):\n",
    "    # Extract center and size from the detection array\n",
    "    width = int(np.asarray(box)[2]*image.shape[1])\n",
    "    height =   int(np.asarray(box)[3]*image.shape[0])\n",
    "    \n",
    "    center_x = int(np.asarray(box)[0]*image.shape[1])\n",
    "    center_y = int(np.asarray(box)[1]*image.shape[0])  \n",
    "    \n",
    "\n",
    "    # Calculate coordinates of the bounding box with extra margin\n",
    "    x1 = int(center_x - width/2) - margin\n",
    "    y1 = int(center_y - height/2) - margin\n",
    "    x2 = int(center_x + width/2) + margin\n",
    "    y2 = int(center_y + height/2) + margin\n",
    "\n",
    "    # Ensure the box is within the image bounds\n",
    "    x1 = max(x1, 0)\n",
    "    y1 = max(y1, 0)\n",
    "    x2 = min(x2, image.shape[1])\n",
    "    y2 = min(y2, image.shape[0])\n",
    "\n",
    "    # Create a new image containing pixels within the bounding box\n",
    "    extracted_image = np.copy(image[y1:y2, x1:x2])\n",
    "    normalized_image = cv2.normalize(extracted_image, None, 0, 255, cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n",
    "\n",
    "    return normalized_image.astype(np.uint8)\n",
    "\n",
    "def compute_center(point1, point2):\n",
    "    center = [(point1[0] + point2[0]) / 2,\n",
    "              (point1[1] + point2[1]) / 2,\n",
    "              (point1[2] + point2[2]) / 2]\n",
    "    return center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "potential_doors = []\n",
    "pointcloud = []\n",
    "\n",
    "wall = 0\n",
    "\n",
    "for n in wallBIMNodes: #^22:24 interessante muren\n",
    "    \n",
    "    count = 0\n",
    "    stand = 0\n",
    "    if len(n.orthos) > 0 and (len(n.boxes[0]) > 0 or len(n.boxes[1]) > 0):\n",
    "        for boxes in n.boxes:\n",
    "            if len(boxes) > 0: \n",
    "                for i, box in enumerate(boxes):\n",
    "                    if stand == 1:\n",
    "                        points, colors = create_point_cloud(n.orthos[stand], n.endpoint,n.startpoint, box)\n",
    "                    else:\n",
    "                        points, colors = create_point_cloud(n.orthos[stand],n.startpoint, n.endpoint, box)\n",
    "                        \n",
    "                    opening_width = int(np.asarray(box)[2]*n.orthos[stand].shape[1])* image_resolution\n",
    "                            \n",
    "                    # print(\"Opening Width:\", opening_width)\n",
    "                    \n",
    "                    #Compute the Height of the door\n",
    "                    opening_height =   int(np.asarray(box)[3]*n.orthos[stand].shape[0]) * image_resolution\n",
    "                    # print(\"Opening height:\", opening_height)\n",
    "                    \n",
    "                    detection_center_u = int(np.asarray(box)[0]*n.orthos[stand].shape[1]) * image_resolution\n",
    "                    detection_center_v = int(np.asarray(box)[1]*n.orthos[stand].shape[0]) * image_resolution                \n",
    "                    \n",
    "                    reference_level = (detection_center_v + opening_height/2)\n",
    "                    \n",
    "                    if is_door(openingwidth = opening_width, openingheight = opening_height) and reference_level > (n.orthos[stand].shape[0]*image_resolution-0.5):\n",
    "                        image = extract_box_with_margin(n.orthos[stand], box.unsqueeze(0)[0])\n",
    "                        image = image[...,::-1] # BGR to RGB\n",
    "                        #Image.fromarray(image).save(os.path.join(Path(os.getcwd()).parents[0]/'data',(str(wall) +\"-\"+ str(stand)+\"-\" + str(count) +'-DOOR.png')))\n",
    "                        #annotated_frame = annotate(image_source= n.orthos[stand], boxes=box.unsqueeze(0), logits=n.logits[stand][i].unsqueeze(0), phrases=[n.phrases[stand][i]])\n",
    "                        # annotated_frame = annotated_frame[...,::-1] # BGR to RGB\n",
    "                        # Image.fromarray(annotated_frame).save(os.path.join(Path(os.getcwd()).parents[0]/'data',(str(wall) +\"-\"+ str(stand)+\"-\" + str(count) +'-DOOR.png')))\n",
    "                        print(\"%s : Door => Referencelevel: %s; Width: %s; Height: %s\" %((str(wall) + \"-\" + str(stand) + \"-\" + str(count)), reference_level, opening_width, opening_height))\n",
    "                        count += 1\n",
    "                        if points.size > 0:\n",
    "                            # Create Open3D point cloud\n",
    "                            pcd_o3d = o3d.geometry.PointCloud()\n",
    "                            pcd_o3d.points = o3d.utility.Vector3dVector(points)\n",
    "                            pcd_o3d.colors = o3d.utility.Vector3dVector(colors)\n",
    "                            o3d.io.write_point_cloud(os.path.join(Path(os.getcwd()).parents[0]/'data',(str(wall) + \"-\" + str(stand) + \"-\" + str(count) + '-DOOR.pcd')), pcd_o3d)\n",
    "                            base_points = points[points[:, 2] == 0, :2]\n",
    "                            # print(base_points)\n",
    "                            min_x_index = np.argmin(points[:, 0])\n",
    "                            max_x_index = np.argmax(points[:, 0])\n",
    "                                                        \n",
    "                            startpoint = [points[min_x_index][0],points[min_x_index][1],0 ]\n",
    "                            endpoint = [points[max_x_index][0],points[max_x_index][1],0 ]\n",
    "                            \n",
    "                            center = compute_center(startpoint, endpoint)\n",
    "                            distance = np.sqrt((endpoint[0] - startpoint[0])**2 + (endpoint[1] - startpoint[1])**2)\n",
    "                            \n",
    "                            \n",
    "                            # pcd_node = PointCloudNode(resource = pcd_o3d, path = os.path.join(Path(os.getcwd()).parents[0]/'data',(str(wall) + \"-\" + str(stand) + \"-\" + str(count) + '-DOOR.pcd')))\n",
    "                            \n",
    "                        on = Node()\n",
    "                        on.width = opening_width\n",
    "                        on.height = opening_height\n",
    "                        on.depth = n.wallThickness\n",
    "                        on.pcd = pcd_o3d\n",
    "                        on.image = image\n",
    "                        on.startpoint = startpoint\n",
    "                        on.endpoint = endpoint\n",
    "                        on.center = center\n",
    "                        on.normal = n.normal\n",
    "                        on.host = n\n",
    "                        potential_doors.append(on)\n",
    "            stand += 1\n",
    "        wall += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_lines(lines, show_centers=True):\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    # Iterate over each line and plot it with a different color\n",
    "    if len(lines[0]) == 2:\n",
    "        for i, (start, end) in enumerate(lines):\n",
    "            color = plt.cm.viridis(i / len(lines))  # Get a color from the Viridis colormap\n",
    "            ax.plot([start[0], end[0]], [start[1], end[1]], color=color)\n",
    "            \n",
    "            if show_centers:\n",
    "                # Compute the center of the line\n",
    "                center = compute_center(start, end)\n",
    "                \n",
    "                # Plot the center with the same color as the line\n",
    "                ax.scatter(center[0], center[1], color=color, label=f'Center {i+1}')\n",
    "\n",
    "        ax.set_aspect('equal', adjustable='box')  # Set aspect ratio to equal\n",
    "        ax.set_xlabel('X')\n",
    "        ax.set_ylabel('Y')\n",
    "        ax.set_title('Lines with Centers')\n",
    "        if show_centers:\n",
    "            ax.legend()\n",
    "        plt.show()\n",
    "    else:\n",
    "        for i, (start, end, _) in enumerate(lines):\n",
    "            color = plt.cm.viridis(i / len(lines))  # Get a color from the Viridis colormap\n",
    "            ax.plot([start[0], end[0]], [start[1], end[1]], color=color)\n",
    "            \n",
    "            if show_centers:\n",
    "                # Compute the center of the line\n",
    "                center = compute_center(start, end)\n",
    "                \n",
    "                # Plot the center with the same color as the line\n",
    "                ax.scatter(center[0], center[1], color=color, label=f'Center {i+1}')\n",
    "\n",
    "        ax.set_aspect('equal', adjustable='box')  # Set aspect ratio to equal\n",
    "        ax.set_xlabel('X')\n",
    "        ax.set_ylabel('Y')\n",
    "        ax.set_title('Lines with Centers')\n",
    "        if show_centers:\n",
    "            ax.legend()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_normal(start, end):\n",
    "    \"\"\"\n",
    "    Compute the normal vector of a line given its start and end points.\n",
    "    \n",
    "    Parameters:\n",
    "        start (tuple): The start point of the line.\n",
    "        end (tuple): The end point of the line.\n",
    "    \n",
    "    Returns:\n",
    "        numpy.ndarray: The computed normal vector.\n",
    "    \"\"\"\n",
    "    # Compute the direction vector of the line\n",
    "    direction = np.array(end) - np.array(start)\n",
    "    # Compute the normal vector by rotating the direction vector 90 degrees\n",
    "    normal = np.array([-direction[1], direction[0]])\n",
    "    # Normalize the normal vector\n",
    "    normal /= np.linalg.norm(normal)\n",
    "    \n",
    "    return normal\n",
    "\n",
    "# Function to calculate the center point of a line segment\n",
    "def calculate_center(line):\n",
    "    startpoint, endpoint, _ = line\n",
    "    return [(startpoint[0] + endpoint[0]) / 2, (startpoint[1] + endpoint[1]) / 2]\n",
    "\n",
    "# Function to calculate the distance between two points\n",
    "def calculate_distance(point1, point2):\n",
    "    return np.linalg.norm(np.array(point1) - np.array(point2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to cluster lines based on normals and centers\n",
    "def cluster_lines(lines, distance_threshold=1, equal_normals = True):\n",
    "    \n",
    "    cluster_ids = [-1] * len(lines)\n",
    "    current_cluster_id = 0\n",
    "    if equal_normals:\n",
    "        normals = set(tuple(line[2]) for line in lines)  # Convert numpy array to tuple\n",
    "        for normal in normals:\n",
    "            lines_with_normal = [line for line in lines if np.array_equal(line[2], normal)]\n",
    "            \n",
    "            centers = [calculate_center(line) for line in lines_with_normal]\n",
    "            \n",
    "            # Using DBSCAN for clustering centers\n",
    "            dbscan = DBSCAN(eps=distance_threshold, min_samples=1, metric=calculate_distance)\n",
    "            labels = dbscan.fit_predict(centers)\n",
    "            \n",
    "            unique_labels = set(labels)\n",
    "            for label in unique_labels:\n",
    "                cluster_lines = [lines_with_normal[i] for i in range(len(lines_with_normal)) if labels[i] == label]\n",
    "                for line in cluster_lines:\n",
    "                    line_index = None\n",
    "                    for i, l in enumerate(lines):\n",
    "                        if np.array_equal(l, line):\n",
    "                            line_index = i\n",
    "                            break\n",
    "                    cluster_ids[line_index] = current_cluster_id\n",
    "                current_cluster_id += 1\n",
    "    else:            \n",
    "        centers = [calculate_center(line) for line in lines]\n",
    "        \n",
    "        # Using DBSCAN for clustering centers\n",
    "        dbscan = DBSCAN(eps=distance_threshold, min_samples=1, metric=calculate_distance)\n",
    "        labels = dbscan.fit_predict(centers)\n",
    "        \n",
    "        unique_labels = set(labels)\n",
    "        for label in unique_labels:\n",
    "            cluster_lines = [lines[i] for i in range(len(lines)) if labels[i] == label]\n",
    "            for line in cluster_lines:\n",
    "                line_index = None\n",
    "                for i, l in enumerate(lines):\n",
    "                    if np.array_equal(l, line):\n",
    "                        line_index = i\n",
    "                        break\n",
    "                cluster_ids[line_index] = current_cluster_id\n",
    "            current_cluster_id += 1\n",
    "    \n",
    "    return cluster_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eerste clustering om detecties langst beide kanten te bundelen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_outer_points(points):\n",
    "    # Convert points to numpy array for easier manipulation\n",
    "    points = np.array(points)\n",
    "    \n",
    "    # Find the index of the point with the smallest coordinate along the line\n",
    "    min_index = np.argmin(points[:, 0])  # Assuming the line is along the x-axis\n",
    "    \n",
    "    # Find the index of the point with the largest coordinate along the line\n",
    "    max_index = np.argmax(points[:, 0])  # Assuming the line is along the x-axis\n",
    "    \n",
    "    # Retrieve the two outer points\n",
    "    outer_point_min = points[min_index]\n",
    "    outer_point_max = points[max_index]\n",
    "    \n",
    "    return outer_point_min, outer_point_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_all_clusters_indices(cluster_labels):\n",
    "    all_clusters_indices = []\n",
    "    \n",
    "    # Get unique cluster labels\n",
    "    unique_labels = np.unique(cluster_labels)\n",
    "    \n",
    "    # Iterate through each unique cluster label\n",
    "    for cluster_label in unique_labels:\n",
    "        if not cluster_label == -1:\n",
    "            cluster_indices = [i for i, label in enumerate(cluster_labels) if label == cluster_label]\n",
    "            all_clusters_indices.append(cluster_indices)\n",
    "        else: \n",
    "            for i, label in enumerate(cluster_labels):\n",
    "                if label == cluster_label:\n",
    "                    all_clusters_indices.append([i])\n",
    "    \n",
    "    return all_clusters_indices\n",
    "\n",
    "def are_normals_same_direction(objects):\n",
    "    # Check if all normals have the same direction\n",
    "    reference_normal = objects[0].normal\n",
    "    for obj in objects[1:]:\n",
    "        if not np.allclose(obj.normal, reference_normal):\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def merge_objects(openings):\n",
    "    if not are_normals_same_direction(openings):\n",
    "        on = openings[0]\n",
    "        return on\n",
    "    \n",
    "    # Merge objects by finding extreme start and end points\n",
    "    on = Node()\n",
    "    on.startpoint, on.endpoint = find_outer_points([obj.startpoint for obj in openings] + [obj.endpoint for obj in openings])\n",
    "    on.height = sum(n.height for n in openings)/len(openings)\n",
    "    on.depth = openings[0].depth\n",
    "    on.pcd = [n.pcd for n in openings]\n",
    "    on.image = [n.image for n in openings]\n",
    "    on.center = compute_center(startpoint, endpoint)\n",
    "    on.normal = openings[0].normal\n",
    "    on.host = openings[0].host\n",
    "    on.width = np.sqrt((on.endpoint[0] - on.startpoint[0])**2 + (on.endpoint[1] - on.startpoint[1])**2)\n",
    "    \n",
    "    return on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = []\n",
    "\n",
    "for n in potential_doors:\n",
    "    lines.append([n.startpoint, n.endpoint, n.normal])\n",
    "\n",
    "plot_lines(lines)\n",
    "clustered_ids = cluster_lines(lines) \n",
    "# plot_clustered_lines_separately(lines, clustered_ids)\n",
    "all_clusters_indices = retrieve_all_clusters_indices(clustered_ids)\n",
    "clustered_lines = []\n",
    "\n",
    "for cluster_indices in all_clusters_indices:\n",
    "    openings = []\n",
    "    for i in cluster_indices:\n",
    "        openings.append(potential_doors[i])\n",
    "    on = merge_objects(openings)\n",
    "    clustered_lines.append(on)\n",
    "    \n",
    "lines = []\n",
    "for n in clustered_lines:\n",
    "    lines.append([n.startpoint, n.endpoint])\n",
    "\n",
    "plot_lines(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = []\n",
    "\n",
    "for n in clustered_lines:\n",
    "    lines.append([n.startpoint, n.endpoint, n.normal])\n",
    "    \n",
    "clustered_ids = cluster_lines(lines, distance_threshold=0.5, equal_normals = True)\n",
    "all_clusters_indices = retrieve_all_clusters_indices(clustered_ids)\n",
    "\n",
    "clustered_lines2 = []\n",
    "for cluster_indices in all_clusters_indices:\n",
    "    openings = []\n",
    "    for i in cluster_indices:\n",
    "        openings.append(clustered_lines[i])\n",
    "    on = merge_objects(openings)\n",
    "    clustered_lines2.append(on)\n",
    "    \n",
    "lines = []\n",
    "for n in clustered_lines2:\n",
    "    lines.append([n.startpoint, n.endpoint])\n",
    "\n",
    "plot_lines(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_percentage_black_pixels(image):\n",
    "    # Convert the image to grayscale\n",
    "    grayscale_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Count black pixels\n",
    "    black_pixel_count = cv2.countNonZero(grayscale_image)\n",
    "\n",
    "    # Calculate total number of pixels\n",
    "    total_pixels = grayscale_image.shape[0] * grayscale_image.shape[1]\n",
    "\n",
    "    # Calculate percentage of black pixels\n",
    "    percentage_black_pixels = (black_pixel_count / total_pixels) * 100\n",
    "\n",
    "    return percentage_black_pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = []\n",
    "\n",
    "for n in clustered_lines2:\n",
    "    lines.append([n.startpoint, n.endpoint, n.normal])\n",
    "    \n",
    "clustered_ids = cluster_lines(lines, distance_threshold=1.2, equal_normals = False)\n",
    "all_clusters_indices = retrieve_all_clusters_indices(clustered_ids)\n",
    "\n",
    "openings = []\n",
    "for cluster in all_clusters_indices:\n",
    "    if len(cluster) > 1:\n",
    "        l = [clustered_lines2[i] for i in cluster]\n",
    "        \n",
    "        # Plotting the images\n",
    "        # fig, axes = plt.subplots(1, len(l))            \n",
    "        \n",
    "        lines = []\n",
    "        i = 0\n",
    "        for j, n in enumerate(l):\n",
    "            lines.append([n.startpoint, n.endpoint, n.normal])\n",
    "            # axes[i].imshow(Image.fromarray(n.image[0][0]))\n",
    "            # axes[i].axis('off')\n",
    "            i+=1\n",
    "            if calculate_percentage_black_pixels(n.image[0][0]) < 50:\n",
    "                openings.append(n)\n",
    "                for jj, n2 in enumerate(l): \n",
    "                    if not jj == j:\n",
    "                        if np.array_equal(n.normal, n2.normal):\n",
    "                            openings.append(n2)\n",
    "                \n",
    "        # plot_lines(lines)\n",
    "    else:\n",
    "        openings.append(clustered_lines[cluster[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines =[]\n",
    "for n in openings:\n",
    "    lines.append([n.startpoint, n.endpoint, n.normal])\n",
    "plot_lines(lines, show_centers=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CVPR2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
